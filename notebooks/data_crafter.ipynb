{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vier verschiedene Datensätze einladen und zu seinem DataFrame zusammenfassen\n",
    "\n",
    "papers = pd.read_csv(\"../data/sources/papers.csv\", sep=\",\") # Einlesen der Daten\n",
    "papers = papers[:700] # Begrenzen auf 700 Einträge\n",
    "papers[\"classification\"] = \"paper\" # Zielvariable für die Klassifikation hinzufügen\n",
    "papers = papers[[\"summaries\", \"classification\"]] # Daten auf wesentlich Spalten reduzieren\n",
    "papers.rename(columns={\"summaries\": \"text\"}, inplace=True) # Spalten umbenennen, damit sie besser zusammengefügt werden können\n",
    "papers_train = papers[:500] # Trainingsdatensatz festlegen (500 Einträge)\n",
    "papers_test = papers[500:] # Testdatensatz festlegen (200 Einträge)\n",
    "\n",
    "# Diese Schritte wiederholen sich für die anderen 3 Kategorien\n",
    "\n",
    "news = pd.read_csv(\"../data/sources/news.csv\", sep=\",\", encoding=\"ISO-8859-1\")\n",
    "news = news[:700]\n",
    "news[\"classification\"] = \"news\"\n",
    "news = news[[\"text\", \"classification\"]]\n",
    "news_train = news[:500]\n",
    "news_test = news[500:]\n",
    "\n",
    "reviews = pd.read_csv(\"../data/sources/reviews.csv\", sep=\",\", header=None)\n",
    "reviews = reviews[:700]\n",
    "reviews[\"classification\"] = \"reviews\"\n",
    "reviews = reviews[[2, \"classification\"]]\n",
    "reviews.rename(columns={2: \"text\"}, inplace=True)\n",
    "reviews_train = reviews[:500]\n",
    "reviews_test = reviews[500:]\n",
    "\n",
    "stories = pd.read_excel(\"../data/sources/stories.xlsx\")\n",
    "stories = stories[:700]\n",
    "stories[\"classification\"] = \"story\"\n",
    "stories = stories[[\"story\", \"classification\"]]\n",
    "stories.rename(columns={\"story\": \"text\"}, inplace=True)\n",
    "stories_train = stories[:500]\n",
    "stories_test = stories[500:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.concat([papers_train, news_train, reviews_train, stories_train]) # Trainingsdaten zu einem Datensatz zusammenfassen\n",
    "data_test = pd.concat([papers_test, news_test, reviews_test, stories_test]) # Testdaten zu einem Datensatz zusammenfassen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daten exportieren\n",
    "data_train.to_csv(\"../data/data_train.csv\")\n",
    "data_test.to_csv(\"../data/data_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP-Projektrealisierung",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
