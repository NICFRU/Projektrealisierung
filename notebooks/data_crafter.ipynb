{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vier verschiedene Datensätze einladen und zu seinem DataFrame zusammenfassen\n",
    "\n",
    "## Wissenschaftlich Texte einlesen (liegen als txt Datei vor)\n",
    "with open('../data/sources/val.txt','r') as f:\n",
    "  texts = []\n",
    "  for i in range(700):\n",
    "    line = f.readline()\n",
    "    obj = json.loads(line)\n",
    "    texts.append(obj[\"article_text\"])\n",
    "    \n",
    "scientific_texts = pd.DataFrame(columns=[\"classification\", \"text\"])\n",
    "scientific_texts[\"text\"] = texts\n",
    "scientific_texts[\"classification\"] = \"Scientific\"\n",
    "scientific_texts_train = scientific_texts[:500]\n",
    "scientific_texts_test = scientific_texts[500:]\n",
    "\n",
    "# Die anderen Kategorien werden als CSV eingelesen\n",
    "\n",
    "news = pd.read_csv(\"../data/sources/news.csv\", sep=\",\", encoding=\"ISO-8859-1\") # Einlesen der Daten\n",
    "news = news[:700] # Begrenzen auf 700 Einträge\n",
    "news[\"classification\"] = \"news\" # Zielvariable für die Klassifikation hinzufügen\n",
    "news = news[[\"text\", \"classification\"]] # Daten auf wesentlich Spalten reduzieren\n",
    "news_train = news[:500] # Trainingsdatensatz festlegen (500 Einträge)\n",
    "news_test = news[500:] # Testdatensatz festlegen (200 Einträge)\n",
    "\n",
    "reviews = pd.read_csv(\"../data/sources/reviews.csv\", sep=\",\", header=None)\n",
    "reviews = reviews[:700]\n",
    "reviews[\"classification\"] = \"reviews\"\n",
    "reviews = reviews[[2, \"classification\"]]\n",
    "reviews.rename(columns={2: \"text\"}, inplace=True) # Spalten umbenennen, damit sie besser zusammengefügt werden können\n",
    "reviews_train = reviews[:500]\n",
    "reviews_test = reviews[500:]\n",
    "\n",
    "stories = pd.read_excel(\"../data/sources/stories.xlsx\")\n",
    "stories = stories[:700]\n",
    "stories[\"classification\"] = \"story\"\n",
    "stories = stories[[\"story\", \"classification\"]]\n",
    "stories.rename(columns={\"story\": \"text\"}, inplace=True)\n",
    "stories_train = stories[:500]\n",
    "stories_test = stories[500:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.concat([papers_train, news_train, reviews_train, stories_train]) # Trainingsdaten zu einem Datensatz zusammenfassen\n",
    "data_test = pd.concat([papers_test, news_test, reviews_test, stories_test]) # Testdaten zu einem Datensatz zusammenfassen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daten exportieren\n",
    "data_train.to_csv(\"../data/data_train.csv\")\n",
    "data_test.to_csv(\"../data/data_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP-Projektrealisierung",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
