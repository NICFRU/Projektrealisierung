{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!apt install git-lfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "# this ensures that the current MacOS version is at least 12.3+\n",
    "print(torch.backends.mps.is_available())\n",
    "# this ensures that the current current PyTorch installation was built with MPS activated.\n",
    "print(torch.backends.mps.is_built())\n",
    "dtype = torch.float\n",
    "device = torch.device(\"mps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached shuffled indices for dataset at /Users/niclascramer/.cache/huggingface/datasets/amazon_reviews_multi/en/1.0.0/724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609/cache-0b126a62dc97ecba.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "'>> Title: Worked in front position, not rear'\n",
      "'>> Review: 3 stars because these are not rear brakes as stated in the item description. At least the mount adapter only worked on the front fork of the bike that I got it for.'\n",
      "\n",
      "'>> Title: meh'\n",
      "'>> Review: Does it’s job and it’s gorgeous but mine is falling apart, I had to basically put it together again with hot glue'\n",
      "\n",
      "'>> Title: Can't beat these for the money'\n",
      "'>> Review: Bought this for handling miscellaneous aircraft parts and hanger \"stuff\" that I needed to organize; it really fit the bill. The unit arrived quickly, was well packaged and arrived intact (always a good sign). There are five wall mounts-- three on the top and two on the bottom. I wanted to mount it on the wall, so all I had to do was to remove the top two layers of plastic drawers, as well as the bottom corner drawers, place it when I wanted and mark it; I then used some of the new plastic screw in wall anchors (the 50 pound variety) and it easily mounted to the wall. Some have remarked that they wanted dividers for the drawers, and that they made those. Good idea. My application was that I needed something that I can see the contents at about eye level, so I wanted the fuller-sized drawers. I also like that these are the new plastic that doesn't get brittle and split like my older plastic drawers did. I like the all-plastic construction. It's heavy duty enough to hold metal parts, but being made of plastic it's not as heavy as a metal frame, so you can easily mount it to the wall and still load it up with heavy stuff, or light stuff. No problem there. For the money, you can't beat it. Best one of these I've bought to date-- and I've been using some version of these for over forty years.'\n"
     ]
    }
   ],
   "source": [
    "def show_samples(dataset, num_samples=3, seed=42):\n",
    "    sample = dataset[\"train\"].shuffle(seed=seed).select(range(num_samples))\n",
    "    for example in sample:\n",
    "        print(f\"\\n'>> Title: {example['review_title']}'\")\n",
    "        print(f\"'>> Review: {example['review_body']}'\")\n",
    "\n",
    "\n",
    "show_samples(english_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_df=english_df[['review_body','review_title']]\n",
    "english_df=english_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200000"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(english_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zähle die Wortanzahl auf jede Zeile in der Spalte 'review_title' und 'review_body' an\n",
    "english_df['review_title_counts'] = english_df['review_title'].apply(lambda x: len(str(x).split()))\n",
    "english_df['review_body_counts'] = english_df['review_body'].apply(lambda x: len(str(x).split()))\n",
    "english_df['kompression']=round(english_df['review_title_counts']/english_df['review_body_counts']*100,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review_body_counts                                                  247\n",
       "review_body           Bought this for handling miscellaneous aircraf...\n",
       "Name: 169285, dtype: object"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english_df.loc[169285][['review_body_counts','review_body']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_body</th>\n",
       "      <th>review_title</th>\n",
       "      <th>review_title_counts</th>\n",
       "      <th>review_body_counts</th>\n",
       "      <th>kompression</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Arrived broken. Manufacturer defect. Two of th...</td>\n",
       "      <td>I'll spend twice the amount of time boxing up ...</td>\n",
       "      <td>22</td>\n",
       "      <td>112</td>\n",
       "      <td>19.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the cabinet dot were all detached from backing...</td>\n",
       "      <td>Not use able</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>30.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I received my first order of this product and ...</td>\n",
       "      <td>The product is junk.</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This product is a piece of shit. Do not buy. D...</td>\n",
       "      <td>Fucking waste of money</td>\n",
       "      <td>4</td>\n",
       "      <td>29</td>\n",
       "      <td>13.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>went through 3 in one day doesn't fit correct ...</td>\n",
       "      <td>bubble</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>6.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         review_body  \\\n",
       "0  Arrived broken. Manufacturer defect. Two of th...   \n",
       "1  the cabinet dot were all detached from backing...   \n",
       "2  I received my first order of this product and ...   \n",
       "3  This product is a piece of shit. Do not buy. D...   \n",
       "4  went through 3 in one day doesn't fit correct ...   \n",
       "\n",
       "                                        review_title  review_title_counts  \\\n",
       "0  I'll spend twice the amount of time boxing up ...                   22   \n",
       "1                                       Not use able                    3   \n",
       "2                               The product is junk.                    4   \n",
       "3                             Fucking waste of money                    4   \n",
       "4                                             bubble                    1   \n",
       "\n",
       "   review_body_counts  kompression  \n",
       "0                 112        19.64  \n",
       "1                  10        30.00  \n",
       "2                  40        10.00  \n",
       "3                  29        13.79  \n",
       "4                  16         6.25  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# der review title = die zusammenfassung\n",
    "english_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_histogram(english_df, 'review_title_counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkQAAAHFCAYAAAAT5Oa6AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAABL6ElEQVR4nO3deVxU9f4/8NfIMiDCKCgMo4hUCBi4BIVoBe4bkpnXCiMtc8ktUrPIWw7eArObS3pzy9zQsL6Bea1QTPTmVRRREpeobuhoDQIKgwub8Pn94YPzcwQUERiY83o+HueR8znvOefzOTPAqzPnM0chhBAgIiIikrFWpu4AERERkakxEBEREZHsMRARERGR7DEQERERkewxEBEREZHsMRARERGR7DEQERERkewxEBEREZHsMRARERGR7DEQUbOxceNGKBQKHDt2rMb1oaGh6NKli1Fbly5dMGHChPvaz6FDh6DValFYWFi/jtJdVb2O586da5L9HTlyBM8++yw6d+4MpVIJFxcXBAUFYc6cOY2+7zvff3/99Re0Wi0yMjIafF8KhQIbN26U9qvVaqV19/rZoXurz++S+6XVaqXfYVWvGTUflqbuANGDSExMhIODw30959ChQ4iOjsaECRPQtm3bxukYNYnvvvsOYWFhCAkJweLFi+Hq6gq9Xo9jx44hPj4en3zySZP256+//kJ0dDS6dOmCnj17Num+6cHU53cJmRcGImrRevXqZeou3Lfy8nIoFApYWvLHry5u3LiB1q1b17hu8eLF8PDwwO7du42O5wsvvIDFixc3VRepAZnq56Ml/i6hhsWPzKhFu/M0d2VlJT744AN4eXnB1tYWbdu2Rffu3bF8+XIAt05Zv/XWWwAADw8PKBQKKBQK7N+/X3r+4sWL4e3tDaVSCWdnZ7z88su4ePGi0X6FEIiJiYG7uztsbGwQEBCA5ORkhISEICQkRKrbv38/FAoFtmzZgjlz5qBjx45QKpX4/fffkZeXh2nTpqFbt25o06YNnJ2d0b9/f/z0009G+zp37hwUCgU+/vhjfPTRR+jSpQtsbW0REhKCX3/9FeXl5XjnnXeg0WigUqnw7LPPIjc3t9pxCg0Nxa5du9CrVy/Y2trCx8cHu3btAnDr9L2Pjw/s7OzwxBNP1Pmjl9TUVPTt2xc2NjbQaDSIiopCeXl5jbXbt29HUFAQ7Ozs0KZNGwwZMgQnTpwwqpkwYQLatGmDzMxMDB48GPb29hgwYECt+798+TLat29f4x/PVq2Mf71VHYPExER0794dNjY2eOihh/Dpp58a1ZWUlGDOnDno2bMnVCoVHB0dERQUhG+//faux2L//v14/PHHAQCvvPKK9N66/aOtY8eOISwsDI6OjrCxsUGvXr3w1Vdf3XW79aXX6+Hv7w9PT0/89ttvAACdToeXXnoJzs7OUCqV8PHxwSeffILKykrpeQ35frvXsb7bzwcA7N27FwMGDICDgwNat26Nvn374scffzTaRl5eHiZPngw3NzcolUp06NABffv2xd69e6WaEydOIDQ0VBq3RqPBiBEjjH6ua/rI7H6O1z//+U8sWbIEHh4eaNOmDYKCgpCamlqPV45MRhA1Exs2bBAARGpqqigvL6+2DB8+XLi7uxs9x93dXYwfP156HBsbKywsLMSCBQvEjz/+KJKSksSyZcuEVqsVQghx4cIFMXPmTAFAJCQkiMOHD4vDhw8Lg8EghBBi8uTJAoCYMWOGSEpKEqtXrxYdOnQQbm5uIi8vT9pPVFSUACAmT54skpKSxLp160Tnzp2Fq6urCA4OlupSUlIEANGxY0cxZswYsXPnTrFr1y5x+fJl8csvv4jXX39dxMfHi/3794tdu3aJiRMnilatWomUlBRpG9nZ2QKAcHd3FyNHjhS7du0ScXFxwsXFRXTt2lVERESIV199Vfzwww9i9erVok2bNmLkyJHVjlOnTp2Er6+v+PLLL8X3338vAgMDhZWVlXj//fdF3759RUJCgkhMTBRdu3YVLi4u4saNG3d9vU6fPi1at24tunXrJr788kvx7bffiiFDhojOnTsLACI7O1uq/fDDD4VCoRCvvvqq2LVrl0hISBBBQUHCzs5OnD59WqobP368sLKyEl26dBGxsbHixx9/FLt37661D6+99poAIGbOnClSU1NFWVlZrbXu7u6iY8eOonPnzuKLL74Q33//vRg3bpwAID7++GOprrCwUEyYMEFs2bJF7Nu3TyQlJYm5c+eKVq1aiU2bNlXbZtX7z2AwSO/hv//979J768KFC0IIIfbt2yesra3FU089JbZv3y6SkpLEhAkTBACxYcOGux7re6nab1pamhBCiMzMTOHm5iaCgoKk921ubq7o2LGj6NChg1i9erVISkoSM2bMEADE66+/Lm2rod5vdTnWd/v52LJli1AoFGLUqFEiISFB/Pvf/xahoaHCwsJC7N27V9rGkCFDRIcOHcTatWvF/v37xY4dO8T7778v4uPjhRBCXLt2TTg5OYmAgADx1VdfiQMHDojt27eLqVOnijNnztT4WtbneHXp0kUMHTpU7NixQ+zYsUP4+fmJdu3aicLCwgd6banpMBBRs1H1S/1uy70CUWhoqOjZs+dd9/Pxxx9X+4MthBBnz54VAMS0adOM2o8cOSIAiHfffVcIIcSVK1eEUqkUzz//vFHd4cOHBYAaA9HTTz99z/HfvHlTlJeXiwEDBohnn31Waq/6hdujRw9RUVEhtS9btkwAEGFhYUbbiYyMFACkkCfEreNka2srLl68KLVlZGQIAMLV1VVcv35dat+xY4cAIHbu3HnX/j7//PPC1tZW5OTkGI3B29vb6PjqdDphaWkpZs6cafT8q1evCrVaLcaOHSu1jR8/XgAQX3zxxV33XSU/P188+eST0vvDyspK9OnTR8TGxoqrV68a1bq7uwuFQiEyMjKM2gcNGiQcHByMjsHtql6XiRMnil69elXb5u3vv7S0tFoDjre3t+jVq5coLy83ag8NDRWurq5Gr+39uj0QJScnCwcHBzFmzBhRXFws1bzzzjsCgDhy5IjRc19//XWhUChEVlaWEKLh3m91Oda1/Xxcv35dODo6VgtaFRUVokePHuKJJ56Q2tq0aSMiIyNrPTbHjh0TAMSOHTtqranq8+2v5f0eLz8/P3Hz5k2p7ujRowKA+PLLL++6X2o++JEZNTubN29GWlpateXJJ5+853OfeOIJ/Pzzz5g2bRp2796NoqKiOu83JSUFAKqdNn/iiSfg4+MjnapPTU1FaWkpxo4da1TXu3fvarPgqjz33HM1tq9evRqPPfYYbGxsYGlpCSsrK/z44484e/Zstdrhw4cbfQzk4+MDABgxYoRRXVW7Tqczau/Zsyc6duxYrS4kJMToGp2q9vPnz9fY5yopKSkYMGAAXFxcpDYLCws8//zzRnW7d+/GzZs38fLLL+PmzZvSYmNjg+DgYOnjytvVdrzu5OTkhJ9++glpaWlYtGgRnnnmGfz666+IioqCn58f8vPzjeofffRR9OjRw6gtPDwcRUVFOH78uNT29ddfo2/fvmjTpo30uqxfv77G16Uufv/9d/zyyy8YN24cABgdh+HDh0Ov1yMrK6te277dpk2bMHz4cLz22mv46quvYGNjI63bt28funXrhieeeMLoORMmTIAQAvv27TNqf9D3W12PNVD99T506BCuXLmC8ePHGx2ryspKDB06FGlpabh+/TqAWz+fGzduxAcffIDU1NRqH9k+8sgjaNeuHd5++22sXr0aZ86cqeHIVXe/x2vEiBGwsLCQHnfv3h3AvX+OqPlgIKJmx8fHBwEBAdUWlUp1z+dGRUXhn//8J1JTUzFs2DA4OTlhwIABdbom5vLlywAAV1fXaus0Go20vuq/tweBKjW11bbNJUuW4PXXX0dgYCC++eYbpKamIi0tDUOHDkVxcXG1ekdHR6PH1tbWd20vKSlp0Off6fLly1Cr1dXa72y7dOkSAODxxx+HlZWV0bJ9+/ZqoaV169b3PdsnICAAb7/9Nr7++mv89ddfePPNN3Hu3LlqF1bfrb9Vr2tCQgLGjh2Ljh07Ii4uDocPH0ZaWhpeffXVex6T2lQdg7lz51Y7BtOmTQOAasehPuLj42Fra4vXXnut2pTuy5cv1/rerlp/uwd9v9TlWFe5s19Vx2vMmDHVjtdHH30EIQSuXLkC4Na1aePHj8fnn3+OoKAgODo64uWXX0ZOTg4AQKVS4cCBA+jZsyfeffddPProo9BoNFiwYEGt17tV9fF+jpeTk5PRY6VSCQA1/ixT88RpLmRWLC0tMXv2bMyePRuFhYXYu3cv3n33XQwZMgQXLlyodbYS8P9/oen1enTq1Mlo3V9//YX27dsb1VX90r5dTk5OjWeJavq+kbi4OISEhGDVqlVG7VevXr37IJsJJycn6Y/O7e5sqzpu//d//wd3d/d7bvdBv5vFysoKCxYswNKlS3Hq1Km79u32tqrXNS4uDh4eHti+fbtRX0pLS+vdp6pjEBUVhdGjR9dY4+XlVe/tV9m6dSvee+89BAcHY8+ePUZT/52cnKDX66s956+//jLqY0Opy7GucudrXtWXFStWoHfv3jVuv+p/Ptq3b49ly5Zh2bJl0Ol02LlzJ9555x3k5uYiKSkJAODn54f4+HgIIXDy5Els3LgRCxcuhK2tLd55550at9/Ux4tMj2eIyGy1bdsWY8aMwfTp03HlyhXpiwJr+z+3/v37A7j1B/F2aWlpOHv2rDTbKTAwEEqlEtu3bzeqS01Nva/T4wqFQupLlZMnT+Lw4cN13oYp9evXDz/++KNRMKyoqKh2XIYMGQJLS0v873//q/HMX0BAQL37UNMfLADSR1tV/zdf5fTp0/j555+N2rZt2wZ7e3s89thjAG69LtbW1kZ/pHNycu45ywyo/b3l5eUFT09P/Pzzz7UeA3t7+3tu/14cHR2xd+9e+Pj4oF+/fkaznAYMGIAzZ85U+7hq8+bNUCgU6Nev3wPv/3Z1Oda16du3L9q2bYszZ87UeryqzkzdrnPnzpgxYwYGDRpUbZzArde2R48eWLp0Kdq2bVtjTZWmPl5kejxDRGZl5MiR8PX1RUBAADp06IDz589j2bJlcHd3h6enJ4Bb/7cIAMuXL8f48eNhZWUFLy8veHl5YfLkyVixYgVatWqFYcOG4dy5c3jvvffg5uaGN998E8CtPzqzZ89GbGws2rVrh2effRYXL15EdHQ0XF1dq033rk1oaCj+8Y9/YMGCBQgODkZWVhYWLlwIDw8P3Lx5s3EOUAP6+9//jp07d6J///54//330bp1a/zrX/+Sru2o0qVLFyxcuBDz58/HH3/8gaFDh6Jdu3a4dOkSjh49Cjs7O0RHR9erD0OGDEGnTp0wcuRIeHt7o7KyEhkZGfjkk0/Qpk0bvPHGG0b1Go0GYWFh0Gq1cHV1RVxcHJKTk/HRRx9JZw9DQ0ORkJCAadOmYcyYMbhw4QL+8Y9/wNXVVZq+XpuHH34Ytra22Lp1K3x8fNCmTRtoNBpoNBqsWbMGw4YNw5AhQzBhwgR07NgRV65cwdmzZ3H8+HF8/fXX9ToGd7K3t0dSUhJGjx6NQYMGYefOnejXrx/efPNNbN68GSNGjMDChQvh7u6O7777Dp999hlef/11dO3atUH2X6Uux7o2bdq0wYoVKzB+/HhcuXIFY8aMgbOzM/Ly8vDzzz8jLy8Pq1atgsFgQL9+/RAeHg5vb2/Y29sjLS1NGj8A7Nq1C5999hlGjRqFhx56CEIIJCQkoLCwEIMGDaq1D019vKgZMOkl3US3uXPq8J1GjBhxz1lmn3zyiejTp49o3769sLa2Fp07dxYTJ04U586dM3peVFSU0Gg0olWrVgKANM29oqJCfPTRR6Jr167CyspKtG/fXrz00kvS1OkqlZWV4oMPPhCdOnUS1tbWonv37mLXrl2iR48eRjPEqmbRfP3119XGU1paKubOnSs6duwobGxsxGOPPSZ27Nghxo8fbzTOqlkst09Xvtu2azqO7u7uYsSIEdX6AEBMnz7dqK22/dXkv//9r+jdu7dQKpVCrVaLt956S6xdu7bGWXw7duwQ/fr1Ew4ODkKpVAp3d3cxZswYoynU48ePF3Z2dvfcb5Xt27eL8PBw4enpKdq0aSOsrKxE586dRUREhNGU6tuPwf/93/+JRx99VFhbW4suXbqIJUuWVNvuokWLRJcuXYRSqRQ+Pj5i3bp1YsGCBeLOX5l3vv+EEOLLL78U3t7ewsrKSgAQCxYskNb9/PPPYuzYscLZ2VlYWVkJtVot+vfvL1avXl3nMdekpte8tLRUPPfcc8LGxkZ89913Qgghzp8/L8LDw4WTk5OwsrISXl5e4uOPPzaaTdaQ77d7Heu7/XwIIcSBAwfEiBEjhKOjo7CyshIdO3YUI0aMkOpLSkrE1KlTRffu3YWDg4OwtbUVXl5eYsGCBdJMtl9++UW8+OKL4uGHHxa2trZCpVKJJ554QmzcuNFoXzW9lg9yvIQQ1V5/at4UQgjR1CGMyBxlZ2fD29sbCxYswLvvvmvq7tAdunTpAl9fX+nLKKnx8FhTS8SPzIjq4eeff8aXX36JPn36wMHBAVlZWVi8eDEcHBwwceJEU3ePiIjuEwMRUT3Y2dnh2LFjWL9+PQoLC6FSqRASEoIPP/yw1qn3RETUfPEjMyIiIpI9TrsnIiIi2WMgIiIiItljICIiIiLZ40XVdVRZWYm//voL9vb2D3xrASIiImoaQghcvXoVGo3mrl+cy0BUR3/99Rfc3NxM3Q0iIiKqhwsXLlS7T+XtGIjqqOo+QxcuXLjvO3ETERGRaRQVFcHNze2e9wtkIKqjqo/JHBwcGIiIiIhamHtd7sKLqomIiEj2GIiIiIhI9hiIiIiISPYYiIiIiEj2GIiIiIhI9hiIiIiISPYYiIiIiEj2GIiIiIhI9hiIiIiISPYYiIiIiEj2GIiIiIhI9hiIiIiISPYYiIiIiEj2GIiIiIhI9hiImjGdTgedTmfqbhAREZk9BqJmSqfTwcvbB17ePgxFREREjYyBqJnKz89HSfENlBTfQH5+vqm7Q0REZNYYiIiIiEj2GIiIiIhI9hiIiIiISPYYiJoRvV4PrVYLvV5v6q4QERHJiqWpO0D/n16vR3R0NIKCgpCQkGDq7hAREckGzxA1Q/n5+Vi7dq2pu0FERCQbDEREREQkewxEREREJHsMRERERCR7DEREREQkewxEREREJHsMRERERCR7DEREREQkewxELZxOp4NOpzN1N4iIiFo0BqIWTKfTwcvbB17ePgxFRERED8DkgejPP//ESy+9BCcnJ7Ru3Ro9e/ZEenq6tF4IAa1WC41GA1tbW4SEhOD06dNG2ygtLcXMmTPRvn172NnZISwsDBcvXjSqKSgoQEREBFQqFVQqFSIiIlBYWNgUQ2w0+fn5KCm+gZLiG8jPzzd1d4iIiFoskwaigoIC9O3bF1ZWVvjhhx9w5swZfPLJJ2jbtq1Us3jxYixZsgQrV65EWloa1Go1Bg0ahKtXr0o1kZGRSExMRHx8PA4ePIhr164hNDQUFRUVUk14eDgyMjKQlJSEpKQkZGRkICIioimHS0RERM2USW/u+tFHH8HNzQ0bNmyQ2rp06SL9WwiBZcuWYf78+Rg9ejQAYNOmTXBxccG2bdswZcoUGAwGrF+/Hlu2bMHAgQMBAHFxcXBzc8PevXsxZMgQnD17FklJSUhNTUVgYCAAYN26dQgKCkJWVha8vLyabtBERETU7Jj0DNHOnTsREBCAv/3tb3B2dkavXr2wbt06aX12djZycnIwePBgqU2pVCI4OBiHDh0CAKSnp6O8vNyoRqPRwNfXV6o5fPgwVCqVFIYAoHfv3lCpVFLNnUpLS1FUVGS0NBXe6Z6IiKhpmTQQ/fHHH1i1ahU8PT2xe/duTJ06FbNmzcLmzZsBADk5OQAAFxcXo+e5uLhI63JycmBtbY127drdtcbZ2bna/p2dnaWaO8XGxkrXG6lUKri5uT3YYO8DAxEREVHTMmkgqqysxGOPPYaYmBj06tULU6ZMwaRJk7Bq1SqjOoVCYfRYCFGt7U531tRUf7ftREVFwWAwSMuFCxfqOiwiIiJqYUwaiFxdXdGtWzejNh+f/z+FXK1WA0C1szi5ubnSWSO1Wo2ysjIUFBTctebSpUvV9p+Xl1ft7FMVpVIJBwcHo4WIiIjMk0kDUd++fZGVlWXU9uuvv8Ld3R0A4OHhAbVajeTkZGl9WVkZDhw4gD59+gAA/P39YWVlZVSj1+tx6tQpqSYoKAgGgwFHjx6Vao4cOQKDwSDVEBERkXyZdJbZm2++iT59+iAmJgZjx47F0aNHsXbtWqxduxbArY+5IiMjERMTA09PT3h6eiImJgatW7dGeHg4AEClUmHixImYM2cOnJyc4OjoiLlz58LPz0+adebj44OhQ4di0qRJWLNmDQBg8uTJCA0N5QwzIiIiMm0gevzxx5GYmIioqCgsXLgQHh4eWLZsGcaNGyfVzJs3D8XFxZg2bRoKCgoQGBiIPXv2wN7eXqpZunQpLC0tMXbsWBQXF2PAgAHYuHEjLCwspJqtW7di1qxZ0my0sLAwrFy5sukGS0RERM2WQgghTN2JlqCoqAgqlQoGg6HRric6fvw4/P39q7Wnp6fjscceu2t9bTVERERyVte/3ya/dQfVHW/kSkRE1DgYiFoI3siViIio8TAQtQBr1qzB2bNnpRu5ZmZmMhQRERE1IAaiFmDt2rVGd7Mf/dwYeHn7QK/Xm7BXRERE5sOks8yofspKSwAAhYWFpu0IERGRmeAZIiIiIpI9BiIzxNloRERE94eByMxwNhoREdH9YyAyM/n5+dJstNsvxCYiIqLaMRARERGR7DEQERERkewxEBEREZHsMRARERGR7DEQERERkewxEBEREZHsMRARERGR7DEQERERkewxEBEREZHsMRARERGR7DEQERERkewxEBEREZHsMRARERGR7DEQERERkewxEBEREZHsMRARERGR7DEQERERkewxEBEREZHsMRARERGR7DEQERERkewxEBEREZHsMRC1EPn5+abuAhERkdliIGoh5r41z9RdICIiMlsMRC3EzfIyU3eBiIjIbDEQERERkewxEBEREZHsMRARERGR7DEQERERkewxEBEREZHsMRARERGR7DEQERERkewxEDUjer3e1F0gIiKSJQaiZqSwsNDUXSAiIpIlBqJmhPcrIyIiMg0GomZCp9PxfmVEREQmYtJApNVqoVAojBa1Wi2tF0JAq9VCo9HA1tYWISEhOH36tNE2SktLMXPmTLRv3x52dnYICwvDxYsXjWoKCgoQEREBlUoFlUqFiIiIZvfxVH5+Pu9XRkREZCImP0P06KOPQq/XS0tmZqa0bvHixViyZAlWrlyJtLQ0qNVqDBo0CFevXpVqIiMjkZiYiPj4eBw8eBDXrl1DaGgoKioqpJrw8HBkZGQgKSkJSUlJyMjIQERERJOOk4iIiJovS5N3wNLS6KxQFSEEli1bhvnz52P06NEAgE2bNsHFxQXbtm3DlClTYDAYsH79emzZsgUDBw4EAMTFxcHNzQ179+7FkCFDcPbsWSQlJSE1NRWBgYEAgHXr1iEoKAhZWVnw8vJqusESERFRs2TyM0S//fYbNBoNPDw88MILL+CPP/4AAGRnZyMnJweDBw+WapVKJYKDg3Ho0CEAQHp6OsrLy41qNBoNfH19pZrDhw9DpVJJYQgAevfuDZVKJdXUpLS0FEVFRUYLERERmSeTBqLAwEBs3rwZu3fvxrp165CTk4M+ffrg8uXLyMnJAQC4uLgYPcfFxUVal5OTA2tra7Rr1+6uNc7OztX27ezsLNXUJDY2VrrmSKVSwc3N7YHGSkRERM2XSQPRsGHD8Nxzz8HPzw8DBw7Ed999B+DWR2NVFAqF0XOEENXa7nRnTU3199pOVFQUDAaDtFy4cKFOYyIiIqKWx+Qfmd3Ozs4Ofn5++O2336Triu48i5ObmyudNVKr1SgrK0NBQcFday5dulRtX3l5edXOPt1OqVTCwcHBaCEiIiLz1KwCUWlpKc6ePQtXV1d4eHhArVYjOTlZWl9WVoYDBw6gT58+AAB/f39YWVkZ1ej1epw6dUqqCQoKgsFgwNGjR6WaI0eOwGAwSDVEREQkbyadZTZ37lyMHDkSnTt3Rm5uLj744AMUFRVh/PjxUCgUiIyMRExMDDw9PeHp6YmYmBi0bt0a4eHhAACVSoWJEydizpw5cHJygqOjI+bOnSt9BAcAPj4+GDp0KCZNmoQ1a9YAACZPnozQ0FDOMCMiIiIAJg5EFy9exIsvvoj8/Hx06NABvXv3RmpqKtzd3QEA8+bNQ3FxMaZNm4aCggIEBgZiz549sLe3l7axdOlSWFpaYuzYsSguLsaAAQOwceNGWFhYSDVbt27FrFmzpNloYWFhWLlyZdMOloiIiJotkwai+Pj4u65XKBTQarXQarW11tjY2GDFihVYsWJFrTWOjo6Ii4urbzfNll6vx5o1azBlyhS4urqaujtEREQm06yuIZKzvLy8Jt+nXq9HdHQ09Hp9k++biIioOWEgaiZ4p3siIiLTYSAiIiIi2WMgIiIiItljICIiIiLZYyAiIiIi2WMgIiIiItljICIiIiLZYyAiIiIi2WMgIiIiItljICIiIiLZYyAiIiIi2WMgIiIiItljICIiIiLZYyAiIiIi2WMgIiIiItljICIiIiLZYyAiIiIi2WMgIiIiItljICIiIiLZYyAiIiIi2WMgIiIiItljIGrBEhISTN0FIiIis8BA1IIxEBERETUMBiIiIiKSPQYiIiIikj0GIiIiIpI9BiIiIiKSPQYiIiIikj0GIiIiIpI9BiIiIiKSPQYiIiIikj0GIiIiIpI9BiIzkZeXB61Wi7y8PFN3hYiIqMVhIDIT+fn5iI6ORn5+vqm7QkRE1OIwEBEREZHsMRARERGR7DEQERERkewxEBEREZHsMRARERGR7DEQERERkewxEMmAXq+HVquFXq83dVeIiIiaJQYiGdDr9YiOjmYgIiIiqgUDEREREcleswlEsbGxUCgUiIyMlNqEENBqtdBoNLC1tUVISAhOnz5t9LzS0lLMnDkT7du3h52dHcLCwnDx4kWjmoKCAkREREClUkGlUiEiIgKFhYVNMCoiIiJqCZpFIEpLS8PatWvRvXt3o/bFixdjyZIlWLlyJdLS0qBWqzFo0CBcvXpVqomMjERiYiLi4+Nx8OBBXLt2DaGhoaioqJBqwsPDkZGRgaSkJCQlJSEjIwMRERFNNj4iIiJq3kweiK5du4Zx48Zh3bp1aNeundQuhMCyZcswf/58jB49Gr6+vti0aRNu3LiBbdu2AQAMBgPWr1+PTz75BAMHDkSvXr0QFxeHzMxM7N27FwBw9uxZJCUl4fPPP0dQUBCCgoKwbt067Nq1C1lZWSYZMxERETUvJg9E06dPx4gRIzBw4ECj9uzsbOTk5GDw4MFSm1KpRHBwMA4dOgQASE9PR3l5uVGNRqOBr6+vVHP48GGoVCoEBgZKNb1794ZKpZJqalJaWoqioiKjhYiIiMyTpSl3Hh8fj+PHjyMtLa3aupycHACAi4uLUbuLiwvOnz8v1VhbWxudWaqqqXp+Tk4OnJ2dq23f2dlZqqlJbGwsoqOj729ARERE1CKZ7AzRhQsX8MYbbyAuLg42Nja11ikUCqPHQohqbXe6s6am+nttJyoqCgaDQVouXLhw130SERFRy2WyQJSeno7c3Fz4+/vD0tISlpaWOHDgAD799FNYWlpKZ4buPIuTm5srrVOr1SgrK0NBQcFday5dulRt/3l5edXOPt1OqVTCwcHBaCEiIiLzZLJANGDAAGRmZiIjI0NaAgICMG7cOGRkZOChhx6CWq1GcnKy9JyysjIcOHAAffr0AQD4+/vDysrKqEav1+PUqVNSTVBQEAwGA44ePSrVHDlyBAaDQaohIiIieavXNUSvvvoqli9fDnt7e6P269evY+bMmfjiiy/uuQ17e3v4+voatdnZ2cHJyUlqj4yMRExMDDw9PeHp6YmYmBi0bt0a4eHhAACVSoWJEydizpw5cHJygqOjI+bOnQs/Pz/pIm0fHx8MHToUkyZNwpo1awAAkydPRmhoKLy8vOozfCIiIjIz9TpDtGnTJhQXF1drLy4uxubNmx+4U1XmzZuHyMhITJs2DQEBAfjzzz+xZ88eoyC2dOlSjBo1CmPHjkXfvn3RunVr/Pvf/4aFhYVUs3XrVvj5+WHw4MEYPHgwunfvji1btjRYP4mIiKhlu68zREVFRRBCQAiBq1evGl0MXVFRge+//77GGV11tX//fqPHCoUCWq0WWq221ufY2NhgxYoVWLFiRa01jo6OiIuLq3e/iIiIyLzdVyBq27YtFAoFFAoFunbtWm29QqHgVHUiIiJqce4rEKWkpEAIgf79++Obb76Bo6OjtM7a2hru7u7QaDQN3kkiIiKixnRfgSg4OBjArW+R7ty58z2/D4iIiIioJahzIDp58iR8fX3RqlUrGAwGZGZm1lp7501aiYiIiJqzOgeinj17SrfB6NmzJxQKBYQQ1eoUCoXRneaJiIiImrs6B6Ls7Gx06NBB+jcRERGRuahzIHJ3d6/x30REREQtXb1v3bFlyxb07dsXGo1Guvv8smXL8O233zZY5+TkzvuxERERUdOpVyBatWoVZs+ejeHDh6OwsFC6Zqht27ZYtmxZQ/ZPNgoLC03dBSIiItmqVyBasWIF1q1bh/nz5xvdIiMgIOCus8+IiIiImqN6BaLs7Gz06tWrWrtSqcT169cfuFNERERETalegcjDwwMZGRnV2n/44Qd069btQftERERE1KTu65uqq7z11luYPn06SkpKIITA0aNH8eWXXyI2Nhaff/55Q/eRiIiIqFHVKxC98soruHnzJubNm4cbN24gPDwcHTt2xPLly/HCCy80dB+JiIiIGlW9AlFhYSEmTZqESZMmIT8/H5WVlXB2dgYA/P7773jkkUcatJNEREREjale1xANHz4cJSUlAID27dtLYSgrKwshISEN1jkiIiKiplCvQNSuXTuMGjUKN2/elNrOnj2LkJAQPPfccw3WOSIiIqKmUK9A9M033+D69esIDw+HEAKnTp1CSEgIXnzxRSxfvryh+0hERETUqOoViGxsbLBr1y789ttv+Nvf/oYBAwbg5ZdfxpIlSxq6f0RERESNrs4XVRcVFRk9VigU2L59OwYOHIjnnnsO7733nlTj4ODQsL0kIiIiakR1DkRt27aFQqGo1i6EwOrVq7FmzRoIIaBQKKR7mxERERG1BHUORCkpKY3ZDyIiIiKTqXMgCg4Obsx+EBEREZlMvb6Y8eTJkzW2KxQK2NjYoHPnzlAqlQ/UMSIiIqKmUq9A1LNnzxqvJ6piZWWF559/HmvWrIGNjU29O0dERETUFOo17T4xMRGenp5Yu3YtMjIycOLECaxduxZeXl7Ytm0b1q9fj3379uHvf/97Q/eXiIiIqMHV6wzRhx9+iOXLl2PIkCFSW/fu3dGpUye89957OHr0KOzs7DBnzhz885//bLDOEhERETWGep0hyszMhLu7e7V2d3d3ZGZmArj1sZper3+w3hERERE1gXoFIm9vbyxatAhlZWVSW3l5ORYtWgRvb28AwJ9//gkXF5eG6SURERFRI6rXR2b/+te/EBYWhk6dOqF79+5QKBQ4efIkKioqsGvXLgDAH3/8gWnTpjVoZ4mIiIgaQ70CUZ8+fXDu3DnExcXh119/hRACY8aMQXh4OOzt7QEAERERDdpRIiIiosZSr0AEAG3atMHUqVMbsi9EREREJlHnQLRz504MGzYMVlZW2Llz511rw8LCHrhjRERERE2lzoFo1KhRyMnJgbOzM0aNGlVrHW/uSkRERC1NnQNRZWVljf8mIiIiaunqPO3e0dER+fn5AIBXX30VV69ebbROERERETWlOgeisrIyFBUVAQA2bdqEkpKSRusUERERUVOq80dmQUFBGDVqFPz9/SGEwKxZs2Bra1tj7RdffNFgHSQiIiJqbHUORHFxcVi6dCn+97//QaFQwGAw8CwRERERmYU6ByIXFxcsWrQIAODh4YEtW7bAycmp0TpGRERE1FTq9cWM2dnZDd0PIiIiIpOpVyBauHDhXde///779eoMERERkSnUKxAlJiYaPS4vL0d2djYsLS3x8MMPMxARERFRi1KvQHTixIlqbUVFRZgwYQKeffbZB+4UERERUVOq8/cQ3YuDgwMWLlyI9957r87PWbVqFbp37w4HBwc4ODggKCgIP/zwg7ReCAGtVguNRgNbW1uEhITg9OnTRtsoLS3FzJkz0b59e9jZ2SEsLAwXL140qikoKEBERARUKhVUKhUiIiJQWFj4QOMlIiIi89FggQgACgsLYTAY6lzfqVMnLFq0CMeOHcOxY8fQv39/PPPMM1LoWbx4MZYsWYKVK1ciLS0NarUagwYNMvqW7MjISCQmJiI+Ph4HDx7EtWvXEBoaanQ/tfDwcGRkZCApKQlJSUnIyMhAREREww2ciIiIWrR6fWT26aefGj0WQkCv12PLli0YOnRonbczcuRIo8cffvghVq1ahdTUVHTr1g3Lli3D/PnzMXr0aAC3viHbxcUF27Ztw5QpU2AwGLB+/Xps2bIFAwcOBHDr+5Lc3Nywd+9eDBkyBGfPnkVSUhJSU1MRGBgIAFi3bh2CgoKQlZUFLy+v+hwCIiIiMiP1CkRLly41etyqVSt06NAB48ePR1RUVL06UlFRga+//hrXr19HUFAQsrOzkZOTg8GDB0s1SqUSwcHBOHToEKZMmYL09HSUl5cb1Wg0Gvj6+uLQoUMYMmQIDh8+DJVKJYUhAOjduzdUKhUOHTpUayAqLS1FaWmp9LjqtiVERERkfkz+PUSZmZkICgpCSUkJ2rRpg8TERHTr1g2HDh0CcOsLIW/n4uKC8+fPAwBycnJgbW2Ndu3aVavJycmRapydnavt19nZWaqpSWxsLKKjox9obERERNQyNOg1RPXh5eWFjIwMpKam4vXXX8f48eNx5swZab1CoTCqF0JUa7vTnTU11d9rO1FRUTAYDNJy4cKFug6JiIiIWph6nSECgLS0NHz99dfQ6XQoKyszWpeQkFDn7VhbW+ORRx4BAAQEBCAtLQ3Lly/H22+/DeDWGR5XV1epPjc3VzprpFarUVZWhoKCAqOzRLm5uejTp49Uc+nSpWr7zcvLq3b26XZKpRJKpbLO4yAiIqKWq85niD799FPpZq7x8fHo27cvzpw5g8TERJSXl+PMmTPYt28fVCrVA3VICIHS0lJ4eHhArVYjOTlZWldWVoYDBw5IYcff3x9WVlZGNXq9HqdOnZJqgoKCYDAYcPToUanmyJEjMBgMUg0RERHJW53PEC1duhTjxo2DjY0NYmJisHTpUkyfPh329vZYvnw5PDw8MGXKFKOzOffy7rvvYtiwYXBzc8PVq1cRHx+P/fv3IykpCQqFApGRkYiJiYGnpyc8PT0RExOD1q1bIzw8HACgUqkwceJEzJkzB05OTnB0dMTcuXPh5+cnzTrz8fHB0KFDMWnSJKxZswYAMHnyZISGhnKGGREREQG4j0B0+4XU//vf/zB8+HAAtz5aun79OhQKBd58803079+/zhcjX7p0CREREdDr9VCpVOjevTuSkpIwaNAgAMC8efNQXFyMadOmoaCgAIGBgdizZw/s7e2lbSxduhSWlpYYO3YsiouLMWDAAGzcuBEWFhZSzdatWzFr1ixpNlpYWBhWrlxZ16ETERGRmatzIOrfvz8SEhLQtm1btGvXDteuXQMAdOzYEadOnYKfnx8KCwtx48aNOu98/fr1d12vUCig1Wqh1WprrbGxscGKFSuwYsWKWmscHR0RFxdX534RERGRvNQ5EPXo0QNWVlYAgCeffBL79u2Dn58fxo4dizfeeAP79u1DcnIyBgwY0GidJSIiImoM93UNUZVPP/0UxcXFAG5NT7eyssLBgwcxevTo+7qXGREREVFzcF/T7qu+rdnGxgY2NjbS46lTp2Lq1KkN3zsiIiKiJnBfgaht27b3/FJEAEY3ViUiIiJq7u4rEKWkpEj/FkJg+PDh+Pzzz9GxY8cG7xgRERFRU7mvQBQcHGz02MLCAr1798ZDDz3UoJ0iIiIiakomv5cZERERkakxEBEREZHsPXAgqstF1kRERETN2X1dQzR69GijxyUlJZg6dSrs7OyM2u/nbvdEREREpnZfgejOO9m/9NJLDdoZIiIiIlO4r0C0YcOGxuqH7BUWFpq6C0RERLLFi6qbAZ1Oh2XLl5u6G0RERLLFQNQM5Ofno+LmTVN3g4iISLYYiIiIiEj2GIiIiIhI9hiIiIiISPYYiIiIiEj2GIiIiIhI9hiIiIiISPYYiIiIiEj2GIiIiIhI9hiIiIiISPYYiIiIiEj2GIiIiIhI9hiIiIiISPYYiIiIiEj2GIjIJPR6PbRaLfR6vam7QkRExEBEpqHX6xEdHc1AREREzQIDEREREckeAxERERHJHgMRERERyR4DEREREckeAxERERHJHgMRERERyR4DEREREckeAxERERHJHgMRERERyR4DEREREckeAxERERHJHgMRERERyR4DEREREckeAxERERHJHgMRERERyZ5JA1FsbCwef/xx2Nvbw9nZGaNGjUJWVpZRjRACWq0WGo0Gtra2CAkJwenTp41qSktLMXPmTLRv3x52dnYICwvDxYsXjWoKCgoQEREBlUoFlUqFiIgIFBYWNvYQiYiIqAUwaSA6cOAApk+fjtTUVCQnJ+PmzZsYPHgwrl+/LtUsXrwYS5YswcqVK5GWlga1Wo1Bgwbh6tWrUk1kZCQSExMRHx+PgwcP4tq1awgNDUVFRYVUEx4ejoyMDCQlJSEpKQkZGRmIiIho0vESERFR82Rpyp0nJSUZPd6wYQOcnZ2Rnp6Op59+GkIILFu2DPPnz8fo0aMBAJs2bYKLiwu2bduGKVOmwGAwYP369diyZQsGDhwIAIiLi4Obmxv27t2LIUOG4OzZs0hKSkJqaioCAwMBAOvWrUNQUBCysrLg5eXVtAMnIiKiZqVZXUNkMBgAAI6OjgCA7Oxs5OTkYPDgwVKNUqlEcHAwDh06BABIT09HeXm5UY1Go4Gvr69Uc/jwYahUKikMAUDv3r2hUqmkmjuVlpaiqKjIaCEiIiLz1GwCkRACs2fPxpNPPglfX18AQE5ODgDAxcXFqNbFxUVal5OTA2tra7Rr1+6uNc7OztX26ezsLNXcKTY2VrreSKVSwc3N7cEGSERERM1WswlEM2bMwMmTJ/Hll19WW6dQKIweCyGqtd3pzpqa6u+2naioKBgMBmm5cOFCXYZBRERELVCzCEQzZ87Ezp07kZKSgk6dOkntarUaAKqdxcnNzZXOGqnVapSVlaGgoOCuNZcuXaq237y8vGpnn6oolUo4ODgYLURERGSeTBqIhBCYMWMGEhISsG/fPnh4eBit9/DwgFqtRnJystRWVlaGAwcOoE+fPgAAf39/WFlZGdXo9XqcOnVKqgkKCoLBYMDRo0elmiNHjsBgMEg1REREJF8mnWU2ffp0bNu2Dd9++y3s7e2lM0EqlQq2trZQKBSIjIxETEwMPD094enpiZiYGLRu3Rrh4eFS7cSJEzFnzhw4OTnB0dERc+fOhZ+fnzTrzMfHB0OHDsWkSZOwZs0aAMDkyZMRGhrKGWZERERk2kC0atUqAEBISIhR+4YNGzBhwgQAwLx581BcXIxp06ahoKAAgYGB2LNnD+zt7aX6pUuXwtLSEmPHjkVxcTEGDBiAjRs3wsLCQqrZunUrZs2aJc1GCwsLw8qVKxt3gERERNQimDQQCSHuWaNQKKDVaqHVamutsbGxwYoVK7BixYpaaxwdHREXF1efbhIREZGZaxYXVRMRERGZEgMRERERyR4DEREREckeAxERERHJHgMRERERyR4DEREREckeA5GZSEhIMHUXiIiIWiwGIjPBQERERFR/DEREREQkewxEREREJHsMRERERCR7DEREREQkewxEREREJHsMRERERCR7DEREREQkewxEREREJHsMRERERCR7DEREREQkewxEZoa38CAiIrp/DERmhoGIiIjo/jEQUZ3odDrodDpTd4OIiKhRMBDRPel0Onh5+8DL24ehiIiIzBIDkRnLy8uDVqtFXl7eA20nPz8fJcU3UFJ8A/n5+Q3UOyIiouaDgciM5efnIzo6miGGiIjoHhiIiIiISPYYiIiIiEj2GIiIiIhI9hiIiIiISPYYiIiIiEj2GIiIiIhI9hiIiIiISPYYiIiIiEj2GIiagQf9JmkiIiJ6MAxEzQC/SZqIiMi0GIiIiIhI9hiIiIiISPYYiIiIiEj2GIiIiIhI9hiIZESv10On05m6G0RERM0OA5GMjH5uDLy8fRiKiIiI7sBAJCNlpSUoKb7Baf5ERER3YCAiIiIi2WMgIiIiItljICIiIiLZM2kg+s9//oORI0dCo9FAoVBgx44dRuuFENBqtdBoNLC1tUVISAhOnz5tVFNaWoqZM2eiffv2sLOzQ1hYGC5evGhUU1BQgIiICKhUKqhUKkRERKCwsLCRR0dEREQthUkD0fXr19GjRw+sXLmyxvWLFy/GkiVLsHLlSqSlpUGtVmPQoEG4evWqVBMZGYnExETEx8fj4MGDuHbtGkJDQ1FRUSHVhIeHIyMjA0lJSUhKSkJGRgYiIiIafXwtlV6vh1arhV6vN3VXiIiImoSlKXc+bNgwDBs2rMZ1QggsW7YM8+fPx+jRowEAmzZtgouLC7Zt24YpU6bAYDBg/fr12LJlCwYOHAgAiIuLg5ubG/bu3YshQ4bg7NmzSEpKQmpqKgIDAwEA69atQ1BQELKysuDl5dU0g21B9Ho9oqOjERYWBldXV1N3h4iIqNE122uIsrOzkZOTg8GDB0ttSqUSwcHBOHToEAAgPT0d5eXlRjUajQa+vr5SzeHDh6FSqaQwBAC9e/eGSqWSaoiIiEjeTHqG6G5ycnIAAC4uLkbtLi4uOH/+vFRjbW2Ndu3aVaupen5OTg6cnZ2rbd/Z2VmqqUlpaSlKS0ulx0VFRfUbCBERETV7zfYMURWFQmH0WAhRre1Od9bUVH+v7cTGxkoXYatUKri5ud1nz4mIiKilaLaBSK1WA0C1szi5ubnSWSO1Wo2ysjIUFBTctebSpUvVtp+Xl1ft7NPtoqKiYDAYpOXChQsPNB4iIiJqvpptIPLw8IBarUZycrLUVlZWhgMHDqBPnz4AAH9/f1hZWRnV6PV6nDp1SqoJCgqCwWDA0aNHpZojR47AYDBINTVRKpVwcHAwWoiIiMg8mfQaomvXruH333+XHmdnZyMjIwOOjo7o3LkzIiMjERMTA09PT3h6eiImJgatW7dGeHg4AEClUmHixImYM2cOnJyc4OjoiLlz58LPz0+adebj44OhQ4di0qRJWLNmDQBg8uTJCA0N5QwzIiIiAmDiQHTs2DH069dPejx79mwAwPjx47Fx40bMmzcPxcXFmDZtGgoKChAYGIg9e/bA3t5ees7SpUthaWmJsWPHori4GAMGDMDGjRthYWEh1WzduhWzZs2SZqOFhYXV+t1HREREJD8mDUQhISEQQtS6XqFQQKvVQqvV1lpjY2ODFStWYMWKFbXWODo6Ii4u7kG6SkRERGas2V5DRI1nzZo1/BZqIiKi2zAQmbH8/Pwa29euXctAREREdBsGIjM29615AGoPRkRERHQLA5EZu1leBgBGN8MlIiKi6hiIqN50Oh10Op2pu0FERPTAGIhkYN++fQ2+TZ1OBy9vH3h5+zAUERFRi8dAJAMpKSkNvs38/HyUFN9ASfENXqNEREQtHgMRERERyR4DEREREckeAxERERHJHgMRERERyR4DERnR6XT8FmsiIpIdk97clZqXqqn0lZWVpu4KERFRk2IgIknVVHoiIiK54UdmREREJHsMRNQgeBsPIiJqyfiRmUw15IXTer0efZ98CgCQ9ctZdO7cucG2TURE1BQYiGRq9HNjGmxbhYWF0rVH+fn5DERERNTiMBDJVFlpiam7QERE1GzwGiIiIiKSPQYiIiIikj0GIiIiIpI9BiIiIiKSPQYikvAeZkREJFcMRATg1hcr3jkVPy8vD1qtFnl5eSbqFRERUdNgICIAt74/6M6p+Pn5+YiOjkZ+fr6JekVERNQ0GIjovul0On68RkREZoVfzEj3FW6qbtNRWVlZ63qdTsdvqyYiohaFgYju6zYet9+mo7ZttWrVivc0IyKiFoUfmRHKSksa7FYeZaUlKCm+weuOiIioRWEgIiIiItljICIiIiLZYyAiIiIi2WMgIiIiItljICIiIiLZYyCiWhUUFBj9l4iIyFwxEFGtCgsLjf57P9asWcNvsyYiohaDgagZMMfv7Fm7di0DERERtRgMRCam0+kw9615pu5Gjfbt21etLSEhwQQ9ISIialwMRCaWn5+Pm+Vlpu5GjVJSUqq11RSImjok6fV6aLXaep+B0ul00Ol0DdwrIiJqyRiI6IHVFoga8jqi20OQXq9HdHR0vbat0+ng5e0DL28fhiIiIpIwEFGjacjriO4Vgup61ig/Px8lxTd4vzUiIjLCQET3VJ9ZZk3tQc4aERERMRDRPS1ZsrTez/3kk0+QlpZW7+dXnfnJy8u77+fyWiEiIqorWQWizz77DB4eHrCxsYG/vz9++uknU3epRRCist7P3fbll3jyqafrFUx0Oh2OHz+O6Ojo+/54qzleK/SgF4MTEVHjkU0g2r59OyIjIzF//nycOHECTz31FIYNG9Zs/liaLSFQVlqCAwcO1PkpOp0OiYmJ6OrljdHPjanXbhviWqGGPsPEj/WIiJov2QSiJUuWYOLEiXjttdfg4+ODZcuWwc3NDatWrTJ112Rh/PgJ+Pe//33POp1Oh65dvTB69HMoLSlGWWlJrbV5eXkNesbl9jM4tZ1hurOGgZqIyDzIIhCVlZUhPT0dgwcPNmofPHgwDh06ZKJeyYuAwOjnxuDw4cM1rtfpdDh8+DASEhJQWloCQNRYVzXtHgB++eWXBjnjUhVsbj+Dc+cZpjtrkpKS0NXL2ygwNWRAqtrWvbbZGB/D1bRPhj8iMneWpu5AU8jPz0dFRQVcXFyM2l1cXJCTk1Pjc0pLS1FaWio9NhgMAICioqIG7du1a9cadHvNlhC4WV6Op55+Gqs++wytWt3K4sePH0d2djYixk9A8fXrtT793XffBQCMfeFFQNwKS29H3Wp7++23MXToUGl7Op0OX3zxhfTct99+G46OjnjxxRdx+fJlqf348eNIT0/HjFlvwMrKCu//fT4AQKvVIjg4WKr75ptv8M8lS41qXp8+A6UlxQCAr776CkePHsUPu/dAAQU2fPF5tfcaAGRlZUn7vXHjRo3jzM/Px7Zt2/DD7j0QlQJQKNBKcWubFhYW+Pbbb/HUU0/hp59+wjPPPIPLly8jOjoanTp1gre3N/Lz8/Htt9/imWeeQfv27Y22W1P7nS5duoRXJr4GCEjjqKntftR133V97oNsj4iaL2dnZ6jV6gbfbtXfbSFq/h9tiZCBP//8UwAQhw4dMmr/4IMPhJeXV43PWbBggcCt0xRcuHDhwoULlxa+XLhw4a5ZQRZniNq3bw8LC4tqZ4Nyc3Nr/b/dqKgozJ49W3pcWVmJK1euwMnJCQqFosH6VlRUBDc3N1y4cAEODg4Ntt3mTo7jluOYAXmOW45jBuQ5bjmOGWhZ4xZC4OrVq9BoNHetk0Ugsra2hr+/P5KTk/Hss89K7cnJyXjmmWdqfI5SqYRSqTRqa9u2baP10cHBodm/qRqDHMctxzED8hy3HMcMyHPcchwz0HLGrVKp7lkji0AEALNnz0ZERAQCAgIQFBSEtWvXQqfTYerUqabuGhEREZmYbALR888/j8uXL2PhwoXQ6/Xw9fXF999/D3d3d1N3jYiIiExMNoEIAKZNm4Zp06aZuhtGlEolFixYUO3jOXMnx3HLccyAPMctxzED8hy3HMcMmOe4FULcax4aERERkXmTxRczEhEREd0NAxERERHJHgMRERERyR4DEREREckeA5GJffbZZ/Dw8ICNjQ38/f3x008/mbpL9faf//wHI0eOhEajgUKhwI4dO4zWCyGg1Wqh0Whga2uLkJAQnD592qimtLQUM2fORPv27WFnZ4ewsDBcvHixCUdxf2JjY/H444/D3t4ezs7OGDVqlHTPsirmNu5Vq1ahe/fu0heyBQUF4YcffpDWm9t4axMbGwuFQoHIyEipzdzGrtVqoVAojJbb7zVlbuO93Z9//omXXnoJTk5OaN26NXr27In09HRpvTmOvUuXLtVeb4VCgenTpwMwzzEbecDbhNEDiI+PF1ZWVmLdunXizJkz4o033hB2dnbi/Pnzpu5avXz//fdi/vz54ptvvhEARGJiotH6RYsWCXt7e/HNN9+IzMxM8fzzzwtXV1dRVFQk1UydOlV07NhRJCcni+PHj4t+/fqJHj16iJs3bzbxaOpmyJAhYsOGDeLUqVMiIyNDjBgxQnTu3Flcu3ZNqjG3ce/cuVN89913IisrS2RlZYl3331XWFlZiVOnTgkhzG+8NTl69Kjo0qWL6N69u3jjjTekdnMb+4IFC8Sjjz4q9Hq9tOTm5krrzW28Va5cuSLc3d3FhAkTxJEjR0R2drbYu3ev+P3336Uacxx7bm6u0WudnJwsAIiUlBQhhHmO+XYMRCb0xBNPiKlTpxq1eXt7i3feecdEPWo4dwaiyspKoVarxaJFi6S2kpISoVKpxOrVq4UQQhQWFgorKysRHx8v1fz555+iVatWIikpqcn6/iByc3MFAHHgwAEhhHzG3a5dO/H555/LYrxXr14Vnp6eIjk5WQQHB0uByBzHvmDBAtGjR48a15njeKu8/fbb4sknn6x1vTmP/XZvvPGGePjhh0VlZaUsxsyPzEykrKwM6enpGDx4sFH74MGDcejQIRP1qvFkZ2cjJyfHaLxKpRLBwcHSeNPT01FeXm5Uo9Fo4Ovr22KOicFgAAA4OjoCMP9xV1RUID4+HtevX0dQUJDZjxcApk+fjhEjRmDgwIFG7eY69t9++w0ajQYeHh544YUX8McffwAw3/ECwM6dOxEQEIC//e1vcHZ2Rq9evbBu3TppvTmPvUpZWRni4uLw6quvQqFQyGLMDEQmkp+fj4qKCri4uBi1u7i4ICcnx0S9ajxVY7rbeHNycmBtbY127drVWtOcCSEwe/ZsPPnkk/D19QVgvuPOzMxEmzZtoFQqMXXqVCQmJqJbt25mO94q8fHxOH78OGJjY6utM8exBwYGYvPmzdi9ezfWrVuHnJwc9OnTB5cvXzbL8Vb5448/sGrVKnh6emL37t2YOnUqZs2ahc2bNwMwz9f6Tjt27EBhYSEmTJgAQB5jltWtO5ojhUJh9FgIUa3NnNRnvC3lmMyYMQMnT57EwYMHq60zt3F7eXkhIyMDhYWF+OabbzB+/HgcOHBAWm9u4wWACxcu4I033sCePXtgY2NTa505jX3YsGHSv/38/BAUFISHH34YmzZtQu/evQGY13irVFZWIiAgADExMQCAXr164fTp01i1ahVefvllqc4cx15l/fr1GDZsGDQajVG7OY+ZZ4hMpH379rCwsKiWmnNzc6slcHNQNTPlbuNVq9UoKytDQUFBrTXN1cyZM7Fz506kpKSgU6dOUru5jtva2hqPPPIIAgICEBsbix49emD58uVmO17g1scBubm58Pf3h6WlJSwtLXHgwAF8+umnsLS0lPpujmOvYmdnBz8/P/z2229m/Vq7urqiW7duRm0+Pj7Q6XQAzPfnusr58+exd+9evPbaa1KbuY8ZYCAyGWtra/j7+yM5OdmoPTk5GX369DFRrxqPh4cH1Gq10XjLyspw4MABabz+/v6wsrIyqtHr9Th16lSzPSZCCMyYMQMJCQnYt28fPDw8jNab67jvJIRAaWmpWY93wIAByMzMREZGhrQEBARg3LhxyMjIwEMPPWS2Y69SWlqKs2fPwtXV1axf6759+1b7+oxff/0V7u7uAMz/53rDhg1wdnbGiBEjpDZzHzMATrs3papp9+vXrxdnzpwRkZGRws7OTpw7d87UXauXq1evihMnTogTJ04IAGLJkiXixIkT0tcILFq0SKhUKpGQkCAyMzPFiy++WOOUzU6dOom9e/eK48ePi/79+zfrKZuvv/66UKlUYv/+/UbTVW/cuCHVmNu4o6KixH/+8x+RnZ0tTp48Kd59913RqlUrsWfPHiGE+Y33bm6fZSaE+Y19zpw5Yv/+/eKPP/4QqampIjQ0VNjb20u/o8xtvFWOHj0qLC0txYcffih+++03sXXrVtG6dWsRFxcn1Zjr2CsqKkTnzp3F22+/XW2duY65CgORif3rX/8S7u7uwtraWjz22GPSdO2WKCUlRQCotowfP14IcWuq6oIFC4RarRZKpVI8/fTTIjMz02gbxcXFYsaMGcLR0VHY2tqK0NBQodPpTDCauqlpvADEhg0bpBpzG/err74qvWc7dOggBgwYIIUhIcxvvHdzZyAyt7FXfc+MlZWV0Gg0YvTo0eL06dPSenMb7+3+/e9/C19fX6FUKoW3t7dYu3at0XpzHfvu3bsFAJGVlVVtnbmOuYpCCCFMcmqKiIiIqJngNUREREQkewxEREREJHsMRERERCR7DEREREQkewxEREREJHsMRERERCR7DEREREQkewxEREREJHsMRERkFlavXg17e3vcvHlTart27RqsrKzw1FNPGdX+9NNPUCgU+PXXX+u1rwkTJmDUqFEP0l0iamYYiIjILPTr1w/Xrl3DsWPHpLaffvoJarUaaWlpuHHjhtS+f/9+aDQadO3a9b72UVFRgcrKygbrMxE1HwxERGQWvLy8oNFosH//fqlt//79eOaZZ/Dwww/j0KFDRu39+vVDWVkZ5s2bh44dO8LOzg6BgYFGz9+4cSPatm2LXbt2oVu3blAqlXjllVewadMmfPvtt1AoFFAoFEbPIaKWydLUHSAiaighISFISUnBO++8AwBISUnBvHnzUFlZiZSUFAwcOBBlZWU4fPgwVqxYgVdeeQXnzp1DfHw8NBoNEhMTMXToUGRmZsLT0xMAcOPGDcTGxuLzzz+Hk5MT1Go1SkpKUFRUhA0bNgAAHB0dTTZmImoYDEREZDZCQkLw5ptv4ubNmyguLsaJEyfw9NNPo6KiAp9++ikAIDU1FcXFxQgJCcGkSZNw8eJFaDQaAMDcuXORlJSEDRs2ICYmBgBQXl6Ozz77DD169JD2Y2tri9LSUqjV6qYfJBE1CgYiIjIb/fr1w/Xr15GWloaCggJ07doVzs7OCA4ORkREBK5fv479+/ejc+fOOH78OIQQ1a4jKi0thZOTk/TY2toa3bt3b+qhEFETYyAiIrPxyCOPoFOnTkhJSUFBQQGCg4MBAGq1Gh4eHvjvf/+LlJQU9O/fH5WVlbCwsEB6ejosLCyMttOmTRvp37a2tlAoFE06DiJqegxERGRW+vXrh/3796OgoABvvfWW1B4cHIzdu3cjNTUVr7zyCnr16oWKigrk5uZWm5Z/L9bW1qioqGjorhORCXGWGRGZlX79+uHgwYPIyMiQzhABtwLRunXrUFJSgn79+qFr164YN24cXn75ZSQkJCA7OxtpaWn46KOP8P333991H126dMHJkyeRlZWF/Px8lJeXN/awiKiRMRARkVnp168fiouL8cgjj8DFxUVqDw4OxtWrV/Hwww/Dzc0NALBhwwa8/PLLmDNnDry8vBAWFoYjR45I62szadIkeHl5ISAgAB06dMB///vfRh0TETU+hRBCmLoTRERERKbEM0REREQkewxEREREJHsMRERERCR7DEREREQkewxEREREJHsMRERERCR7DEREREQkewxEREREJHsMRERERCR7DEREREQkewxEREREJHsMRERERCR7/w9F+HcVzbeYhwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    " plot_histogram(english_df, 'kompression')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/niclascramer/opt/miniconda3/envs/torch/lib/python3.9/site-packages/transformers/models/t5/tokenization_t5_fast.py:156: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-large automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_checkpoint = \"t5-large\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset amazon_reviews_multi (/Users/niclascramer/.cache/huggingface/datasets/amazon_reviews_multi/es/1.0.0/724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab9f1cbae3f34060901d04493d80854e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset amazon_reviews_multi (/Users/niclascramer/.cache/huggingface/datasets/amazon_reviews_multi/en/1.0.0/724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "937af75ea45b4260812f7ef363523a31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "home                      17679\n",
       "apparel                   15951\n",
       "wireless                  15717\n",
       "other                     13418\n",
       "beauty                    12091\n",
       "drugstore                 11730\n",
       "kitchen                   10382\n",
       "toy                        8745\n",
       "sports                     8277\n",
       "automotive                 7506\n",
       "lawn_and_garden            7327\n",
       "home_improvement           7136\n",
       "pet_products               7082\n",
       "digital_ebook_purchase     6749\n",
       "pc                         6401\n",
       "electronics                6186\n",
       "office_product             5521\n",
       "shoes                      5197\n",
       "grocery                    4730\n",
       "book                       3756\n",
       "Name: product_category, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "spanish_dataset = load_dataset(\"amazon_reviews_multi\", \"es\")\n",
    "english_dataset = load_dataset(\"amazon_reviews_multi\", \"en\")\n",
    "\n",
    "\n",
    "english_dataset.set_format(\"pandas\")\n",
    "english_df = english_dataset[\"train\"][:]\n",
    "# Show counts for top 20 products\n",
    "english_df[\"product_category\"].value_counts()[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_books(example):\n",
    "    return (\n",
    "        example[\"product_category\"] == \"book\"\n",
    "        or example[\"product_category\"] == \"digital_ebook_purchase\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /Users/niclascramer/.cache/huggingface/datasets/amazon_reviews_multi/en/1.0.0/724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609/cache-1f8a8639b644779a.arrow\n",
      "Loading cached processed dataset at /Users/niclascramer/.cache/huggingface/datasets/amazon_reviews_multi/en/1.0.0/724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609/cache-e24d64f51478b699.arrow\n",
      "Loading cached processed dataset at /Users/niclascramer/.cache/huggingface/datasets/amazon_reviews_multi/en/1.0.0/724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609/cache-be78948bbd5c9f80.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc4d6181475248aabba0fe07a1211c8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Flattening the indices:   0%|          | 0/11 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Row Number: 789\n",
      "'>> Title: I'm dissapointed.'\n",
      "'>> Review: I guess I had higher expectations for this book from the reviews. I really thought I'd at least like it. The plot idea was great. I loved Ash but, it just didnt go anywhere. Most of the book was about their radio show and talking to callers. I wanted the author to dig deeper so we could really get to know the characters. All we know about Grace is that she is attractive looking, Latino and is kind of a brat. I'm dissapointed.'\n",
      "\n",
      "Row Number: 4776\n",
      "'>> Title: Good art, good price, poor design'\n",
      "'>> Review: I had gotten the DC Vintage calendar the past two years, but it was on backorder forever this year and I saw they had shrunk the dimensions for no good reason. This one has good art choices but the design has the fold going through the picture, so it's less aesthetically pleasing, especially if you want to keep a picture to hang. For the price, a good calendar'\n",
      "\n",
      "Row Number: 10320\n",
      "'>> Title: Helpful'\n",
      "'>> Review: Nearly all the tips useful and. I consider myself an intermediate to advanced user of OneNote. I would highly recommend.'\n"
     ]
    }
   ],
   "source": [
    "english_dataset.reset_format()\n",
    "english_books = english_dataset.filter(filter_books)\n",
    "show_samples(english_books)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_input_length = 512\n",
    "max_target_length = 30\n",
    "\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    model_inputs = tokenizer(\n",
    "        examples[\"review_body\"],\n",
    "        max_length=max_input_length,\n",
    "        truncation=True,\n",
    "    )\n",
    "    labels = tokenizer(\n",
    "        examples[\"review_title\"], max_length=max_target_length, truncation=True\n",
    "    )\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /Users/niclascramer/.cache/huggingface/datasets/amazon_reviews_multi/en/1.0.0/724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609/cache-d9be55edb2f6380e.arrow\n",
      "Loading cached processed dataset at /Users/niclascramer/.cache/huggingface/datasets/amazon_reviews_multi/en/1.0.0/724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609/cache-8a909fb6470b3bc1.arrow\n",
      "Loading cached processed dataset at /Users/niclascramer/.cache/huggingface/datasets/amazon_reviews_multi/en/1.0.0/724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609/cache-ab7f469c8f0781ae.arrow\n"
     ]
    }
   ],
   "source": [
    "tokenized_datasets = english_books.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "rouge_score = evaluate.load(\"rouge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_summary = \"I absolutely loved reading the Hunger Games\"\n",
    "reference_summary = \"I loved reading the Hunger Games\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "rouge_score = evaluate.load(\"rouge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': 0.923076923076923,\n",
       " 'rouge2': 0.7272727272727272,\n",
       " 'rougeL': 0.923076923076923,\n",
       " 'rougeLsum': 0.923076923076923}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = rouge_score.compute(\n",
    "    predictions=[generated_summary], references=[reference_summary]\n",
    ")\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.923076923076923"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores[\"rouge1\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/niclascramer/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I ordered this book on February 11.\n",
      "It never arrived.\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "\n",
    "def three_sentence_summary(text):\n",
    "    return \"\\n\".join(sent_tokenize(text)[:3])\n",
    "\n",
    "\n",
    "print(three_sentence_summary(english_books[\"train\"][1][\"review_body\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_baseline(dataset, metric):\n",
    "    summaries = [three_sentence_summary(text) for text in dataset[\"review_body\"]]\n",
    "    return metric.compute(predictions=summaries, references=dataset[\"review_title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/niclascramer/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': 10.37, 'rouge2': 5.26, 'rougeL': 9.77, 'rougeLsum': 10.03}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "score = evaluate_baseline(english_books[\"validation\"], rouge_score)\n",
    "rouge_names = [\"rouge1\", \"rouge2\", \"rougeL\", \"rougeLsum\"]\n",
    "rouge_dict = dict((rn, round(score[rn] * 100, 2)) for rn in rouge_names)\n",
    "rouge_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2e0ee53a3654f2ab77781fae91e0077",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainingArguments\n",
    "\n",
    "batch_size = 8\n",
    "num_train_epochs = 8\n",
    "# Show the training loss with every epoch\n",
    "logging_steps = len(tokenized_datasets[\"train\"]) // batch_size\n",
    "model_name = model_checkpoint.split(\"/\")[-1]\n",
    "\n",
    "args = Seq2SeqTrainingArguments(\n",
    "    output_dir=f\"{model_name}-finetuned-amazon-test_2\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=5.6e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=num_train_epochs,\n",
    "    predict_with_generate=True,\n",
    "    logging_steps=logging_steps,\n",
    "    push_to_hub=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    # Decode generated summaries into text\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    # Replace -100 in the labels as we can't decode them\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    # Decode reference summaries into text\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    # ROUGE expects a newline after each sentence\n",
    "    decoded_preds = [\"\\n\".join(sent_tokenize(pred.strip())) for pred in decoded_preds]\n",
    "    decoded_labels = [\"\\n\".join(sent_tokenize(label.strip())) for label in decoded_labels]\n",
    "    # Compute ROUGE scores\n",
    "    result = rouge_score.compute(\n",
    "        predictions=decoded_preds, references=decoded_labels, use_stemmer=True\n",
    "    )\n",
    "    # Extract the median scores\n",
    "    result = {key: value.mean() * 100 for key, value in result.items()}\n",
    "    return {k: round(v, 4) for k, v in result.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets  = tokenized_datasets.remove_columns(\n",
    "    english_books[\"train\"].column_names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 3059,  4779,  6833,    65,   349,    38,     8,   167, 19930,   120,\n",
       "           147, 25444,  4346,     5,  1203,    27,  6220,     8,  2291,    19,\n",
       "             3,     9, 24556,     5, 20510,  9412,     5,     1],\n",
       "        [   27,  5563,    48,   484,    30,  2083,  7806,    94,   470,  4363,\n",
       "             5,     1,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0]]), 'labels': tensor([[  499,  8581,    48,   484,  3290,    22,    17,   414,     1],\n",
       "        [25629,    12,  1299,   484,     1,  -100,  -100,  -100,  -100]]), 'decoder_input_ids': tensor([[    0,   499,  8581,    48,   484,  3290,    22,    17,   414],\n",
       "        [    0, 25629,    12,  1299,   484,     1,     0,     0,     0]])}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = [tokenized_datasets[\"train\"][i] for i in range(2)]\n",
    "data_collator(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/niclascramer/opt/miniconda3/envs/torch/lib/python3.9/site-packages/huggingface_hub/repository.py:725: FutureWarning: Creating a repository through 'clone_from' is deprecated and will be removed in v0.12. Please create the repository first using `create_repo(..., exists_ok=True)`.\n",
      "  warnings.warn(\n",
      "Cloning https://huggingface.co/NICFRU/t5-large-finetuned-amazon-test_2 into local empty directory.\n",
      "WARNING:huggingface_hub.repository:Cloning https://huggingface.co/NICFRU/t5-large-finetuned-amazon-test_2 into local empty directory.\n"
     ]
    }
   ],
   "source": [
    "from transformers import Seq2SeqTrainer\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/niclascramer/opt/miniconda3/envs/torch/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 10505\n",
      "  Num Epochs = 8\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 10512\n",
      "  Number of trainable parameters = 737668096\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f427607e5ce0465d91567383d9e177c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10512 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[64], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtransformers\u001b[39;00m \u001b[39mimport\u001b[39;00m Trainer\n\u001b[0;32m----> 2\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain()\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/torch/lib/python3.9/site-packages/transformers/trainer.py:1501\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_wrapped \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\n\u001b[1;32m   1498\u001b[0m inner_training_loop \u001b[39m=\u001b[39m find_executable_batch_size(\n\u001b[1;32m   1499\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inner_training_loop, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_train_batch_size, args\u001b[39m.\u001b[39mauto_find_batch_size\n\u001b[1;32m   1500\u001b[0m )\n\u001b[0;32m-> 1501\u001b[0m \u001b[39mreturn\u001b[39;00m inner_training_loop(\n\u001b[1;32m   1502\u001b[0m     args\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m   1503\u001b[0m     resume_from_checkpoint\u001b[39m=\u001b[39;49mresume_from_checkpoint,\n\u001b[1;32m   1504\u001b[0m     trial\u001b[39m=\u001b[39;49mtrial,\n\u001b[1;32m   1505\u001b[0m     ignore_keys_for_eval\u001b[39m=\u001b[39;49mignore_keys_for_eval,\n\u001b[1;32m   1506\u001b[0m )\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/torch/lib/python3.9/site-packages/transformers/trainer.py:1749\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1747\u001b[0m         tr_loss_step \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining_step(model, inputs)\n\u001b[1;32m   1748\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1749\u001b[0m     tr_loss_step \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining_step(model, inputs)\n\u001b[1;32m   1751\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   1752\u001b[0m     args\u001b[39m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   1753\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[1;32m   1754\u001b[0m     \u001b[39mand\u001b[39;00m (torch\u001b[39m.\u001b[39misnan(tr_loss_step) \u001b[39mor\u001b[39;00m torch\u001b[39m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   1755\u001b[0m ):\n\u001b[1;32m   1756\u001b[0m     \u001b[39m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   1757\u001b[0m     tr_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m tr_loss \u001b[39m/\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mglobal_step \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/torch/lib/python3.9/site-packages/transformers/trainer.py:2508\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2505\u001b[0m     \u001b[39mreturn\u001b[39;00m loss_mb\u001b[39m.\u001b[39mreduce_mean()\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m   2507\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 2508\u001b[0m     loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompute_loss(model, inputs)\n\u001b[1;32m   2510\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mn_gpu \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   2511\u001b[0m     loss \u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mmean()  \u001b[39m# mean() to average on multi-gpu parallel training\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/torch/lib/python3.9/site-packages/transformers/trainer.py:2540\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   2538\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2539\u001b[0m     labels \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 2540\u001b[0m outputs \u001b[39m=\u001b[39m model(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49minputs)\n\u001b[1;32m   2541\u001b[0m \u001b[39m# Save past state if it exists\u001b[39;00m\n\u001b[1;32m   2542\u001b[0m \u001b[39m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[1;32m   2543\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mpast_index \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py:1482\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1477\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1478\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1479\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1480\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1481\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1482\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1483\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1484\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/torch/lib/python3.9/site-packages/transformers/models/t5/modeling_t5.py:1611\u001b[0m, in \u001b[0;36mT5ForConditionalGeneration.forward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1608\u001b[0m \u001b[39m# Encode if needed (training, first prediction pass)\u001b[39;00m\n\u001b[1;32m   1609\u001b[0m \u001b[39mif\u001b[39;00m encoder_outputs \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1610\u001b[0m     \u001b[39m# Convert encoder inputs in embeddings if needed\u001b[39;00m\n\u001b[0;32m-> 1611\u001b[0m     encoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(\n\u001b[1;32m   1612\u001b[0m         input_ids\u001b[39m=\u001b[39;49minput_ids,\n\u001b[1;32m   1613\u001b[0m         attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m   1614\u001b[0m         inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[1;32m   1615\u001b[0m         head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m   1616\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1617\u001b[0m         output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   1618\u001b[0m         return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m   1619\u001b[0m     )\n\u001b[1;32m   1620\u001b[0m \u001b[39melif\u001b[39;00m return_dict \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(encoder_outputs, BaseModelOutput):\n\u001b[1;32m   1621\u001b[0m     encoder_outputs \u001b[39m=\u001b[39m BaseModelOutput(\n\u001b[1;32m   1622\u001b[0m         last_hidden_state\u001b[39m=\u001b[39mencoder_outputs[\u001b[39m0\u001b[39m],\n\u001b[1;32m   1623\u001b[0m         hidden_states\u001b[39m=\u001b[39mencoder_outputs[\u001b[39m1\u001b[39m] \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(encoder_outputs) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1624\u001b[0m         attentions\u001b[39m=\u001b[39mencoder_outputs[\u001b[39m2\u001b[39m] \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(encoder_outputs) \u001b[39m>\u001b[39m \u001b[39m2\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1625\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py:1482\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1477\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1478\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1479\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1480\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1481\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1482\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1483\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1484\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/torch/lib/python3.9/site-packages/transformers/models/t5/modeling_t5.py:1040\u001b[0m, in \u001b[0;36mT5Stack.forward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1027\u001b[0m     layer_outputs \u001b[39m=\u001b[39m checkpoint(\n\u001b[1;32m   1028\u001b[0m         create_custom_forward(layer_module),\n\u001b[1;32m   1029\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1037\u001b[0m         \u001b[39mNone\u001b[39;00m,  \u001b[39m# past_key_value is always None with gradient checkpointing\u001b[39;00m\n\u001b[1;32m   1038\u001b[0m     )\n\u001b[1;32m   1039\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1040\u001b[0m     layer_outputs \u001b[39m=\u001b[39m layer_module(\n\u001b[1;32m   1041\u001b[0m         hidden_states,\n\u001b[1;32m   1042\u001b[0m         attention_mask\u001b[39m=\u001b[39;49mextended_attention_mask,\n\u001b[1;32m   1043\u001b[0m         position_bias\u001b[39m=\u001b[39;49mposition_bias,\n\u001b[1;32m   1044\u001b[0m         encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[1;32m   1045\u001b[0m         encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_extended_attention_mask,\n\u001b[1;32m   1046\u001b[0m         encoder_decoder_position_bias\u001b[39m=\u001b[39;49mencoder_decoder_position_bias,\n\u001b[1;32m   1047\u001b[0m         layer_head_mask\u001b[39m=\u001b[39;49mlayer_head_mask,\n\u001b[1;32m   1048\u001b[0m         cross_attn_layer_head_mask\u001b[39m=\u001b[39;49mcross_attn_layer_head_mask,\n\u001b[1;32m   1049\u001b[0m         past_key_value\u001b[39m=\u001b[39;49mpast_key_value,\n\u001b[1;32m   1050\u001b[0m         use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m   1051\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1052\u001b[0m     )\n\u001b[1;32m   1054\u001b[0m \u001b[39m# layer_outputs is a tuple with:\u001b[39;00m\n\u001b[1;32m   1055\u001b[0m \u001b[39m# hidden-states, key-value-states, (self-attention position bias), (self-attention weights), (cross-attention position bias), (cross-attention weights)\u001b[39;00m\n\u001b[1;32m   1056\u001b[0m \u001b[39mif\u001b[39;00m use_cache \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py:1482\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1477\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1478\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1479\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1480\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1481\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1482\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1483\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1484\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/torch/lib/python3.9/site-packages/transformers/models/t5/modeling_t5.py:725\u001b[0m, in \u001b[0;36mT5Block.forward\u001b[0;34m(self, hidden_states, attention_mask, position_bias, encoder_hidden_states, encoder_attention_mask, encoder_decoder_position_bias, layer_head_mask, cross_attn_layer_head_mask, past_key_value, use_cache, output_attentions, return_dict)\u001b[0m\n\u001b[1;32m    722\u001b[0m     attention_outputs \u001b[39m=\u001b[39m attention_outputs \u001b[39m+\u001b[39m cross_attention_outputs[\u001b[39m2\u001b[39m:]\n\u001b[1;32m    724\u001b[0m \u001b[39m# Apply Feed Forward layer\u001b[39;00m\n\u001b[0;32m--> 725\u001b[0m hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlayer[\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m](hidden_states)\n\u001b[1;32m    727\u001b[0m \u001b[39m# clamp inf values to enable fp16 training\u001b[39;00m\n\u001b[1;32m    728\u001b[0m \u001b[39mif\u001b[39;00m hidden_states\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m torch\u001b[39m.\u001b[39mfloat16 \u001b[39mand\u001b[39;00m torch\u001b[39m.\u001b[39misinf(hidden_states)\u001b[39m.\u001b[39many():\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py:1482\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1477\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1478\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1479\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1480\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1481\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1482\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1483\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1484\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/torch/lib/python3.9/site-packages/transformers/models/t5/modeling_t5.py:328\u001b[0m, in \u001b[0;36mT5LayerFF.forward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, hidden_states):\n\u001b[1;32m    327\u001b[0m     forwarded_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayer_norm(hidden_states)\n\u001b[0;32m--> 328\u001b[0m     forwarded_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mDenseReluDense(forwarded_states)\n\u001b[1;32m    329\u001b[0m     hidden_states \u001b[39m=\u001b[39m hidden_states \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(forwarded_states)\n\u001b[1;32m    330\u001b[0m     \u001b[39mreturn\u001b[39;00m hidden_states\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py:1482\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1477\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1478\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1479\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1480\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1481\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1482\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1483\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1484\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/torch/lib/python3.9/site-packages/transformers/models/t5/modeling_t5.py:292\u001b[0m, in \u001b[0;36mT5DenseActDense.forward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    290\u001b[0m hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwi(hidden_states)\n\u001b[1;32m    291\u001b[0m hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mact(hidden_states)\n\u001b[0;32m--> 292\u001b[0m hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropout(hidden_states)\n\u001b[1;32m    293\u001b[0m hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwo(hidden_states)\n\u001b[1;32m    294\u001b[0m \u001b[39mreturn\u001b[39;00m hidden_states\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py:1482\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1477\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1478\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1479\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1480\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1481\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1482\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1483\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1484\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/dropout.py:59\u001b[0m, in \u001b[0;36mDropout.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m---> 59\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mdropout(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mp, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minplace)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/torch/lib/python3.9/site-packages/torch/nn/functional.py:1252\u001b[0m, in \u001b[0;36mdropout\u001b[0;34m(input, p, training, inplace)\u001b[0m\n\u001b[1;32m   1250\u001b[0m \u001b[39mif\u001b[39;00m p \u001b[39m<\u001b[39m \u001b[39m0.0\u001b[39m \u001b[39mor\u001b[39;00m p \u001b[39m>\u001b[39m \u001b[39m1.0\u001b[39m:\n\u001b[1;32m   1251\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mdropout probability has to be between 0 and 1, \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbut got \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(p))\n\u001b[0;32m-> 1252\u001b[0m \u001b[39mreturn\u001b[39;00m _VF\u001b[39m.\u001b[39mdropout_(\u001b[39minput\u001b[39m, p, training) \u001b[39mif\u001b[39;00m inplace \u001b[39melse\u001b[39;00m _VF\u001b[39m.\u001b[39;49mdropout(\u001b[39minput\u001b[39;49m, p, training)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from transformers import Trainer\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.push_to_hub(commit_message=\"Training complete\", tags=\"summarization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine-tuning T5 with Accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 8\n",
    "train_dataloader = DataLoader(\n",
    "    tokenized_datasets[\"train\"],\n",
    "    shuffle=True,\n",
    "    collate_fn=data_collator,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "eval_dataloader = DataLoader(\n",
    "    tokenized_datasets[\"validation\"], collate_fn=data_collator, batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from accelerate import Accelerator\n",
    "\n",
    "accelerator = Accelerator()\n",
    "model, optimizer, train_dataloader, eval_dataloader = accelerator.prepare(\n",
    "    model, optimizer, train_dataloader, eval_dataloader\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_scheduler\n",
    "\n",
    "num_train_epochs = 10\n",
    "num_update_steps_per_epoch = len(train_dataloader)\n",
    "num_training_steps = num_train_epochs * num_update_steps_per_epoch\n",
    "\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"linear\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=num_training_steps,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess_text(preds, labels):\n",
    "    preds = [pred.strip() for pred in preds]\n",
    "    labels = [label.strip() for label in labels]\n",
    "\n",
    "    # ROUGE expects a newline after each sentence\n",
    "    preds = [\"\\n\".join(nltk.sent_tokenize(pred)) for pred in preds]\n",
    "    labels = [\"\\n\".join(nltk.sent_tokenize(label)) for label in labels]\n",
    "\n",
    "    return preds, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import get_full_repo_name\n",
    "\n",
    "model_name = \"t5-finetuned-amazon-test\"\n",
    "repo_name = get_full_repo_name(model_name)\n",
    "repo_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import Repository\n",
    "\n",
    "output_dir = \"results-mt5-finetuned-squad-accelerate\"\n",
    "repo = Repository(output_dir, clone_from=repo_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "for epoch in range(num_train_epochs):\n",
    "    # Training\n",
    "    model.train()\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        accelerator.backward(loss)\n",
    "\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        progress_bar.update(1)\n",
    "\n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    for step, batch in enumerate(eval_dataloader):\n",
    "        with torch.no_grad():\n",
    "            generated_tokens = accelerator.unwrap_model(model).generate(\n",
    "                batch[\"input_ids\"],\n",
    "                attention_mask=batch[\"attention_mask\"],\n",
    "            )\n",
    "\n",
    "            generated_tokens = accelerator.pad_across_processes(\n",
    "                generated_tokens, dim=1, pad_index=tokenizer.pad_token_id\n",
    "            )\n",
    "            labels = batch[\"labels\"]\n",
    "\n",
    "            # If we did not pad to max length, we need to pad the labels too\n",
    "            labels = accelerator.pad_across_processes(\n",
    "                batch[\"labels\"], dim=1, pad_index=tokenizer.pad_token_id\n",
    "            )\n",
    "\n",
    "            generated_tokens = accelerator.gather(generated_tokens).cpu().numpy()\n",
    "            labels = accelerator.gather(labels).cpu().numpy()\n",
    "\n",
    "            # Replace -100 in the labels as we can't decode them\n",
    "            labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "            if isinstance(generated_tokens, tuple):\n",
    "                generated_tokens = generated_tokens[0]\n",
    "            decoded_preds = tokenizer.batch_decode(\n",
    "                generated_tokens, skip_special_tokens=True\n",
    "            )\n",
    "            decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "            decoded_preds, decoded_labels = postprocess_text(\n",
    "                decoded_preds, decoded_labels\n",
    "            )\n",
    "\n",
    "            rouge_score.add_batch(predictions=decoded_preds, references=decoded_labels)\n",
    "\n",
    "    # Compute metrics\n",
    "    result = rouge_score.compute()\n",
    "    # Extract the median ROUGE scores\n",
    "    result = {key: value.mean() * 100 for key, value in result.items()}\n",
    "    result = {k: round(v, 4) for k, v in result.items()}\n",
    "    print(f\"Epoch {epoch}:\", result)\n",
    "\n",
    "    # Save and upload\n",
    "    accelerator.wait_for_everyone()\n",
    "    unwrapped_model = accelerator.unwrap_model(model)\n",
    "    unwrapped_model.save_pretrained(output_dir, save_function=accelerator.save)\n",
    "    if accelerator.is_main_process:\n",
    "        tokenizer.save_pretrained(output_dir)\n",
    "        repo.push_to_hub(\n",
    "            commit_message=f\"Training in progress epoch {epoch}\", blocking=False\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testen der Modelle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_summary(model, tokenizer, text, max_length=512, min_length=30, length_penalty=5.0, repetition_penalty=5.0, num_beams=3):\n",
    "    '''Description: Call HuggingFace T5 model to generate abstractive summary \n",
    "       Input: a pre-trained T5 model, a T5 tokenizer, an original text to summarize and a set of tunable hyperprams \n",
    "       Output: an abstractive summary text generated by T5 \n",
    "       \n",
    "       Note: You could try different values for tuning hyperprams to control the summary length.\n",
    "       Specifically you could use the `length_penalty` argument. \n",
    "       Set to values < 1.0 in order to encourage the model to generate shorter sequences, \n",
    "       to a value > 1.0 in order to encourage the model to produce longer sequences.\n",
    "       Be default generate will use arguments from config or config.task_specific_params \n",
    "       but you could also directly pass these args to generate to override them\n",
    "    '''\n",
    "    inputs = tokenizer.encode(\"summarize: \" + text, return_tensors=\"pt\", max_length=max_length, truncation=True)\n",
    "    outputs = model.generate(\n",
    "        inputs, \n",
    "        max_length=max_length, \n",
    "        min_length=min_length, \n",
    "        length_penalty=length_penalty,\n",
    "        repetition_penalty=repetition_penalty,\n",
    "        num_beams=num_beams, \n",
    "        early_stopping=True)\n",
    "    print(tokenizer.decode(outputs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_summary(model, tokenizer, text, max_length=512, min_length=30, length_penalty=5.0, repetition_penalty=5.0, num_beams=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /Users/niclascramer/.cache/huggingface/hub/models--NICFRU--t5-large-finetuned-amazon-test_2/snapshots/aefae4d1549dcf4152be201c7967e4f724391890/config.json\n",
      "Model config T5Config {\n",
      "  \"_name_or_path\": \"NICFRU/t5-large-finetuned-amazon-test_2\",\n",
      "  \"architectures\": [\n",
      "    \"T5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 4096,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 24,\n",
      "  \"num_heads\": 16,\n",
      "  \"num_layers\": 24,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 200,\n",
      "      \"min_length\": 30,\n",
      "      \"no_repeat_ngram_size\": 3,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"summarize: \"\n",
      "    },\n",
      "    \"translation_en_to_de\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to German: \"\n",
      "    },\n",
      "    \"translation_en_to_fr\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to French: \"\n",
      "    },\n",
      "    \"translation_en_to_ro\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to Romanian: \"\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /Users/niclascramer/.cache/huggingface/hub/models--NICFRU--t5-large-finetuned-amazon-test_2/snapshots/aefae4d1549dcf4152be201c7967e4f724391890/config.json\n",
      "Model config T5Config {\n",
      "  \"_name_or_path\": \"NICFRU/t5-large-finetuned-amazon-test_2\",\n",
      "  \"architectures\": [\n",
      "    \"T5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 4096,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 24,\n",
      "  \"num_heads\": 16,\n",
      "  \"num_layers\": 24,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 200,\n",
      "      \"min_length\": 30,\n",
      "      \"no_repeat_ngram_size\": 3,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"summarize: \"\n",
      "    },\n",
      "    \"translation_en_to_de\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to German: \"\n",
      "    },\n",
      "    \"translation_en_to_fr\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to French: \"\n",
      "    },\n",
      "    \"translation_en_to_ro\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to Romanian: \"\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at /Users/niclascramer/.cache/huggingface/hub/models--NICFRU--t5-large-finetuned-amazon-test_2/snapshots/aefae4d1549dcf4152be201c7967e4f724391890/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing T5ForConditionalGeneration.\n",
      "\n",
      "All the weights of T5ForConditionalGeneration were initialized from the model checkpoint at NICFRU/t5-large-finetuned-amazon-test_2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use T5ForConditionalGeneration for predictions without further training.\n",
      "loading file spiece.model from cache at /Users/niclascramer/.cache/huggingface/hub/models--NICFRU--t5-large-finetuned-amazon-test_2/snapshots/aefae4d1549dcf4152be201c7967e4f724391890/spiece.model\n",
      "loading file tokenizer.json from cache at /Users/niclascramer/.cache/huggingface/hub/models--NICFRU--t5-large-finetuned-amazon-test_2/snapshots/aefae4d1549dcf4152be201c7967e4f724391890/tokenizer.json\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at /Users/niclascramer/.cache/huggingface/hub/models--NICFRU--t5-large-finetuned-amazon-test_2/snapshots/aefae4d1549dcf4152be201c7967e4f724391890/special_tokens_map.json\n",
      "loading file tokenizer_config.json from cache at /Users/niclascramer/.cache/huggingface/hub/models--NICFRU--t5-large-finetuned-amazon-test_2/snapshots/aefae4d1549dcf4152be201c7967e4f724391890/tokenizer_config.json\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'SummarizationPipeline' object has no attribute 'generate'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[92], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m text\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mIt is not mush of guide.It kinda sucks I wish I wanted for the official one\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m      5\u001b[0m model \u001b[39m=\u001b[39m pipeline(\u001b[39m\"\u001b[39m\u001b[39msummarization\u001b[39m\u001b[39m\"\u001b[39m, model\u001b[39m=\u001b[39mhub_model_id)\n\u001b[0;32m----> 6\u001b[0m create_summary(model, tokenizer, text, max_length\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m, min_length\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m, length_penalty\u001b[39m=\u001b[39;49m\u001b[39m5.0\u001b[39;49m, repetition_penalty\u001b[39m=\u001b[39;49m\u001b[39m5.0\u001b[39;49m, num_beams\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m)\n",
      "Cell \u001b[0;32mIn[90], line 14\u001b[0m, in \u001b[0;36mcreate_summary\u001b[0;34m(model, tokenizer, text, max_length, min_length, length_penalty, repetition_penalty, num_beams)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39m'''Description: Call HuggingFace T5 model to generate abstractive summary \u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m   Input: a pre-trained T5 model, a T5 tokenizer, an original text to summarize and a set of tunable hyperprams \u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39m   Output: an abstractive summary text generated by T5 \u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[39m   but you could also directly pass these args to generate to override them\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[1;32m     13\u001b[0m inputs \u001b[39m=\u001b[39m tokenizer\u001b[39m.\u001b[39mencode(\u001b[39m\"\u001b[39m\u001b[39msummarize: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m text, return_tensors\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m, max_length\u001b[39m=\u001b[39mmax_length, truncation\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m---> 14\u001b[0m outputs \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mgenerate(\n\u001b[1;32m     15\u001b[0m     inputs, \n\u001b[1;32m     16\u001b[0m     max_length\u001b[39m=\u001b[39mmax_length, \n\u001b[1;32m     17\u001b[0m     min_length\u001b[39m=\u001b[39mmin_length, \n\u001b[1;32m     18\u001b[0m     length_penalty\u001b[39m=\u001b[39mlength_penalty,\n\u001b[1;32m     19\u001b[0m     repetition_penalty\u001b[39m=\u001b[39mrepetition_penalty,\n\u001b[1;32m     20\u001b[0m     num_beams\u001b[39m=\u001b[39mnum_beams, \n\u001b[1;32m     21\u001b[0m     early_stopping\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     22\u001b[0m \u001b[39mprint\u001b[39m(tokenizer\u001b[39m.\u001b[39mdecode(outputs[\u001b[39m0\u001b[39m]))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'SummarizationPipeline' object has no attribute 'generate'"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "hub_model_id = \"NICFRU/t5-large-finetuned-amazon-test_2\"\n",
    "text='It is not mush of guide.It kinda sucks I wish I wanted for the official one'\n",
    "model = pipeline(\"summarization\", model=hub_model_id)\n",
    "create_summary(model, tokenizer, text, max_length=10, min_length=5, length_penalty=5.0, repetition_penalty=5.0, num_beams=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18ae93e2d05f4640b9c684404cd874be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.48k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /Users/niclascramer/.cache/huggingface/hub/models--NICFRU--t5-large-finetuned-amazon-test_2/snapshots/aefae4d1549dcf4152be201c7967e4f724391890/config.json\n",
      "Model config T5Config {\n",
      "  \"_name_or_path\": \"NICFRU/t5-large-finetuned-amazon-test_2\",\n",
      "  \"architectures\": [\n",
      "    \"T5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 4096,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 24,\n",
      "  \"num_heads\": 16,\n",
      "  \"num_layers\": 24,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 200,\n",
      "      \"min_length\": 30,\n",
      "      \"no_repeat_ngram_size\": 3,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"summarize: \"\n",
      "    },\n",
      "    \"translation_en_to_de\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to German: \"\n",
      "    },\n",
      "    \"translation_en_to_fr\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to French: \"\n",
      "    },\n",
      "    \"translation_en_to_ro\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to Romanian: \"\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /Users/niclascramer/.cache/huggingface/hub/models--NICFRU--t5-large-finetuned-amazon-test_2/snapshots/aefae4d1549dcf4152be201c7967e4f724391890/config.json\n",
      "Model config T5Config {\n",
      "  \"_name_or_path\": \"NICFRU/t5-large-finetuned-amazon-test_2\",\n",
      "  \"architectures\": [\n",
      "    \"T5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 4096,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 24,\n",
      "  \"num_heads\": 16,\n",
      "  \"num_layers\": 24,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 200,\n",
      "      \"min_length\": 30,\n",
      "      \"no_repeat_ngram_size\": 3,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"summarize: \"\n",
      "    },\n",
      "    \"translation_en_to_de\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to German: \"\n",
      "    },\n",
      "    \"translation_en_to_fr\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to French: \"\n",
      "    },\n",
      "    \"translation_en_to_ro\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to Romanian: \"\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40ae1b714ff74986b72b577d35c3cd08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/2.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file pytorch_model.bin from cache at /Users/niclascramer/.cache/huggingface/hub/models--NICFRU--t5-large-finetuned-amazon-test_2/snapshots/aefae4d1549dcf4152be201c7967e4f724391890/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing T5ForConditionalGeneration.\n",
      "\n",
      "All the weights of T5ForConditionalGeneration were initialized from the model checkpoint at NICFRU/t5-large-finetuned-amazon-test_2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use T5ForConditionalGeneration for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "044a8d2a88b245c392fb943ef117cf2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/2.32k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "638595806b4a47c7bf6148401d532ab5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75ffa6331932469787bd9eae081a5063",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/2.42M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "286920e6a05e4a3ba805f8c7342616cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/2.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file spiece.model from cache at /Users/niclascramer/.cache/huggingface/hub/models--NICFRU--t5-large-finetuned-amazon-test_2/snapshots/aefae4d1549dcf4152be201c7967e4f724391890/spiece.model\n",
      "loading file tokenizer.json from cache at /Users/niclascramer/.cache/huggingface/hub/models--NICFRU--t5-large-finetuned-amazon-test_2/snapshots/aefae4d1549dcf4152be201c7967e4f724391890/tokenizer.json\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at /Users/niclascramer/.cache/huggingface/hub/models--NICFRU--t5-large-finetuned-amazon-test_2/snapshots/aefae4d1549dcf4152be201c7967e4f724391890/special_tokens_map.json\n",
      "loading file tokenizer_config.json from cache at /Users/niclascramer/.cache/huggingface/hub/models--NICFRU--t5-large-finetuned-amazon-test_2/snapshots/aefae4d1549dcf4152be201c7967e4f724391890/tokenizer_config.json\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "hub_model_id = \"NICFRU/t5-large-finetuned-amazon-test_2\"\n",
    "summarizer = pipeline(\"summarization\", model=hub_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_summary(idx):\n",
    "    review = english_books[\"test\"][idx][\"review_body\"]\n",
    "    title = english_books[\"test\"][idx][\"review_title\"]\n",
    "    summary = summarizer(english_books[\"test\"][idx][\"review_body\"])[0][\"summary_text\"]\n",
    "    print(f\"'>>> Review: {review}'\")\n",
    "    print(f\"\\n'>>> Title: {title}'\")\n",
    "    print(f\"\\n'>>> Summary: {summary}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 200, but you input_length is only 28. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=14)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'>>> Review: It is not mush of guide.It kinda sucks I wish I wanted for the official one'\n",
      "\n",
      "'>>> Title: It kinda sucks I wish I wanted for the official'\n",
      "\n",
      "'>>> Summary: it is not mush of guide.I wish I wanted for the official one . the cover art is great but the text is not.'\n"
     ]
    }
   ],
   "source": [
    "print_summary(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainer\n",
    "def trainfunction(model_checkpoint,model,tokenizer,tokenized_datasets,model_name,batch_size=8,num_train_epochs=8,learning_rate=5.6e-5,weight_decay=0.01,save_total_limit=3):\n",
    "    \n",
    "    # Show the training loss with every epoch\n",
    "    logging_steps = len(tokenized_datasets[\"train\"]) // batch_size\n",
    "    model_name = model_checkpoint.split(\"/\")[-1]\n",
    "\n",
    "    args = Seq2SeqTrainingArguments(\n",
    "        output_dir=f\"{model_name}-finetuned\",\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        learning_rate=learning_rate,\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        per_device_eval_batch_size=batch_size,\n",
    "        weight_decay=weight_decay,\n",
    "        save_total_limit=save_total_limit,\n",
    "        num_train_epochs=num_train_epochs,\n",
    "        predict_with_generate=True,\n",
    "        logging_steps=logging_steps,\n",
    "        push_to_hub=True,\n",
    "    )\n",
    "    data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
    "    trainer = Seq2SeqTrainer(\n",
    "        model,\n",
    "        args,\n",
    "        train_dataset=tokenized_datasets[\"train\"],\n",
    "        eval_dataset=tokenized_datasets[\"validation\"],\n",
    "        data_collator=data_collator,\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "    trainer.train()\n",
    "    trainer.evaluate()\n",
    "    trainer.push_to_hub(commit_message=\"Training complete\", tags=\"summarization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint='t5-large'\n",
    "model_name='t5-large'\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /Users/niclascramer/.cache/huggingface/hub/models--google--pegasus-large/snapshots/dec7796b22f29b7d1c476192313eae8ed57b6b77/config.json\n",
      "Model config PegasusConfig {\n",
      "  \"_name_or_path\": \"google/pegasus-large\",\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"activation_function\": \"relu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": true,\n",
      "  \"architectures\": [\n",
      "    \"PegasusForConditionalGeneration\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 4096,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 16,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 16,\n",
      "  \"encoder_ffn_dim\": 4096,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 16,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"extra_pos_embeddings\": 1,\n",
      "  \"force_bos_token_to_be_generated\": false,\n",
      "  \"forced_eos_token_id\": 1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"length_penalty\": 0.8,\n",
      "  \"max_length\": 256,\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"pegasus\",\n",
      "  \"normalize_before\": true,\n",
      "  \"normalize_embedding\": false,\n",
      "  \"num_beams\": 8,\n",
      "  \"num_hidden_layers\": 16,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"scale_embedding\": true,\n",
      "  \"static_position_embeddings\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization_aeslc\": {\n",
      "      \"length_penalty\": 0.6,\n",
      "      \"max_length\": 32,\n",
      "      \"max_position_embeddings\": 512\n",
      "    },\n",
      "    \"summarization_arxiv\": {\n",
      "      \"length_penalty\": 0.8,\n",
      "      \"max_length\": 256,\n",
      "      \"max_position_embeddings\": 1024\n",
      "    },\n",
      "    \"summarization_big_patent\": {\n",
      "      \"length_penalty\": 0.7,\n",
      "      \"max_length\": 256,\n",
      "      \"max_position_embeddings\": 1024\n",
      "    },\n",
      "    \"summarization_billsum\": {\n",
      "      \"length_penalty\": 0.6,\n",
      "      \"max_length\": 256,\n",
      "      \"max_position_embeddings\": 1024\n",
      "    },\n",
      "    \"summarization_cnn_dailymail\": {\n",
      "      \"length_penalty\": 0.8,\n",
      "      \"max_length\": 128,\n",
      "      \"max_position_embeddings\": 1024\n",
      "    },\n",
      "    \"summarization_gigaword\": {\n",
      "      \"length_penalty\": 0.6,\n",
      "      \"max_length\": 32,\n",
      "      \"max_position_embeddings\": 128\n",
      "    },\n",
      "    \"summarization_large\": {\n",
      "      \"length_penalty\": 0.8,\n",
      "      \"max_length\": 256,\n",
      "      \"max_position_embeddings\": 1024\n",
      "    },\n",
      "    \"summarization_multi_news\": {\n",
      "      \"length_penalty\": 0.8,\n",
      "      \"max_length\": 256,\n",
      "      \"max_position_embeddings\": 1024\n",
      "    },\n",
      "    \"summarization_newsroom\": {\n",
      "      \"length_penalty\": 0.8,\n",
      "      \"max_length\": 128,\n",
      "      \"max_position_embeddings\": 512\n",
      "    },\n",
      "    \"summarization_pubmed\": {\n",
      "      \"length_penalty\": 0.8,\n",
      "      \"max_length\": 256,\n",
      "      \"max_position_embeddings\": 1024\n",
      "    },\n",
      "    \"summarization_reddit_tifu\": {\n",
      "      \"length_penalty\": 0.6,\n",
      "      \"max_length\": 128,\n",
      "      \"max_position_embeddings\": 512\n",
      "    },\n",
      "    \"summarization_wikihow\": {\n",
      "      \"length_penalty\": 0.6,\n",
      "      \"max_length\": 256,\n",
      "      \"max_position_embeddings\": 512\n",
      "    },\n",
      "    \"summarization_xsum\": {\n",
      "      \"length_penalty\": 0.8,\n",
      "      \"max_length\": 64,\n",
      "      \"max_position_embeddings\": 512\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 96103\n",
      "}\n",
      "\n",
      "loading file spiece.model from cache at /Users/niclascramer/.cache/huggingface/hub/models--google--pegasus-large/snapshots/dec7796b22f29b7d1c476192313eae8ed57b6b77/spiece.model\n",
      "loading file tokenizer.json from cache at None\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at /Users/niclascramer/.cache/huggingface/hub/models--google--pegasus-large/snapshots/dec7796b22f29b7d1c476192313eae8ed57b6b77/special_tokens_map.json\n",
      "loading file tokenizer_config.json from cache at /Users/niclascramer/.cache/huggingface/hub/models--google--pegasus-large/snapshots/dec7796b22f29b7d1c476192313eae8ed57b6b77/tokenizer_config.json\n",
      "loading configuration file config.json from cache at /Users/niclascramer/.cache/huggingface/hub/models--google--pegasus-large/snapshots/dec7796b22f29b7d1c476192313eae8ed57b6b77/config.json\n",
      "Model config PegasusConfig {\n",
      "  \"_name_or_path\": \"google/pegasus-large\",\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"activation_function\": \"relu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": true,\n",
      "  \"architectures\": [\n",
      "    \"PegasusForConditionalGeneration\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 4096,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 16,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 16,\n",
      "  \"encoder_ffn_dim\": 4096,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 16,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"extra_pos_embeddings\": 1,\n",
      "  \"force_bos_token_to_be_generated\": false,\n",
      "  \"forced_eos_token_id\": 1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"length_penalty\": 0.8,\n",
      "  \"max_length\": 256,\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"pegasus\",\n",
      "  \"normalize_before\": true,\n",
      "  \"normalize_embedding\": false,\n",
      "  \"num_beams\": 8,\n",
      "  \"num_hidden_layers\": 16,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"scale_embedding\": true,\n",
      "  \"static_position_embeddings\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization_aeslc\": {\n",
      "      \"length_penalty\": 0.6,\n",
      "      \"max_length\": 32,\n",
      "      \"max_position_embeddings\": 512\n",
      "    },\n",
      "    \"summarization_arxiv\": {\n",
      "      \"length_penalty\": 0.8,\n",
      "      \"max_length\": 256,\n",
      "      \"max_position_embeddings\": 1024\n",
      "    },\n",
      "    \"summarization_big_patent\": {\n",
      "      \"length_penalty\": 0.7,\n",
      "      \"max_length\": 256,\n",
      "      \"max_position_embeddings\": 1024\n",
      "    },\n",
      "    \"summarization_billsum\": {\n",
      "      \"length_penalty\": 0.6,\n",
      "      \"max_length\": 256,\n",
      "      \"max_position_embeddings\": 1024\n",
      "    },\n",
      "    \"summarization_cnn_dailymail\": {\n",
      "      \"length_penalty\": 0.8,\n",
      "      \"max_length\": 128,\n",
      "      \"max_position_embeddings\": 1024\n",
      "    },\n",
      "    \"summarization_gigaword\": {\n",
      "      \"length_penalty\": 0.6,\n",
      "      \"max_length\": 32,\n",
      "      \"max_position_embeddings\": 128\n",
      "    },\n",
      "    \"summarization_large\": {\n",
      "      \"length_penalty\": 0.8,\n",
      "      \"max_length\": 256,\n",
      "      \"max_position_embeddings\": 1024\n",
      "    },\n",
      "    \"summarization_multi_news\": {\n",
      "      \"length_penalty\": 0.8,\n",
      "      \"max_length\": 256,\n",
      "      \"max_position_embeddings\": 1024\n",
      "    },\n",
      "    \"summarization_newsroom\": {\n",
      "      \"length_penalty\": 0.8,\n",
      "      \"max_length\": 128,\n",
      "      \"max_position_embeddings\": 512\n",
      "    },\n",
      "    \"summarization_pubmed\": {\n",
      "      \"length_penalty\": 0.8,\n",
      "      \"max_length\": 256,\n",
      "      \"max_position_embeddings\": 1024\n",
      "    },\n",
      "    \"summarization_reddit_tifu\": {\n",
      "      \"length_penalty\": 0.6,\n",
      "      \"max_length\": 128,\n",
      "      \"max_position_embeddings\": 512\n",
      "    },\n",
      "    \"summarization_wikihow\": {\n",
      "      \"length_penalty\": 0.6,\n",
      "      \"max_length\": 256,\n",
      "      \"max_position_embeddings\": 512\n",
      "    },\n",
      "    \"summarization_xsum\": {\n",
      "      \"length_penalty\": 0.8,\n",
      "      \"max_length\": 64,\n",
      "      \"max_position_embeddings\": 512\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 96103\n",
      "}\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Couldn't instantiate the backend tokenizer from one of: \n(1) a `tokenizers` library serialization file, \n(2) a slow tokenizer instance to convert or \n(3) an equivalent slow tokenizer class to instantiate and convert. \nYou need to have sentencepiece installed to convert a slow tokenizer to a fast one.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[81], line 7\u001b[0m\n\u001b[1;32m      3\u001b[0m model_checkpoint\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mgoogle/pegasus-large\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m      4\u001b[0m model_name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mpegasus\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m----> 7\u001b[0m tokenizer \u001b[39m=\u001b[39m AutoTokenizer\u001b[39m.\u001b[39;49mfrom_pretrained(\u001b[39m\"\u001b[39;49m\u001b[39mgoogle/pegasus-large\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      8\u001b[0m model \u001b[39m=\u001b[39m PegasusModel\u001b[39m.\u001b[39mfrom_pretrained(\u001b[39m\"\u001b[39m\u001b[39mgoogle/pegasus-large\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/torch/lib/python3.9/site-packages/transformers/models/auto/tokenization_auto.py:637\u001b[0m, in \u001b[0;36mAutoTokenizer.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    635\u001b[0m tokenizer_class_py, tokenizer_class_fast \u001b[39m=\u001b[39m TOKENIZER_MAPPING[\u001b[39mtype\u001b[39m(config)]\n\u001b[1;32m    636\u001b[0m \u001b[39mif\u001b[39;00m tokenizer_class_fast \u001b[39mand\u001b[39;00m (use_fast \u001b[39mor\u001b[39;00m tokenizer_class_py \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 637\u001b[0m     \u001b[39mreturn\u001b[39;00m tokenizer_class_fast\u001b[39m.\u001b[39;49mfrom_pretrained(pretrained_model_name_or_path, \u001b[39m*\u001b[39;49minputs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    638\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    639\u001b[0m     \u001b[39mif\u001b[39;00m tokenizer_class_py \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/torch/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:1777\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   1774\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1775\u001b[0m         logger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mloading file \u001b[39m\u001b[39m{\u001b[39;00mfile_path\u001b[39m}\u001b[39;00m\u001b[39m from cache at \u001b[39m\u001b[39m{\u001b[39;00mresolved_vocab_files[file_id]\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 1777\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m_from_pretrained(\n\u001b[1;32m   1778\u001b[0m     resolved_vocab_files,\n\u001b[1;32m   1779\u001b[0m     pretrained_model_name_or_path,\n\u001b[1;32m   1780\u001b[0m     init_configuration,\n\u001b[1;32m   1781\u001b[0m     \u001b[39m*\u001b[39;49minit_inputs,\n\u001b[1;32m   1782\u001b[0m     use_auth_token\u001b[39m=\u001b[39;49muse_auth_token,\n\u001b[1;32m   1783\u001b[0m     cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[1;32m   1784\u001b[0m     local_files_only\u001b[39m=\u001b[39;49mlocal_files_only,\n\u001b[1;32m   1785\u001b[0m     _commit_hash\u001b[39m=\u001b[39;49mcommit_hash,\n\u001b[1;32m   1786\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m   1787\u001b[0m )\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/torch/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:1932\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase._from_pretrained\u001b[0;34m(cls, resolved_vocab_files, pretrained_model_name_or_path, init_configuration, use_auth_token, cache_dir, local_files_only, _commit_hash, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   1930\u001b[0m \u001b[39m# Instantiate tokenizer.\u001b[39;00m\n\u001b[1;32m   1931\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1932\u001b[0m     tokenizer \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m(\u001b[39m*\u001b[39;49minit_inputs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49minit_kwargs)\n\u001b[1;32m   1933\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m:\n\u001b[1;32m   1934\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mOSError\u001b[39;00m(\n\u001b[1;32m   1935\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mUnable to load vocabulary from file. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1936\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPlease check that the provided vocabulary is accessible and not corrupted.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1937\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/torch/lib/python3.9/site-packages/transformers/models/pegasus/tokenization_pegasus_fast.py:142\u001b[0m, in \u001b[0;36mPegasusTokenizerFast.__init__\u001b[0;34m(self, vocab_file, tokenizer_file, pad_token, eos_token, unk_token, mask_token, mask_token_sent, additional_special_tokens, offset, **kwargs)\u001b[0m\n\u001b[1;32m    139\u001b[0m     additional_special_tokens \u001b[39m=\u001b[39m [mask_token_sent] \u001b[39mif\u001b[39;00m mask_token_sent \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m []\n\u001b[1;32m    140\u001b[0m     additional_special_tokens \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m [\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m<unk_\u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m>\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m2\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moffset)]\n\u001b[0;32m--> 142\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\n\u001b[1;32m    143\u001b[0m     vocab_file,\n\u001b[1;32m    144\u001b[0m     tokenizer_file\u001b[39m=\u001b[39;49mtokenizer_file,\n\u001b[1;32m    145\u001b[0m     pad_token\u001b[39m=\u001b[39;49mpad_token,\n\u001b[1;32m    146\u001b[0m     eos_token\u001b[39m=\u001b[39;49meos_token,\n\u001b[1;32m    147\u001b[0m     unk_token\u001b[39m=\u001b[39;49munk_token,\n\u001b[1;32m    148\u001b[0m     mask_token\u001b[39m=\u001b[39;49mmask_token,\n\u001b[1;32m    149\u001b[0m     mask_token_sent\u001b[39m=\u001b[39;49mmask_token_sent,\n\u001b[1;32m    150\u001b[0m     offset\u001b[39m=\u001b[39;49moffset,\n\u001b[1;32m    151\u001b[0m     additional_special_tokens\u001b[39m=\u001b[39;49madditional_special_tokens,\n\u001b[1;32m    152\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    153\u001b[0m )\n\u001b[1;32m    154\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvocab_file \u001b[39m=\u001b[39m vocab_file\n\u001b[1;32m    155\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcan_save_slow_tokenizer \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvocab_file \u001b[39melse\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/torch/lib/python3.9/site-packages/transformers/tokenization_utils_fast.py:120\u001b[0m, in \u001b[0;36mPreTrainedTokenizerFast.__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m     fast_tokenizer \u001b[39m=\u001b[39m convert_slow_tokenizer(slow_tokenizer)\n\u001b[1;32m    119\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 120\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    121\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCouldn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt instantiate the backend tokenizer from one of: \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    122\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m(1) a `tokenizers` library serialization file, \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    123\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m(2) a slow tokenizer instance to convert or \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    124\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m(3) an equivalent slow tokenizer class to instantiate and convert. \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    125\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mYou need to have sentencepiece installed to convert a slow tokenizer to a fast one.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    126\u001b[0m     )\n\u001b[1;32m    128\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tokenizer \u001b[39m=\u001b[39m fast_tokenizer\n\u001b[1;32m    130\u001b[0m \u001b[39mif\u001b[39;00m slow_tokenizer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: Couldn't instantiate the backend tokenizer from one of: \n(1) a `tokenizers` library serialization file, \n(2) a slow tokenizer instance to convert or \n(3) an equivalent slow tokenizer class to instantiate and convert. \nYou need to have sentencepiece installed to convert a slow tokenizer to a fast one."
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, PegasusModel\n",
    "\n",
    "model_checkpoint='google/pegasus-large'\n",
    "model_name='pegasus'\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/pegasus-large\")\n",
    "model = PegasusModel.from_pretrained(\"google/pegasus-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d960c2aada1470c99451272890571dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed073735f2df491d9490153bf4f91106",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file vocab.json from cache at /Users/niclascramer/.cache/huggingface/hub/models--facebook--bart-base/snapshots/aadd2ab0ae0c8268c7c9693540e9904811f36177/vocab.json\n",
      "loading file merges.txt from cache at /Users/niclascramer/.cache/huggingface/hub/models--facebook--bart-base/snapshots/aadd2ab0ae0c8268c7c9693540e9904811f36177/merges.txt\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at None\n",
      "loading file tokenizer_config.json from cache at None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b56659735cc41949b14655e20d13402",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.72k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /Users/niclascramer/.cache/huggingface/hub/models--facebook--bart-base/snapshots/aadd2ab0ae0c8268c7c9693540e9904811f36177/config.json\n",
      "Model config BartConfig {\n",
      "  \"_name_or_path\": \"facebook/bart-base\",\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.1,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_attention_heads\": 12,\n",
      "  \"decoder_ffn_dim\": 3072,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"early_stopping\": true,\n",
      "  \"encoder_attention_heads\": 12,\n",
      "  \"encoder_ffn_dim\": 3072,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": true,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"scale_embedding\": false,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 128,\n",
      "      \"min_length\": 12,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_cnn\": {\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 142,\n",
      "      \"min_length\": 56,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_xsum\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 62,\n",
      "      \"min_length\": 11,\n",
      "      \"num_beams\": 6\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /Users/niclascramer/.cache/huggingface/hub/models--facebook--bart-base/snapshots/aadd2ab0ae0c8268c7c9693540e9904811f36177/config.json\n",
      "Model config BartConfig {\n",
      "  \"_name_or_path\": \"bart-base\",\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.1,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_attention_heads\": 12,\n",
      "  \"decoder_ffn_dim\": 3072,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"early_stopping\": true,\n",
      "  \"encoder_attention_heads\": 12,\n",
      "  \"encoder_ffn_dim\": 3072,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": true,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"scale_embedding\": false,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 128,\n",
      "      \"min_length\": 12,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_cnn\": {\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 142,\n",
      "      \"min_length\": 56,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_xsum\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 62,\n",
      "      \"min_length\": 11,\n",
      "      \"num_beams\": 6\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec6e286165c34d119017d08fb0b8933f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/558M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file pytorch_model.bin from cache at /Users/niclascramer/.cache/huggingface/hub/models--facebook--bart-base/snapshots/aadd2ab0ae0c8268c7c9693540e9904811f36177/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BartModel.\n",
      "\n",
      "All the weights of BartModel were initialized from the model checkpoint at facebook/bart-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BartModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BartTokenizer, BartModel\n",
    "\n",
    "model_checkpoint='facebook/bart-base'\n",
    "model_name='bart'\n",
    "tokenizer = BartTokenizer.from_pretrained(model_checkpoint)\n",
    "model = BartModel.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56b229bbf3b14afa90b460a56d3f8133",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/3.09k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /Users/niclascramer/.cache/huggingface/hub/models--google--pegasus-large/snapshots/dec7796b22f29b7d1c476192313eae8ed57b6b77/config.json\n",
      "Model config PegasusConfig {\n",
      "  \"_name_or_path\": \"google/pegasus-large\",\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"activation_function\": \"relu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": true,\n",
      "  \"architectures\": [\n",
      "    \"PegasusForConditionalGeneration\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 4096,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 16,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 16,\n",
      "  \"encoder_ffn_dim\": 4096,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 16,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"extra_pos_embeddings\": 1,\n",
      "  \"force_bos_token_to_be_generated\": false,\n",
      "  \"forced_eos_token_id\": 1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"length_penalty\": 0.8,\n",
      "  \"max_length\": 256,\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"pegasus\",\n",
      "  \"normalize_before\": true,\n",
      "  \"normalize_embedding\": false,\n",
      "  \"num_beams\": 8,\n",
      "  \"num_hidden_layers\": 16,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"scale_embedding\": true,\n",
      "  \"static_position_embeddings\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization_aeslc\": {\n",
      "      \"length_penalty\": 0.6,\n",
      "      \"max_length\": 32,\n",
      "      \"max_position_embeddings\": 512\n",
      "    },\n",
      "    \"summarization_arxiv\": {\n",
      "      \"length_penalty\": 0.8,\n",
      "      \"max_length\": 256,\n",
      "      \"max_position_embeddings\": 1024\n",
      "    },\n",
      "    \"summarization_big_patent\": {\n",
      "      \"length_penalty\": 0.7,\n",
      "      \"max_length\": 256,\n",
      "      \"max_position_embeddings\": 1024\n",
      "    },\n",
      "    \"summarization_billsum\": {\n",
      "      \"length_penalty\": 0.6,\n",
      "      \"max_length\": 256,\n",
      "      \"max_position_embeddings\": 1024\n",
      "    },\n",
      "    \"summarization_cnn_dailymail\": {\n",
      "      \"length_penalty\": 0.8,\n",
      "      \"max_length\": 128,\n",
      "      \"max_position_embeddings\": 1024\n",
      "    },\n",
      "    \"summarization_gigaword\": {\n",
      "      \"length_penalty\": 0.6,\n",
      "      \"max_length\": 32,\n",
      "      \"max_position_embeddings\": 128\n",
      "    },\n",
      "    \"summarization_large\": {\n",
      "      \"length_penalty\": 0.8,\n",
      "      \"max_length\": 256,\n",
      "      \"max_position_embeddings\": 1024\n",
      "    },\n",
      "    \"summarization_multi_news\": {\n",
      "      \"length_penalty\": 0.8,\n",
      "      \"max_length\": 256,\n",
      "      \"max_position_embeddings\": 1024\n",
      "    },\n",
      "    \"summarization_newsroom\": {\n",
      "      \"length_penalty\": 0.8,\n",
      "      \"max_length\": 128,\n",
      "      \"max_position_embeddings\": 512\n",
      "    },\n",
      "    \"summarization_pubmed\": {\n",
      "      \"length_penalty\": 0.8,\n",
      "      \"max_length\": 256,\n",
      "      \"max_position_embeddings\": 1024\n",
      "    },\n",
      "    \"summarization_reddit_tifu\": {\n",
      "      \"length_penalty\": 0.6,\n",
      "      \"max_length\": 128,\n",
      "      \"max_position_embeddings\": 512\n",
      "    },\n",
      "    \"summarization_wikihow\": {\n",
      "      \"length_penalty\": 0.6,\n",
      "      \"max_length\": 256,\n",
      "      \"max_position_embeddings\": 512\n",
      "    },\n",
      "    \"summarization_xsum\": {\n",
      "      \"length_penalty\": 0.8,\n",
      "      \"max_length\": 64,\n",
      "      \"max_position_embeddings\": 512\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 96103\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9924bd245d9b43e5aad473de78f88b15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/2.28G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file pytorch_model.bin from cache at /Users/niclascramer/.cache/huggingface/hub/models--google--pegasus-large/snapshots/dec7796b22f29b7d1c476192313eae8ed57b6b77/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing PegasusForConditionalGeneration.\n",
      "\n",
      "All the weights of PegasusForConditionalGeneration were initialized from the model checkpoint at google/pegasus-large.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use PegasusForConditionalGeneration for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05edb08745514753a5c9de51de584123",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/88.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /Users/niclascramer/.cache/huggingface/hub/models--google--pegasus-large/snapshots/dec7796b22f29b7d1c476192313eae8ed57b6b77/config.json\n",
      "Model config PegasusConfig {\n",
      "  \"_name_or_path\": \"google/pegasus-large\",\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"activation_function\": \"relu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": true,\n",
      "  \"architectures\": [\n",
      "    \"PegasusForConditionalGeneration\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 4096,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 16,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 16,\n",
      "  \"encoder_ffn_dim\": 4096,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 16,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"extra_pos_embeddings\": 1,\n",
      "  \"force_bos_token_to_be_generated\": false,\n",
      "  \"forced_eos_token_id\": 1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"length_penalty\": 0.8,\n",
      "  \"max_length\": 256,\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"pegasus\",\n",
      "  \"normalize_before\": true,\n",
      "  \"normalize_embedding\": false,\n",
      "  \"num_beams\": 8,\n",
      "  \"num_hidden_layers\": 16,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"scale_embedding\": true,\n",
      "  \"static_position_embeddings\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization_aeslc\": {\n",
      "      \"length_penalty\": 0.6,\n",
      "      \"max_length\": 32,\n",
      "      \"max_position_embeddings\": 512\n",
      "    },\n",
      "    \"summarization_arxiv\": {\n",
      "      \"length_penalty\": 0.8,\n",
      "      \"max_length\": 256,\n",
      "      \"max_position_embeddings\": 1024\n",
      "    },\n",
      "    \"summarization_big_patent\": {\n",
      "      \"length_penalty\": 0.7,\n",
      "      \"max_length\": 256,\n",
      "      \"max_position_embeddings\": 1024\n",
      "    },\n",
      "    \"summarization_billsum\": {\n",
      "      \"length_penalty\": 0.6,\n",
      "      \"max_length\": 256,\n",
      "      \"max_position_embeddings\": 1024\n",
      "    },\n",
      "    \"summarization_cnn_dailymail\": {\n",
      "      \"length_penalty\": 0.8,\n",
      "      \"max_length\": 128,\n",
      "      \"max_position_embeddings\": 1024\n",
      "    },\n",
      "    \"summarization_gigaword\": {\n",
      "      \"length_penalty\": 0.6,\n",
      "      \"max_length\": 32,\n",
      "      \"max_position_embeddings\": 128\n",
      "    },\n",
      "    \"summarization_large\": {\n",
      "      \"length_penalty\": 0.8,\n",
      "      \"max_length\": 256,\n",
      "      \"max_position_embeddings\": 1024\n",
      "    },\n",
      "    \"summarization_multi_news\": {\n",
      "      \"length_penalty\": 0.8,\n",
      "      \"max_length\": 256,\n",
      "      \"max_position_embeddings\": 1024\n",
      "    },\n",
      "    \"summarization_newsroom\": {\n",
      "      \"length_penalty\": 0.8,\n",
      "      \"max_length\": 128,\n",
      "      \"max_position_embeddings\": 512\n",
      "    },\n",
      "    \"summarization_pubmed\": {\n",
      "      \"length_penalty\": 0.8,\n",
      "      \"max_length\": 256,\n",
      "      \"max_position_embeddings\": 1024\n",
      "    },\n",
      "    \"summarization_reddit_tifu\": {\n",
      "      \"length_penalty\": 0.6,\n",
      "      \"max_length\": 128,\n",
      "      \"max_position_embeddings\": 512\n",
      "    },\n",
      "    \"summarization_wikihow\": {\n",
      "      \"length_penalty\": 0.6,\n",
      "      \"max_length\": 256,\n",
      "      \"max_position_embeddings\": 512\n",
      "    },\n",
      "    \"summarization_xsum\": {\n",
      "      \"length_penalty\": 0.8,\n",
      "      \"max_length\": 64,\n",
      "      \"max_position_embeddings\": 512\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 96103\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "feabe48209224866af04c4ada596fe90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.91M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec5cbf1c196f4b0a822bc561325b5135",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/65.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file spiece.model from cache at /Users/niclascramer/.cache/huggingface/hub/models--google--pegasus-large/snapshots/dec7796b22f29b7d1c476192313eae8ed57b6b77/spiece.model\n",
      "loading file tokenizer.json from cache at None\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at /Users/niclascramer/.cache/huggingface/hub/models--google--pegasus-large/snapshots/dec7796b22f29b7d1c476192313eae8ed57b6b77/special_tokens_map.json\n",
      "loading file tokenizer_config.json from cache at /Users/niclascramer/.cache/huggingface/hub/models--google--pegasus-large/snapshots/dec7796b22f29b7d1c476192313eae8ed57b6b77/tokenizer_config.json\n",
      "loading configuration file config.json from cache at /Users/niclascramer/.cache/huggingface/hub/models--google--pegasus-large/snapshots/dec7796b22f29b7d1c476192313eae8ed57b6b77/config.json\n",
      "Model config PegasusConfig {\n",
      "  \"_name_or_path\": \"google/pegasus-large\",\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"activation_function\": \"relu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": true,\n",
      "  \"architectures\": [\n",
      "    \"PegasusForConditionalGeneration\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 4096,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 16,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 16,\n",
      "  \"encoder_ffn_dim\": 4096,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 16,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"extra_pos_embeddings\": 1,\n",
      "  \"force_bos_token_to_be_generated\": false,\n",
      "  \"forced_eos_token_id\": 1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"length_penalty\": 0.8,\n",
      "  \"max_length\": 256,\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"pegasus\",\n",
      "  \"normalize_before\": true,\n",
      "  \"normalize_embedding\": false,\n",
      "  \"num_beams\": 8,\n",
      "  \"num_hidden_layers\": 16,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"scale_embedding\": true,\n",
      "  \"static_position_embeddings\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization_aeslc\": {\n",
      "      \"length_penalty\": 0.6,\n",
      "      \"max_length\": 32,\n",
      "      \"max_position_embeddings\": 512\n",
      "    },\n",
      "    \"summarization_arxiv\": {\n",
      "      \"length_penalty\": 0.8,\n",
      "      \"max_length\": 256,\n",
      "      \"max_position_embeddings\": 1024\n",
      "    },\n",
      "    \"summarization_big_patent\": {\n",
      "      \"length_penalty\": 0.7,\n",
      "      \"max_length\": 256,\n",
      "      \"max_position_embeddings\": 1024\n",
      "    },\n",
      "    \"summarization_billsum\": {\n",
      "      \"length_penalty\": 0.6,\n",
      "      \"max_length\": 256,\n",
      "      \"max_position_embeddings\": 1024\n",
      "    },\n",
      "    \"summarization_cnn_dailymail\": {\n",
      "      \"length_penalty\": 0.8,\n",
      "      \"max_length\": 128,\n",
      "      \"max_position_embeddings\": 1024\n",
      "    },\n",
      "    \"summarization_gigaword\": {\n",
      "      \"length_penalty\": 0.6,\n",
      "      \"max_length\": 32,\n",
      "      \"max_position_embeddings\": 128\n",
      "    },\n",
      "    \"summarization_large\": {\n",
      "      \"length_penalty\": 0.8,\n",
      "      \"max_length\": 256,\n",
      "      \"max_position_embeddings\": 1024\n",
      "    },\n",
      "    \"summarization_multi_news\": {\n",
      "      \"length_penalty\": 0.8,\n",
      "      \"max_length\": 256,\n",
      "      \"max_position_embeddings\": 1024\n",
      "    },\n",
      "    \"summarization_newsroom\": {\n",
      "      \"length_penalty\": 0.8,\n",
      "      \"max_length\": 128,\n",
      "      \"max_position_embeddings\": 512\n",
      "    },\n",
      "    \"summarization_pubmed\": {\n",
      "      \"length_penalty\": 0.8,\n",
      "      \"max_length\": 256,\n",
      "      \"max_position_embeddings\": 1024\n",
      "    },\n",
      "    \"summarization_reddit_tifu\": {\n",
      "      \"length_penalty\": 0.6,\n",
      "      \"max_length\": 128,\n",
      "      \"max_position_embeddings\": 512\n",
      "    },\n",
      "    \"summarization_wikihow\": {\n",
      "      \"length_penalty\": 0.6,\n",
      "      \"max_length\": 256,\n",
      "      \"max_position_embeddings\": 512\n",
      "    },\n",
      "    \"summarization_xsum\": {\n",
      "      \"length_penalty\": 0.8,\n",
      "      \"max_length\": 64,\n",
      "      \"max_position_embeddings\": 512\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 96103\n",
      "}\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Couldn't instantiate the backend tokenizer from one of: \n(1) a `tokenizers` library serialization file, \n(2) a slow tokenizer instance to convert or \n(3) an equivalent slow tokenizer class to instantiate and convert. \nYou need to have sentencepiece installed to convert a slow tokenizer to a fast one.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[77], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trainfunction(model_checkpoint,tokenized_datasets,model_name\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mpegasus\u001b[39;49m\u001b[39m'\u001b[39;49m,batch_size\u001b[39m=\u001b[39;49m\u001b[39m8\u001b[39;49m,num_train_epochs\u001b[39m=\u001b[39;49m\u001b[39m8\u001b[39;49m,learning_rate\u001b[39m=\u001b[39;49m\u001b[39m5.6e-5\u001b[39;49m,weight_decay\u001b[39m=\u001b[39;49m\u001b[39m0.01\u001b[39;49m,save_total_limit\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m)\n",
      "Cell \u001b[0;32mIn[72], line 4\u001b[0m, in \u001b[0;36mtrainfunction\u001b[0;34m(model_checkpoint, tokenized_datasets, model_name, batch_size, num_train_epochs, learning_rate, weight_decay, save_total_limit)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrainfunction\u001b[39m(model_checkpoint,tokenized_datasets,model_name,batch_size\u001b[39m=\u001b[39m\u001b[39m8\u001b[39m,num_train_epochs\u001b[39m=\u001b[39m\u001b[39m8\u001b[39m,learning_rate\u001b[39m=\u001b[39m\u001b[39m5.6e-5\u001b[39m,weight_decay\u001b[39m=\u001b[39m\u001b[39m0.01\u001b[39m,save_total_limit\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m):\n\u001b[1;32m      3\u001b[0m     model \u001b[39m=\u001b[39m AutoModelForSeq2SeqLM\u001b[39m.\u001b[39mfrom_pretrained(model_checkpoint)\n\u001b[0;32m----> 4\u001b[0m     tokenizer \u001b[39m=\u001b[39m AutoTokenizer\u001b[39m.\u001b[39;49mfrom_pretrained(model_checkpoint)\n\u001b[1;32m      5\u001b[0m     \u001b[39m# Show the training loss with every epoch\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     logging_steps \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(tokenized_datasets[\u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m]) \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m batch_size\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/torch/lib/python3.9/site-packages/transformers/models/auto/tokenization_auto.py:637\u001b[0m, in \u001b[0;36mAutoTokenizer.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    635\u001b[0m tokenizer_class_py, tokenizer_class_fast \u001b[39m=\u001b[39m TOKENIZER_MAPPING[\u001b[39mtype\u001b[39m(config)]\n\u001b[1;32m    636\u001b[0m \u001b[39mif\u001b[39;00m tokenizer_class_fast \u001b[39mand\u001b[39;00m (use_fast \u001b[39mor\u001b[39;00m tokenizer_class_py \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 637\u001b[0m     \u001b[39mreturn\u001b[39;00m tokenizer_class_fast\u001b[39m.\u001b[39;49mfrom_pretrained(pretrained_model_name_or_path, \u001b[39m*\u001b[39;49minputs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    638\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    639\u001b[0m     \u001b[39mif\u001b[39;00m tokenizer_class_py \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/torch/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:1777\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   1774\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1775\u001b[0m         logger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mloading file \u001b[39m\u001b[39m{\u001b[39;00mfile_path\u001b[39m}\u001b[39;00m\u001b[39m from cache at \u001b[39m\u001b[39m{\u001b[39;00mresolved_vocab_files[file_id]\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 1777\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m_from_pretrained(\n\u001b[1;32m   1778\u001b[0m     resolved_vocab_files,\n\u001b[1;32m   1779\u001b[0m     pretrained_model_name_or_path,\n\u001b[1;32m   1780\u001b[0m     init_configuration,\n\u001b[1;32m   1781\u001b[0m     \u001b[39m*\u001b[39;49minit_inputs,\n\u001b[1;32m   1782\u001b[0m     use_auth_token\u001b[39m=\u001b[39;49muse_auth_token,\n\u001b[1;32m   1783\u001b[0m     cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[1;32m   1784\u001b[0m     local_files_only\u001b[39m=\u001b[39;49mlocal_files_only,\n\u001b[1;32m   1785\u001b[0m     _commit_hash\u001b[39m=\u001b[39;49mcommit_hash,\n\u001b[1;32m   1786\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m   1787\u001b[0m )\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/torch/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:1932\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase._from_pretrained\u001b[0;34m(cls, resolved_vocab_files, pretrained_model_name_or_path, init_configuration, use_auth_token, cache_dir, local_files_only, _commit_hash, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   1930\u001b[0m \u001b[39m# Instantiate tokenizer.\u001b[39;00m\n\u001b[1;32m   1931\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1932\u001b[0m     tokenizer \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m(\u001b[39m*\u001b[39;49minit_inputs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49minit_kwargs)\n\u001b[1;32m   1933\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m:\n\u001b[1;32m   1934\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mOSError\u001b[39;00m(\n\u001b[1;32m   1935\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mUnable to load vocabulary from file. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1936\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPlease check that the provided vocabulary is accessible and not corrupted.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1937\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/torch/lib/python3.9/site-packages/transformers/models/pegasus/tokenization_pegasus_fast.py:142\u001b[0m, in \u001b[0;36mPegasusTokenizerFast.__init__\u001b[0;34m(self, vocab_file, tokenizer_file, pad_token, eos_token, unk_token, mask_token, mask_token_sent, additional_special_tokens, offset, **kwargs)\u001b[0m\n\u001b[1;32m    139\u001b[0m     additional_special_tokens \u001b[39m=\u001b[39m [mask_token_sent] \u001b[39mif\u001b[39;00m mask_token_sent \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m []\n\u001b[1;32m    140\u001b[0m     additional_special_tokens \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m [\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m<unk_\u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m>\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m2\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moffset)]\n\u001b[0;32m--> 142\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\n\u001b[1;32m    143\u001b[0m     vocab_file,\n\u001b[1;32m    144\u001b[0m     tokenizer_file\u001b[39m=\u001b[39;49mtokenizer_file,\n\u001b[1;32m    145\u001b[0m     pad_token\u001b[39m=\u001b[39;49mpad_token,\n\u001b[1;32m    146\u001b[0m     eos_token\u001b[39m=\u001b[39;49meos_token,\n\u001b[1;32m    147\u001b[0m     unk_token\u001b[39m=\u001b[39;49munk_token,\n\u001b[1;32m    148\u001b[0m     mask_token\u001b[39m=\u001b[39;49mmask_token,\n\u001b[1;32m    149\u001b[0m     mask_token_sent\u001b[39m=\u001b[39;49mmask_token_sent,\n\u001b[1;32m    150\u001b[0m     offset\u001b[39m=\u001b[39;49moffset,\n\u001b[1;32m    151\u001b[0m     additional_special_tokens\u001b[39m=\u001b[39;49madditional_special_tokens,\n\u001b[1;32m    152\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    153\u001b[0m )\n\u001b[1;32m    154\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvocab_file \u001b[39m=\u001b[39m vocab_file\n\u001b[1;32m    155\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcan_save_slow_tokenizer \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvocab_file \u001b[39melse\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/torch/lib/python3.9/site-packages/transformers/tokenization_utils_fast.py:120\u001b[0m, in \u001b[0;36mPreTrainedTokenizerFast.__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m     fast_tokenizer \u001b[39m=\u001b[39m convert_slow_tokenizer(slow_tokenizer)\n\u001b[1;32m    119\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 120\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    121\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCouldn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt instantiate the backend tokenizer from one of: \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    122\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m(1) a `tokenizers` library serialization file, \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    123\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m(2) a slow tokenizer instance to convert or \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    124\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m(3) an equivalent slow tokenizer class to instantiate and convert. \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    125\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mYou need to have sentencepiece installed to convert a slow tokenizer to a fast one.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    126\u001b[0m     )\n\u001b[1;32m    128\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tokenizer \u001b[39m=\u001b[39m fast_tokenizer\n\u001b[1;32m    130\u001b[0m \u001b[39mif\u001b[39;00m slow_tokenizer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: Couldn't instantiate the backend tokenizer from one of: \n(1) a `tokenizers` library serialization file, \n(2) a slow tokenizer instance to convert or \n(3) an equivalent slow tokenizer class to instantiate and convert. \nYou need to have sentencepiece installed to convert a slow tokenizer to a fast one."
     ]
    }
   ],
   "source": [
    "trainfunction(model_checkpoint,tokenized_datasets,model_name=model_name,batch_size=8,num_train_epochs=8,learning_rate=5.6e-5,weight_decay=0.01,save_total_limit=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>classification</th>\n",
       "      <th>text</th>\n",
       "      <th>sentences</th>\n",
       "      <th>num_sentences</th>\n",
       "      <th>words</th>\n",
       "      <th>num_words</th>\n",
       "      <th>lemmas</th>\n",
       "      <th>stops</th>\n",
       "      <th>num_stops</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Scientific</td>\n",
       "      <td>the past few years witnessed a growing interes...</td>\n",
       "      <td>['the past few years witnessed a growing inter...</td>\n",
       "      <td>123</td>\n",
       "      <td>['past', 'years', 'witnessed', 'growing', 'int...</td>\n",
       "      <td>2001</td>\n",
       "      <td>['past', 'year', 'witness', 'grow', 'interest'...</td>\n",
       "      <td>[the, few, a, among, and, toward, with, was, b...</td>\n",
       "      <td>1263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Scientific</td>\n",
       "      <td>a standing sound wave in a tube with an open e...</td>\n",
       "      <td>['a standing sound wave in a tube with an open...</td>\n",
       "      <td>55</td>\n",
       "      <td>['standing', 'sound', 'wave', 'tube', 'open', ...</td>\n",
       "      <td>796</td>\n",
       "      <td>['stand', 'sound', 'wave', 'tube', 'open', 'en...</td>\n",
       "      <td>[a, in, a, with, an, has, an, the, a, is, the,...</td>\n",
       "      <td>592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Scientific</td>\n",
       "      <td>quantum mechanics does not allow the joint mea...</td>\n",
       "      <td>['quantum mechanics does not allow the joint m...</td>\n",
       "      <td>259</td>\n",
       "      <td>['quantum', 'mechanics', 'allow', 'joint', 'me...</td>\n",
       "      <td>4923</td>\n",
       "      <td>['quantum', 'mechanic', 'allow', 'joint', 'mea...</td>\n",
       "      <td>[does, not, the, of, as, on, the, of, of, the,...</td>\n",
       "      <td>3477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Scientific</td>\n",
       "      <td>inner rings and pseudo - rings are evident in ...</td>\n",
       "      <td>['inner rings and pseudo - rings are evident i...</td>\n",
       "      <td>14</td>\n",
       "      <td>['inner', 'rings', 'pseudo', 'rings', 'evident...</td>\n",
       "      <td>540</td>\n",
       "      <td>['inner', 'ring', 'pseudo', 'ring', 'evident',...</td>\n",
       "      <td>[and, are, in, of, all, and, in, more, than, o...</td>\n",
       "      <td>213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Scientific</td>\n",
       "      <td>pesin s theorem @xcite prescribes the equality...</td>\n",
       "      <td>['pesin s theorem @xcite prescribes the equali...</td>\n",
       "      <td>66</td>\n",
       "      <td>['pesin', 's', 'theorem', '@xcite', 'prescribe...</td>\n",
       "      <td>2037</td>\n",
       "      <td>['pesin', 's', 'theorem', '@xcite', 'prescribe...</td>\n",
       "      <td>[the, of, the, with, the, of, the, of, a, the,...</td>\n",
       "      <td>1570</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 classification  \\\n",
       "0           0     Scientific   \n",
       "1           1     Scientific   \n",
       "2           2     Scientific   \n",
       "3           3     Scientific   \n",
       "4           4     Scientific   \n",
       "\n",
       "                                                text  \\\n",
       "0  the past few years witnessed a growing interes...   \n",
       "1  a standing sound wave in a tube with an open e...   \n",
       "2  quantum mechanics does not allow the joint mea...   \n",
       "3  inner rings and pseudo - rings are evident in ...   \n",
       "4  pesin s theorem @xcite prescribes the equality...   \n",
       "\n",
       "                                           sentences  num_sentences  \\\n",
       "0  ['the past few years witnessed a growing inter...            123   \n",
       "1  ['a standing sound wave in a tube with an open...             55   \n",
       "2  ['quantum mechanics does not allow the joint m...            259   \n",
       "3  ['inner rings and pseudo - rings are evident i...             14   \n",
       "4  ['pesin s theorem @xcite prescribes the equali...             66   \n",
       "\n",
       "                                               words  num_words  \\\n",
       "0  ['past', 'years', 'witnessed', 'growing', 'int...       2001   \n",
       "1  ['standing', 'sound', 'wave', 'tube', 'open', ...        796   \n",
       "2  ['quantum', 'mechanics', 'allow', 'joint', 'me...       4923   \n",
       "3  ['inner', 'rings', 'pseudo', 'rings', 'evident...        540   \n",
       "4  ['pesin', 's', 'theorem', '@xcite', 'prescribe...       2037   \n",
       "\n",
       "                                              lemmas  \\\n",
       "0  ['past', 'year', 'witness', 'grow', 'interest'...   \n",
       "1  ['stand', 'sound', 'wave', 'tube', 'open', 'en...   \n",
       "2  ['quantum', 'mechanic', 'allow', 'joint', 'mea...   \n",
       "3  ['inner', 'ring', 'pseudo', 'ring', 'evident',...   \n",
       "4  ['pesin', 's', 'theorem', '@xcite', 'prescribe...   \n",
       "\n",
       "                                               stops  num_stops  \n",
       "0  [the, few, a, among, and, toward, with, was, b...       1263  \n",
       "1  [a, in, a, with, an, has, an, the, a, is, the,...        592  \n",
       "2  [does, not, the, of, as, on, the, of, of, the,...       3477  \n",
       "3  [and, are, in, of, all, and, in, more, than, o...        213  \n",
       "4  [the, of, the, with, the, of, the, of, a, the,...       1570  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test=pd.read_csv('data/data_test_with_features.csv')\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x1000 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Berechnung der durchschnittlichen Wortanzahl pro Satz\n",
    "df_test['avg_words_per_sentence'] = df_test['num_words'] / df_test['num_sentences']\n",
    "\n",
    "# Erstellung der Boxplots\n",
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "sns.boxplot(y=df_test['num_words'])\n",
    "plt.title('Verteilung der Wortanzahl')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "sns.boxplot(y=df_test['num_sentences'])\n",
    "plt.title('Verteilung der Satzanzahl')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "sns.boxplot(y=df_test['avg_words_per_sentence'])\n",
    "plt.title('Verteilung der durchschnittlichen Wortanzahl pro Satz')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistiken für 'num_words':\n",
      "Mean:  1115.84\n",
      "Std:  1647.159849213511\n",
      "Min:  7\n",
      "Max:  13136\n",
      "\n",
      "\n",
      "Statistiken für 'num_sentences':\n",
      "Mean:  84.355\n",
      "Std:  113.28428017677015\n",
      "Min:  1\n",
      "Max:  664\n",
      "\n",
      "\n",
      "Statistiken für 'avg_words_per_sentence':\n",
      "Mean:  12.057614521179525\n",
      "Std:  7.371799227471006\n",
      "Min:  1.75\n",
      "Max:  60.61875\n"
     ]
    }
   ],
   "source": [
    "# Ausdrucken des Durchschnitts, der Standardabweichung, des Minimums und des Maximums für 'num_words'\n",
    "print(\"Statistiken für 'num_words':\")\n",
    "print(\"Mean: \", df_test['num_words'].mean())\n",
    "print(\"Std: \", df_test['num_words'].std())\n",
    "print(\"Min: \", df_test['num_words'].min())\n",
    "print(\"Max: \", df_test['num_words'].max())\n",
    "\n",
    "print(\"\\n\")  # Zeilenumbruch für die Lesbarkeit\n",
    "\n",
    "# Ausdrucken des Durchschnitts, der Standardabweichung, des Minimums und des Maximums für 'num_sentences'\n",
    "print(\"Statistiken für 'num_sentences':\")\n",
    "print(\"Mean: \", df_test['num_sentences'].mean())\n",
    "print(\"Std: \", df_test['num_sentences'].std())\n",
    "print(\"Min: \", df_test['num_sentences'].min())\n",
    "print(\"Max: \", df_test['num_sentences'].max())\n",
    "\n",
    "print(\"\\n\")  # Zeilenumbruch für die Lesbarkeit\n",
    "\n",
    "# Ausdrucken des Durchschnitts, der Standardabweichung, des Minimums und des Maximums für 'avg_words_per_sentence'\n",
    "print(\"Statistiken für 'avg_words_per_sentence':\")\n",
    "print(\"Mean: \", df_test['avg_words_per_sentence'].mean())\n",
    "print(\"Std: \", df_test['avg_words_per_sentence'].std())\n",
    "print(\"Min: \", df_test['avg_words_per_sentence'].min())\n",
    "print(\"Max: \", df_test['avg_words_per_sentence'].max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl der Sätze, die bei 1024 Wörtern genutzt werden können:  84\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "# Durchschnittliche Anzahl an Wörtern pro Satz berechnen\n",
    "mean_words_per_sentence = df_test['avg_words_per_sentence'].mean()\n",
    "\n",
    "# Anzahl der Sätze berechnen, die bei 1024 Wörtern genutzt werden können\n",
    "num_sentences = math.floor(1024 / mean_words_per_sentence)\n",
    "\n",
    "print(\"Anzahl der Sätze, die bei 1024 Wörtern genutzt werden können: \", num_sentences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Länge der ersten Zeile:  22273\n"
     ]
    }
   ],
   "source": [
    "first_line = df_test['text'].iloc[0]  # Zugriff auf die erste Zeile der Spalte \"text\"\n",
    "\n",
    "#print(\"Erste Zeile: \", first_line)\n",
    "print(\"Länge der ersten Zeile: \", len(first_line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BartForConditionalGeneration, BartTokenizer\n",
    "\n",
    "# Wählen Sie das gewünschte Modell\n",
    "model_name = 'facebook/bart-large-cnn'\n",
    "# Laden Sie das Modell und den Tokenizer\n",
    "model = BartForConditionalGeneration.from_pretrained(model_name)\n",
    "tokenizer = BartTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Ihr Ausgangstext\n",
    "original_text =first_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Berechnen Sie die gewünschten Mindest- und Maximallängen basierend auf der Kompressionsrate\n",
    "compression_rate_min = 70  # 20%\n",
    "compression_rate_max = 80  # 80%\n",
    "min_length = len(tokenizer(original_text)['input_ids']) * compression_rate_min // 100\n",
    "max_length = len(tokenizer(original_text)['input_ids']) * compression_rate_max // 100\n",
    "\n",
    "# Generieren Sie die Zusammenfassung\n",
    "inputs = tokenizer([original_text], max_length=len(original_text), return_tensors='pt')\n",
    "summary_ids = model.generate(inputs['input_ids'], num_beams=4, min_length=min_length, max_length=max_length, early_stopping=True)\n",
    "summary = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=False) for g in summary_ids]\n",
    "\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (5669 > 1024). Running this sequence through the model will result in indexing errors\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index out of range in self",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 23\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[39m# Generieren Sie die Zusammenfassung\u001b[39;00m\n\u001b[1;32m     22\u001b[0m inputs \u001b[39m=\u001b[39m tokenizer([original_text], max_length\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(original_text), return_tensors\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 23\u001b[0m summary_ids \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mgenerate(inputs[\u001b[39m'\u001b[39;49m\u001b[39minput_ids\u001b[39;49m\u001b[39m'\u001b[39;49m], num_beams\u001b[39m=\u001b[39;49m\u001b[39m4\u001b[39;49m, min_length\u001b[39m=\u001b[39;49mmin_length, max_length\u001b[39m=\u001b[39;49mmax_length, early_stopping\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m     24\u001b[0m summary \u001b[39m=\u001b[39m [tokenizer\u001b[39m.\u001b[39mdecode(g, skip_special_tokens\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, clean_up_tokenization_spaces\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m) \u001b[39mfor\u001b[39;00m g \u001b[39min\u001b[39;00m summary_ids]\n\u001b[1;32m     26\u001b[0m \u001b[39m# Bestimmen Sie die tatsächliche Kompressionsrate der generierten Zusammenfassung\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/torch/lib/python3.9/site-packages/torch/autograd/grad_mode.py:34\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m     32\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     33\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclone():\n\u001b[0;32m---> 34\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/torch/lib/python3.9/site-packages/transformers/generation_utils.py:1339\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, max_length, min_length, do_sample, early_stopping, num_beams, temperature, penalty_alpha, top_k, top_p, typical_p, repetition_penalty, bad_words_ids, force_words_ids, bos_token_id, pad_token_id, eos_token_id, length_penalty, no_repeat_ngram_size, encoder_no_repeat_ngram_size, num_return_sequences, max_time, max_new_tokens, decoder_start_token_id, use_cache, num_beam_groups, diversity_penalty, prefix_allowed_tokens_fn, logits_processor, renormalize_logits, stopping_criteria, constraints, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, forced_bos_token_id, forced_eos_token_id, remove_invalid_values, synced_gpus, exponential_decay_length_penalty, suppress_tokens, begin_suppress_tokens, forced_decoder_ids, **model_kwargs)\u001b[0m\n\u001b[1;32m   1331\u001b[0m         logger\u001b[39m.\u001b[39mwarning(\n\u001b[1;32m   1332\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mA decoder-only architecture is being used, but right-padding was detected! For correct \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1333\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mgeneration results, please set `padding_side=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mleft\u001b[39m\u001b[39m'\u001b[39m\u001b[39m` when initializing the tokenizer.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1334\u001b[0m         )\n\u001b[1;32m   1336\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mis_encoder_decoder \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mencoder_outputs\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m model_kwargs:\n\u001b[1;32m   1337\u001b[0m     \u001b[39m# if model is encoder decoder encoder_outputs are created\u001b[39;00m\n\u001b[1;32m   1338\u001b[0m     \u001b[39m# and added to `model_kwargs`\u001b[39;00m\n\u001b[0;32m-> 1339\u001b[0m     model_kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_prepare_encoder_decoder_kwargs_for_generation(\n\u001b[1;32m   1340\u001b[0m         inputs_tensor, model_kwargs, model_input_name\n\u001b[1;32m   1341\u001b[0m     )\n\u001b[1;32m   1343\u001b[0m \u001b[39m# 4. Prepare `input_ids` which will be used for auto-regressive generation\u001b[39;00m\n\u001b[1;32m   1344\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mis_encoder_decoder:\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/torch/lib/python3.9/site-packages/transformers/generation_utils.py:583\u001b[0m, in \u001b[0;36mGenerationMixin._prepare_encoder_decoder_kwargs_for_generation\u001b[0;34m(self, inputs_tensor, model_kwargs, model_input_name)\u001b[0m\n\u001b[1;32m    581\u001b[0m encoder_kwargs[\u001b[39m\"\u001b[39m\u001b[39mreturn_dict\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    582\u001b[0m encoder_kwargs[model_input_name] \u001b[39m=\u001b[39m inputs_tensor\n\u001b[0;32m--> 583\u001b[0m model_kwargs[\u001b[39m\"\u001b[39m\u001b[39mencoder_outputs\u001b[39m\u001b[39m\"\u001b[39m]: ModelOutput \u001b[39m=\u001b[39m encoder(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mencoder_kwargs)\n\u001b[1;32m    585\u001b[0m \u001b[39mreturn\u001b[39;00m model_kwargs\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py:1482\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1477\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1478\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1479\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1480\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1481\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1482\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1483\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1484\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/torch/lib/python3.9/site-packages/transformers/models/bart/modeling_bart.py:804\u001b[0m, in \u001b[0;36mBartEncoder.forward\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    801\u001b[0m \u001b[39mif\u001b[39;00m inputs_embeds \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    802\u001b[0m     inputs_embeds \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membed_tokens(input_ids) \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membed_scale\n\u001b[0;32m--> 804\u001b[0m embed_pos \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49membed_positions(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    805\u001b[0m embed_pos \u001b[39m=\u001b[39m embed_pos\u001b[39m.\u001b[39mto(inputs_embeds\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m    807\u001b[0m hidden_states \u001b[39m=\u001b[39m inputs_embeds \u001b[39m+\u001b[39m embed_pos\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py:1482\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1477\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1478\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1479\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1480\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1481\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1482\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1483\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1484\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/torch/lib/python3.9/site-packages/transformers/models/bart/modeling_bart.py:139\u001b[0m, in \u001b[0;36mBartLearnedPositionalEmbedding.forward\u001b[0;34m(self, input_ids, past_key_values_length)\u001b[0m\n\u001b[1;32m    134\u001b[0m bsz, seq_len \u001b[39m=\u001b[39m input_ids\u001b[39m.\u001b[39mshape[:\u001b[39m2\u001b[39m]\n\u001b[1;32m    135\u001b[0m positions \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39marange(\n\u001b[1;32m    136\u001b[0m     past_key_values_length, past_key_values_length \u001b[39m+\u001b[39m seq_len, dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mlong, device\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweight\u001b[39m.\u001b[39mdevice\n\u001b[1;32m    137\u001b[0m )\u001b[39m.\u001b[39mexpand(bsz, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m--> 139\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mforward(positions \u001b[39m+\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moffset)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/sparse.py:162\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 162\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49membedding(\n\u001b[1;32m    163\u001b[0m         \u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding_idx, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_norm,\n\u001b[1;32m    164\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnorm_type, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mscale_grad_by_freq, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msparse)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/torch/lib/python3.9/site-packages/torch/nn/functional.py:2210\u001b[0m, in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2204\u001b[0m     \u001b[39m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[1;32m   2205\u001b[0m     \u001b[39m# XXX: equivalent to\u001b[39;00m\n\u001b[1;32m   2206\u001b[0m     \u001b[39m# with torch.no_grad():\u001b[39;00m\n\u001b[1;32m   2207\u001b[0m     \u001b[39m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[1;32m   2208\u001b[0m     \u001b[39m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[1;32m   2209\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[39minput\u001b[39m, max_norm, norm_type)\n\u001b[0;32m-> 2210\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49membedding(weight, \u001b[39minput\u001b[39;49m, padding_idx, scale_grad_by_freq, sparse)\n",
      "\u001b[0;31mIndexError\u001b[0m: index out of range in self"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Initialisiere leeren DataFrame\n",
    "df_summary_testing = pd.DataFrame(columns=['Min_Kompressionsrate', 'Max_Kompressionsrate', 'Endgueltige_Kompressionsrate', 'Zusammenfassung'])\n",
    "\n",
    "# Ausgangstextlänge\n",
    "original_length = len(tokenizer(original_text)['input_ids'])\n",
    "\n",
    "# Liste der Kompressionsraten\n",
    "compression_rates = range(20, 81, 10)  # Werte von 20 bis 80 mit Schrittgröße 10\n",
    "\n",
    "# Für jede Kompressionsrate\n",
    "for rate in compression_rates:\n",
    "    compression_rate_min = rate\n",
    "    compression_rate_max = rate + 10 if rate + 10 <= 80 else 80  # Stellen Sie sicher, dass die max_rate 80 nicht überschreitet\n",
    "\n",
    "    # Berechnen Sie die Mindest- und Maximallänge\n",
    "    min_length = original_length * compression_rate_min // 100\n",
    "    max_length = original_length * compression_rate_max // 100\n",
    "\n",
    "    # Generieren Sie die Zusammenfassung\n",
    "    inputs = tokenizer([original_text], max_length=len(original_text), return_tensors='pt')\n",
    "    summary_ids = model.generate(inputs['input_ids'], num_beams=4, min_length=min_length, max_length=max_length, early_stopping=True)\n",
    "    summary = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=False) for g in summary_ids]\n",
    "    \n",
    "    # Bestimmen Sie die tatsächliche Kompressionsrate der generierten Zusammenfassung\n",
    "    summary_length = len(tokenizer(summary[0])['input_ids'])\n",
    "    actual_compression_rate = summary_length / original_length * 100\n",
    "\n",
    "    # Fügen Sie die Daten zum DataFrame hinzu\n",
    "    df_summary_testing = df_summary_testing.append({\n",
    "        'Min_Kompressionsrate': compression_rate_min,\n",
    "        'Max_Kompressionsrate': compression_rate_max,\n",
    "        'Endgueltige_Kompressionsrate': actual_compression_rate,\n",
    "        'Zusammenfassung': summary[0]\n",
    "    }, ignore_index=True)\n",
    "\n",
    "# Zeige den DataFrame\n",
    "print(df_summary_testing)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204\n",
      "307\n"
     ]
    }
   ],
   "source": [
    "print(original_length * compression_rate_min // 100)\n",
    "print(original_length * compression_rate_max // 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k3/z_svrdgd6sb9lc9bqdfzp_k00000gn/T/ipykernel_3271/3005128698.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_summary_testing = df_summary_testing.append({\n",
      "/var/folders/k3/z_svrdgd6sb9lc9bqdfzp_k00000gn/T/ipykernel_3271/3005128698.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_summary_testing = df_summary_testing.append({\n",
      "/var/folders/k3/z_svrdgd6sb9lc9bqdfzp_k00000gn/T/ipykernel_3271/3005128698.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_summary_testing = df_summary_testing.append({\n",
      "/var/folders/k3/z_svrdgd6sb9lc9bqdfzp_k00000gn/T/ipykernel_3271/3005128698.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_summary_testing = df_summary_testing.append({\n",
      "/var/folders/k3/z_svrdgd6sb9lc9bqdfzp_k00000gn/T/ipykernel_3271/3005128698.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_summary_testing = df_summary_testing.append({\n",
      "/var/folders/k3/z_svrdgd6sb9lc9bqdfzp_k00000gn/T/ipykernel_3271/3005128698.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_summary_testing = df_summary_testing.append({\n",
      "/var/folders/k3/z_svrdgd6sb9lc9bqdfzp_k00000gn/T/ipykernel_3271/3005128698.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_summary_testing = df_summary_testing.append({\n"
     ]
    }
   ],
   "source": [
    "for rate in compression_rates:\n",
    "    compression_rate_min = rate\n",
    "    compression_rate_max = rate + 10 if rate + 10 <= 80 else 80  # Stellen Sie sicher, dass die max_rate 80 nicht überschreitet\n",
    "\n",
    "    # Trunkieren Sie den Originaltext auf die maximale Länge, die das Modell verarbeiten kann (in diesem Fall 1024 Token)\n",
    "    inputs = tokenizer([original_text], truncation=True, max_length=1024, padding='max_length', return_tensors='pt')\n",
    "\n",
    "    # Originaltextlänge nach der Trunkierung\n",
    "    original_length = len(inputs['input_ids'][0])\n",
    "\n",
    "    # Berechnen Sie die Mindest- und Maximallänge\n",
    "    min_length_test = original_length * compression_rate_min // 100\n",
    "    max_length_test = original_length * compression_rate_max // 100\n",
    "\n",
    "    # Prüfen Sie, ob die Mindest- und Maximallänge innerhalb des zulässigen Bereichs liegt\n",
    "    min_length = max(1, min_length)  # min_length muss mindestens 1 sein\n",
    "    max_length = min(max_length, model.config.max_length)  # max_length darf nicht länger als die maximale Länge des Modells sein\n",
    "\n",
    "    # Generieren Sie die Zusammenfassung\n",
    "    summary_ids = model.generate(inputs['input_ids'], num_beams=4, min_length=min_length_test, max_length=max_length_test, early_stopping=True)\n",
    "    summary = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=False) for g in summary_ids]\n",
    "\n",
    "    # Bestimmen Sie die tatsächliche Kompressionsrate der generierten Zusammenfassung\n",
    "    summary_length = len(tokenizer(summary[0])['input_ids'])\n",
    "    actual_compression_rate = summary_length / original_length * 100\n",
    "\n",
    "    # Fügen Sie die Daten zum DataFrame hinzu\n",
    "    df_summary_testing = df_summary_testing.append({\n",
    "        'Min_Kompressionsrate': compression_rate_min,\n",
    "        'Max_Kompressionsrate': compression_rate_max,\n",
    "        'Endgueltige_Kompressionsrate': actual_compression_rate,\n",
    "        'Zusammenfassung': summary[0]\n",
    "    }, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Min_Kompressionsrate</th>\n",
       "      <th>Max_Kompressionsrate</th>\n",
       "      <th>Endgueltige_Kompressionsrate</th>\n",
       "      <th>Zusammenfassung</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "      <td>21.484375</td>\n",
       "      <td>String theorists @xcite exploited a moderately...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>40</td>\n",
       "      <td>31.054688</td>\n",
       "      <td>String theorists @xcite exploited a moderately...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40</td>\n",
       "      <td>50</td>\n",
       "      <td>41.210938</td>\n",
       "      <td>String theorists @xcite exploited a moderately...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50</td>\n",
       "      <td>60</td>\n",
       "      <td>51.269531</td>\n",
       "      <td>String theorists @xcite exploited a moderately...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>70</td>\n",
       "      <td>61.718750</td>\n",
       "      <td>String theorists @xcite exploited a moderately...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>70</td>\n",
       "      <td>80</td>\n",
       "      <td>75.585938</td>\n",
       "      <td>String theorists @xcite exploited a moderately...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>79.101562</td>\n",
       "      <td>String theorists @xcite exploited a moderately...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Min_Kompressionsrate Max_Kompressionsrate  Endgueltige_Kompressionsrate  \\\n",
       "0                   20                   30                     21.484375   \n",
       "1                   30                   40                     31.054688   \n",
       "2                   40                   50                     41.210938   \n",
       "3                   50                   60                     51.269531   \n",
       "4                   60                   70                     61.718750   \n",
       "5                   70                   80                     75.585938   \n",
       "6                   80                   80                     79.101562   \n",
       "\n",
       "                                     Zusammenfassung  \n",
       "0  String theorists @xcite exploited a moderately...  \n",
       "1  String theorists @xcite exploited a moderately...  \n",
       "2  String theorists @xcite exploited a moderately...  \n",
       "3  String theorists @xcite exploited a moderately...  \n",
       "4  String theorists @xcite exploited a moderately...  \n",
       "5  String theorists @xcite exploited a moderately...  \n",
       "6  String theorists @xcite exploited a moderately...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_summary_testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'String theorists @xcite exploited a moderately large size of an external 11th dimension in order to reconcile the planck and string / gut scales. Large extra dimensions allow for a reduction of the fundamental higher - dimensional gravitational scale down to the tev - scale. These models are argued to make contact with an intricate phenomenology with a variety of consequences for collider searches, low - energy precision measurements, rare decays and astroparticle physics and cosmology.however, the mechanisms , responsible for the stabilization of extra dimensions , remain unknown. An alternative solution to the hierarchy problem was proposed in ref . This higher dimensional scenario is based on a non - factorizable geometry which accounts for the ratio between the plank scale and weak scales. The distance between the branes is associated with the vacuum expectation value of a massless four dimensional scalar field. For this scenario to be relevant, it is necessary to find a mechanism for generating a potential to stabilize the distance between branes. The problem of radion stabilization in hyperbolic brane - world scenarios is considered in the present paper.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_summary_testing[0:1].Zusammenfassung[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'String theorists @xcite exploited a moderately large size of an external 11th dimension in order to reconcile the planck and string / gut scales. Large extra dimensions allow for a reduction of the fundamental higher - dimensional gravitational scale down to the tev - scale. These models are argued to make contact with an intricate phenomenology with a variety of consequences for collider searches, low - energy precision measurements, rare decays and astroparticle physics and cosmology.however, the mechanisms , responsible for the stabilization of extra dimensions , remain unknown. An alternative solution to the hierarchy problem was proposed in ref . This higher dimensional scenario is based on a non - factorizable geometry which accounts for the ratio between the plank scale and weak scales. The distance between the branes is associated with the vacuum expectation value of a massless four dimensional scalar field. For this scenario to be relevant, it is necessary to find a mechanism for generating a potential to stabilize the distance between branes. The problem of radion stabilization in hyperbolic brane - world scenarios is considered in the present paper. The casimir energy - momentum tensor for these geometries can be generated from the corresponding flat spacetime results by using the standard transformation formula. We will consider the general plane symmetric solutions of the gravitational field equations and boundary conditions of the robin type on the brane. We need to have more general background domain domain wall conditions for more general models. We use the results of refite to generate vacuum momentum tensors for the flat boundaries of a general conformal coupling case to generate the energy tensor of the casimir effect for the general robin - world geometry as well as for flat boundaries. The results of this paper follows the results for the spherically symmetric backgrounds of the minkowski spacetasewasew as investigated in refs and in @xcites. The paper is organized as follows:\\xa0@xcite for the plane conformally flat backgrounds of a flat brane world geometry and the general\\xa0 robin-world geometry in terms of the general mass - terms and vacuum momentum\\xa0tensor of a conformally\\xa0coupled\\xa0scalar field on background of the conformallyflat brane- world geometry.\\xa0@xmath0 for a background randall  sundrum geometry ( see also @xcited for the case of the de sitter bulk ) .@xcites for a flat boundaries in the general spheric and cylindically cylrindically organized backgrounds of flat boundaries and in the cases of the dirichlet and neumann boundary conditions as special cases.    For the general Robin -world geometry and flat boundaries, we need to use the standard\\xa0spherically\\xa0organized vacuum energy-momentum tensor to generate a vacuum momentum Tensor for the\\xa0general robin\\xa0world\\xa0geometries.\\xa0The results of the paper follow the\\xa0standard transformation formula for the generic\\xa0Robin\\xa0Geometries in the flat\\xa0brane-world\\xa0case and for flat\\xa0 boundaries of the\\xa0minkowski\\xa0spacetas\\xa0and\\xa0the\\xa0neumann\\xa0Domain\\xa0of the Robin\\xa0World\\xa0as well as the\\xa0de sitter\\xa0World in the\\xa0refs\\xa0of refs\\xa0in refs in ref\\xa0in\\xa0ref\\xa0in the\\xa0past\\xa0and in\\xa0ref-in-refs in\\xa0#refs-in\\xa0the-past\\xa0in-the\\xa0past-and-ref-out-of-the-first-place-and\\xa0in this\\xa0paper\\xa0we\\xa0will\\xa0consider\\xa0the vacuum expectation values of the energy\\xa0momentus\\xa0on background of\\xa0the conformally coupled scalar\\xa0field on background\\xa0of\\xa0the flat\\xa0Brane-World\\xa0Geometry.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_summary_testing[5:6].Zusammenfassung[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "müssen den code verbessern oder ne gpu dran machen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'BertTokenizer'. \n",
      "The class this function is called from is 'PreTrainedTokenizerFast'.\n",
      "Using eos_token, but it is not set yet.\n",
      "/var/folders/k3/z_svrdgd6sb9lc9bqdfzp_k00000gn/T/ipykernel_3271/1734927330.py:54: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_summary_testing = df_summary_testing.append({\n",
      "/var/folders/k3/z_svrdgd6sb9lc9bqdfzp_k00000gn/T/ipykernel_3271/1734927330.py:54: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_summary_testing = df_summary_testing.append({\n",
      "/var/folders/k3/z_svrdgd6sb9lc9bqdfzp_k00000gn/T/ipykernel_3271/1734927330.py:54: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_summary_testing = df_summary_testing.append({\n",
      "/var/folders/k3/z_svrdgd6sb9lc9bqdfzp_k00000gn/T/ipykernel_3271/1734927330.py:54: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_summary_testing = df_summary_testing.append({\n",
      "/var/folders/k3/z_svrdgd6sb9lc9bqdfzp_k00000gn/T/ipykernel_3271/1734927330.py:54: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_summary_testing = df_summary_testing.append({\n",
      "/var/folders/k3/z_svrdgd6sb9lc9bqdfzp_k00000gn/T/ipykernel_3271/1734927330.py:54: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_summary_testing = df_summary_testing.append({\n",
      "/var/folders/k3/z_svrdgd6sb9lc9bqdfzp_k00000gn/T/ipykernel_3271/1734927330.py:54: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_summary_testing = df_summary_testing.append({\n",
      "/var/folders/k3/z_svrdgd6sb9lc9bqdfzp_k00000gn/T/ipykernel_3271/1734927330.py:54: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_summary_testing = df_summary_testing.append({\n",
      "/var/folders/k3/z_svrdgd6sb9lc9bqdfzp_k00000gn/T/ipykernel_3271/1734927330.py:54: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_summary_testing = df_summary_testing.append({\n",
      "/var/folders/k3/z_svrdgd6sb9lc9bqdfzp_k00000gn/T/ipykernel_3271/1734927330.py:54: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_summary_testing = df_summary_testing.append({\n",
      "/var/folders/k3/z_svrdgd6sb9lc9bqdfzp_k00000gn/T/ipykernel_3271/1734927330.py:54: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_summary_testing = df_summary_testing.append({\n",
      "/var/folders/k3/z_svrdgd6sb9lc9bqdfzp_k00000gn/T/ipykernel_3271/1734927330.py:54: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_summary_testing = df_summary_testing.append({\n",
      "/var/folders/k3/z_svrdgd6sb9lc9bqdfzp_k00000gn/T/ipykernel_3271/1734927330.py:54: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_summary_testing = df_summary_testing.append({\n",
      "/var/folders/k3/z_svrdgd6sb9lc9bqdfzp_k00000gn/T/ipykernel_3271/1734927330.py:54: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_summary_testing = df_summary_testing.append({\n",
      "/var/folders/k3/z_svrdgd6sb9lc9bqdfzp_k00000gn/T/ipykernel_3271/1734927330.py:54: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_summary_testing = df_summary_testing.append({\n",
      "/var/folders/k3/z_svrdgd6sb9lc9bqdfzp_k00000gn/T/ipykernel_3271/1734927330.py:54: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_summary_testing = df_summary_testing.append({\n",
      "/var/folders/k3/z_svrdgd6sb9lc9bqdfzp_k00000gn/T/ipykernel_3271/1734927330.py:54: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_summary_testing = df_summary_testing.append({\n",
      "/var/folders/k3/z_svrdgd6sb9lc9bqdfzp_k00000gn/T/ipykernel_3271/1734927330.py:54: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_summary_testing = df_summary_testing.append({\n",
      "/var/folders/k3/z_svrdgd6sb9lc9bqdfzp_k00000gn/T/ipykernel_3271/1734927330.py:54: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_summary_testing = df_summary_testing.append({\n",
      "/var/folders/k3/z_svrdgd6sb9lc9bqdfzp_k00000gn/T/ipykernel_3271/1734927330.py:54: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_summary_testing = df_summary_testing.append({\n",
      "/var/folders/k3/z_svrdgd6sb9lc9bqdfzp_k00000gn/T/ipykernel_3271/1734927330.py:54: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_summary_testing = df_summary_testing.append({\n",
      "/var/folders/k3/z_svrdgd6sb9lc9bqdfzp_k00000gn/T/ipykernel_3271/1734927330.py:54: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_summary_testing = df_summary_testing.append({\n",
      "/var/folders/k3/z_svrdgd6sb9lc9bqdfzp_k00000gn/T/ipykernel_3271/1734927330.py:54: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_summary_testing = df_summary_testing.append({\n",
      "/var/folders/k3/z_svrdgd6sb9lc9bqdfzp_k00000gn/T/ipykernel_3271/1734927330.py:54: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_summary_testing = df_summary_testing.append({\n",
      "/var/folders/k3/z_svrdgd6sb9lc9bqdfzp_k00000gn/T/ipykernel_3271/1734927330.py:54: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_summary_testing = df_summary_testing.append({\n",
      "/var/folders/k3/z_svrdgd6sb9lc9bqdfzp_k00000gn/T/ipykernel_3271/1734927330.py:54: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_summary_testing = df_summary_testing.append({\n",
      "/var/folders/k3/z_svrdgd6sb9lc9bqdfzp_k00000gn/T/ipykernel_3271/1734927330.py:54: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_summary_testing = df_summary_testing.append({\n",
      "/var/folders/k3/z_svrdgd6sb9lc9bqdfzp_k00000gn/T/ipykernel_3271/1734927330.py:54: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_summary_testing = df_summary_testing.append({\n",
      "/var/folders/k3/z_svrdgd6sb9lc9bqdfzp_k00000gn/T/ipykernel_3271/1734927330.py:54: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_summary_testing = df_summary_testing.append({\n",
      "/var/folders/k3/z_svrdgd6sb9lc9bqdfzp_k00000gn/T/ipykernel_3271/1734927330.py:54: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_summary_testing = df_summary_testing.append({\n",
      "/var/folders/k3/z_svrdgd6sb9lc9bqdfzp_k00000gn/T/ipykernel_3271/1734927330.py:54: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_summary_testing = df_summary_testing.append({\n",
      "/var/folders/k3/z_svrdgd6sb9lc9bqdfzp_k00000gn/T/ipykernel_3271/1734927330.py:54: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_summary_testing = df_summary_testing.append({\n",
      "/var/folders/k3/z_svrdgd6sb9lc9bqdfzp_k00000gn/T/ipykernel_3271/1734927330.py:54: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_summary_testing = df_summary_testing.append({\n",
      "/var/folders/k3/z_svrdgd6sb9lc9bqdfzp_k00000gn/T/ipykernel_3271/1734927330.py:54: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_summary_testing = df_summary_testing.append({\n",
      "/var/folders/k3/z_svrdgd6sb9lc9bqdfzp_k00000gn/T/ipykernel_3271/1734927330.py:54: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_summary_testing = df_summary_testing.append({\n",
      "/var/folders/k3/z_svrdgd6sb9lc9bqdfzp_k00000gn/T/ipykernel_3271/1734927330.py:54: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_summary_testing = df_summary_testing.append({\n",
      "/var/folders/k3/z_svrdgd6sb9lc9bqdfzp_k00000gn/T/ipykernel_3271/1734927330.py:54: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_summary_testing = df_summary_testing.append({\n",
      "/var/folders/k3/z_svrdgd6sb9lc9bqdfzp_k00000gn/T/ipykernel_3271/1734927330.py:54: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_summary_testing = df_summary_testing.append({\n",
      "/var/folders/k3/z_svrdgd6sb9lc9bqdfzp_k00000gn/T/ipykernel_3271/1734927330.py:54: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_summary_testing = df_summary_testing.append({\n",
      "/var/folders/k3/z_svrdgd6sb9lc9bqdfzp_k00000gn/T/ipykernel_3271/1734927330.py:54: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_summary_testing = df_summary_testing.append({\n",
      "/var/folders/k3/z_svrdgd6sb9lc9bqdfzp_k00000gn/T/ipykernel_3271/1734927330.py:54: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_summary_testing = df_summary_testing.append({\n",
      "/var/folders/k3/z_svrdgd6sb9lc9bqdfzp_k00000gn/T/ipykernel_3271/1734927330.py:54: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_summary_testing = df_summary_testing.append({\n",
      "/var/folders/k3/z_svrdgd6sb9lc9bqdfzp_k00000gn/T/ipykernel_3271/1734927330.py:54: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_summary_testing = df_summary_testing.append({\n",
      "/var/folders/k3/z_svrdgd6sb9lc9bqdfzp_k00000gn/T/ipykernel_3271/1734927330.py:54: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_summary_testing = df_summary_testing.append({\n",
      "/var/folders/k3/z_svrdgd6sb9lc9bqdfzp_k00000gn/T/ipykernel_3271/1734927330.py:54: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_summary_testing = df_summary_testing.append({\n",
      "/var/folders/k3/z_svrdgd6sb9lc9bqdfzp_k00000gn/T/ipykernel_3271/1734927330.py:54: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_summary_testing = df_summary_testing.append({\n",
      "/var/folders/k3/z_svrdgd6sb9lc9bqdfzp_k00000gn/T/ipykernel_3271/1734927330.py:54: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_summary_testing = df_summary_testing.append({\n",
      "/var/folders/k3/z_svrdgd6sb9lc9bqdfzp_k00000gn/T/ipykernel_3271/1734927330.py:54: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_summary_testing = df_summary_testing.append({\n",
      "/var/folders/k3/z_svrdgd6sb9lc9bqdfzp_k00000gn/T/ipykernel_3271/1734927330.py:54: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_summary_testing = df_summary_testing.append({\n"
     ]
    }
   ],
   "source": [
    "from transformers import PreTrainedTokenizerFast\n",
    "tokenizer = PreTrainedTokenizerFast.from_pretrained('bert-base-cased')\n",
    "\n",
    "df_summary_testing = pd.DataFrame(columns=['Min_Kompressionsrate', 'Max_Kompressionsrate', 'Endgueltige_Kompressionsrate', 'Zusammenfassung'])\n",
    "tokenizer.pad_token = tokenizer.eos_token if tokenizer.eos_token else '[PAD]'\n",
    "\n",
    "# Teilen Sie den Text in Sätze\n",
    "sentences = original_text.split('. ')\n",
    "\n",
    "# Erstellen Sie Batches von Sätzen, die weniger als 1024 Tokens enthalten\n",
    "batches = []\n",
    "batch = []\n",
    "batch_len = 0\n",
    "for sentence in sentences:\n",
    "    sentence_len = len(tokenizer.tokenize(sentence))\n",
    "    if sentence_len + batch_len > 1024:\n",
    "        if sentence_len < 1024:  # überspringen Sie Sätze, die länger als 1024 Tokens sind\n",
    "            batches.append(batch)\n",
    "            batch = [sentence]\n",
    "            batch_len = sentence_len\n",
    "        # wenn ein Satz alleine 1024 Tokens überschreitet, wird er übersprungen\n",
    "    else:\n",
    "        batch.append(sentence)\n",
    "        batch_len += sentence_len\n",
    "batches.append(batch)  # fügen Sie den letzten Batch hinzu\n",
    "\n",
    "# Führen Sie die Zusammenfassung für jeden Batch durch\n",
    "for rate in compression_rates:\n",
    "    compression_rate_min = rate\n",
    "    compression_rate_max = rate + 10 if rate + 10 <= 80 else 80  # Stellen Sie sicher, dass die max_rate 80 nicht überschreitet\n",
    "\n",
    "    for batch in batches:\n",
    "        # Zusammenfügen der Sätze in einem Batch\n",
    "        batch_text = '. '.join(batch)\n",
    "        \n",
    "        inputs = tokenizer([batch_text], truncation=True, max_length=1024, padding='max_length', return_tensors='pt')\n",
    "\n",
    "        # Originaltextlänge nach der Trunkierung\n",
    "        original_length = len(inputs['input_ids'][0])\n",
    "\n",
    "        # Berechnen Sie die Mindest- und Maximallänge\n",
    "        min_length_test = original_length * compression_rate_min // 100\n",
    "        max_length_test = original_length * compression_rate_max // 100\n",
    "\n",
    "        # Generieren Sie die Zusammenfassung\n",
    "        summary_ids = model.generate(inputs['input_ids'], num_beams=4, min_length=min_length_test, max_length=max_length_test, early_stopping=True)\n",
    "        summary = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=False) for g in summary_ids]\n",
    "\n",
    "        # Bestimmen Sie die tatsächliche Kompressionsrate der generierten Zusammenfassung\n",
    "        summary_length = len(tokenizer(summary[0])['input_ids'])\n",
    "        actual_compression_rate = summary_length / original_length * 100\n",
    "\n",
    "        # Fügen Sie die Daten zum DataFrame hinzu\n",
    "        df_summary_testing = df_summary_testing.append({\n",
    "            'Min_Kompressionsrate': compression_rate_min,\n",
    "            'Max_Kompressionsrate': compression_rate_max,\n",
    "            'Endgueltige_Kompressionsrate': actual_compression_rate,\n",
    "            'Zusammenfassung': summary[0]\n",
    "        }, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import PreTrainedTokenizerFast\n",
    "from tqdm import tqdm\n",
    "\n",
    "tokenizer = PreTrainedTokenizerFast.from_pretrained('bert-base-cased')\n",
    "tokenizer.pad_token = tokenizer.eos_token if tokenizer.eos_token else '[PAD]'\n",
    "\n",
    "df_summary_testing = pd.DataFrame(columns=['Min_Kompressionsrate', 'Max_Kompressionsrate', 'Endgueltige_Kompressionsrate', 'Zusammenfassung'])\n",
    "\n",
    "# Teilen Sie den Text in Sätze\n",
    "sentences = original_text.split('. ')\n",
    "\n",
    "# Erstellen Sie Batches von Sätzen, die weniger als 1024 Tokens enthalten\n",
    "batches = []\n",
    "batch = []\n",
    "batch_len = 0\n",
    "for sentence in sentences:\n",
    "    sentence_len = len(tokenizer.tokenize(sentence))\n",
    "    if sentence_len + batch_len > 1024:\n",
    "        if sentence_len < 1024:  # überspringen Sie Sätze, die länger als 1024 Tokens sind\n",
    "            batches.append(batch)\n",
    "            batch = [sentence]\n",
    "            batch_len = sentence_len\n",
    "        # wenn ein Satz alleine 1024 Tokens überschreitet, wird er übersprungen\n",
    "    else:\n",
    "        batch.append(sentence)\n",
    "        batch_len += sentence_len\n",
    "batches.append(batch)  # fügen Sie den letzten Batch hinzu\n",
    "\n",
    "# Führen Sie die Zusammenfassung für jeden Batch durch\n",
    "for rate in tqdm(compression_rates, desc='Verarbeite Kompressionsraten'):\n",
    "    compression_rate_min = rate\n",
    "    compression_rate_max = rate + 10 if rate + 10 <= 80 else 80  # Stellen Sie sicher, dass die max_rate 80 nicht überschreitet\n",
    "\n",
    "    for batch in tqdm(batches, desc='Verarbeite Batches'):\n",
    "        # Zusammenfügen der Sätze in einem Batch\n",
    "        batch_text = '. '.join(batch)\n",
    "        \n",
    "        inputs = tokenizer([batch_text], truncation=True, max_length=1024, padding='max_length', return_tensors='pt')\n",
    "\n",
    "        # Originaltextlänge nach der Trunkierung\n",
    "        original_length = len(inputs['input_ids'][0])\n",
    "\n",
    "        # Berechnen Sie die Mindest- und Maximallänge\n",
    "        min_length_test = original_length * compression_rate_min // 100\n",
    "        max_length_test = original_length * compression_rate_max // 100\n",
    "\n",
    "        # Generieren Sie die Zusammenfassung\n",
    "        summary_ids = model.generate(inputs['input_ids'], num_beams=4, min_length=min_length_test, max_length=max_length_test, early_stopping=True)\n",
    "        summary = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=False) for g in summary_ids]\n",
    "\n",
    "        # Bestimmen Sie die tatsächliche Kompressionsrate der generierten Zusammenfassung\n",
    "        summary_length = len(tokenizer(summary[0])['input_ids'])\n",
    "        actual_compression_rate = summary_length / original_length * 100\n",
    "\n",
    "        # Erstellen Sie einen DataFrame für die aktuellen Ergebnisse\n",
    "        df_current = pd.DataFrame({\n",
    "            'Min_Kompressionsrate': [compression_rate_min],\n",
    "            'Max_Kompressionsrate': [compression_rate_max],\n",
    "            'Endgueltige_Kompressionsrate': [actual_compression_rate],\n",
    "            'Zusammenfassung': [summary[0]]\n",
    "        })\n",
    "\n",
    "        # Fügen Sie die Daten zum DataFrame hinzu\n",
    "        df_summary_testing = pd.concat([df_summary_testing, df_current], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Min_Kompressionsrate</th>\n",
       "      <th>Max_Kompressionsrate</th>\n",
       "      <th>Endgueltige_Kompressionsrate</th>\n",
       "      <th>Zusammenfassung</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "      <td>56.152344</td>\n",
       "      <td>[unused2] А rebuilding [unused8] կ the [unused...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "      <td>48.046875</td>\n",
       "      <td>[unused2] from x @ x @h @ xh [unused4] 1949 xh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "      <td>58.691406</td>\n",
       "      <td>[unused2] &lt; x [unused76] [unused40] [unused28]...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "      <td>58.398438</td>\n",
       "      <td>[unused2] &lt; ī \\ [unused31] [unused5] _ [unused...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "      <td>21.972656</td>\n",
       "      <td>[unused2] a ) : @ xmath72. these points are ze...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "      <td>31.054688</td>\n",
       "      <td>[unused2] А the boundary conditions for the co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "      <td>50.195312</td>\n",
       "      <td>[unused2] ( et [unused4] ; ( * p, [unused55] [...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>30</td>\n",
       "      <td>40</td>\n",
       "      <td>86.035156</td>\n",
       "      <td>[unused2] А rebuilding [unused8] կ the [unused...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>30</td>\n",
       "      <td>40</td>\n",
       "      <td>80.664062</td>\n",
       "      <td>[unused2] from x @ x @h @ xh [unused4] 1949 xh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>30</td>\n",
       "      <td>40</td>\n",
       "      <td>86.425781</td>\n",
       "      <td>[unused2] &lt; x [unused76] [unused40] [unused28]...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>30</td>\n",
       "      <td>40</td>\n",
       "      <td>87.695312</td>\n",
       "      <td>[unused2] &lt; ī \\ [unused31] [unused5] _ [unused...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>30</td>\n",
       "      <td>40</td>\n",
       "      <td>28.027344</td>\n",
       "      <td>[unused2] a ) : @ xmath72. these points are ze...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>30</td>\n",
       "      <td>40</td>\n",
       "      <td>37.304688</td>\n",
       "      <td>[unused2] А the boundary conditions for the co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>30</td>\n",
       "      <td>40</td>\n",
       "      <td>83.105469</td>\n",
       "      <td>[unused2] ( et [unused4] ; ( * p, [unused55] [...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>40</td>\n",
       "      <td>50</td>\n",
       "      <td>112.695312</td>\n",
       "      <td>[unused2] А rebuilding [unused8] կ the [unused...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>40</td>\n",
       "      <td>50</td>\n",
       "      <td>109.179688</td>\n",
       "      <td>[unused2] from x @ x @h @ xh [unused4] 1949 xh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>40</td>\n",
       "      <td>50</td>\n",
       "      <td>109.667969</td>\n",
       "      <td>[unused2] &lt; x [unused76] [unused40] [unused28]...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>40</td>\n",
       "      <td>50</td>\n",
       "      <td>112.988281</td>\n",
       "      <td>[unused2] &lt; ī \\ [unused31] [unused5] _ [unused...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>40</td>\n",
       "      <td>50</td>\n",
       "      <td>50.683594</td>\n",
       "      <td>[unused2] a ) : @ xmath72. these points are ze...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>40</td>\n",
       "      <td>50</td>\n",
       "      <td>44.140625</td>\n",
       "      <td>[unused2] А the boundary conditions for the co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>40</td>\n",
       "      <td>50</td>\n",
       "      <td>104.785156</td>\n",
       "      <td>[unused2] ( et [unused4] ; ( * p, [unused55] [...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>50</td>\n",
       "      <td>60</td>\n",
       "      <td>145.117188</td>\n",
       "      <td>[unused2] А rebuilding [unused8] կ the [unused...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>50</td>\n",
       "      <td>60</td>\n",
       "      <td>134.375000</td>\n",
       "      <td>[unused2] from x @ x @h @ xh [unused4] 1949 xh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>50</td>\n",
       "      <td>60</td>\n",
       "      <td>143.164062</td>\n",
       "      <td>[unused2] &lt; x [unused76] [unused40] [unused28]...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>50</td>\n",
       "      <td>60</td>\n",
       "      <td>141.796875</td>\n",
       "      <td>[unused2] &lt; ī \\ [unused31] [unused5] _ [unused...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>50</td>\n",
       "      <td>60</td>\n",
       "      <td>81.347656</td>\n",
       "      <td>[unused2] a ) : @ xmath72. these points are ze...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>50</td>\n",
       "      <td>60</td>\n",
       "      <td>52.148438</td>\n",
       "      <td>[unused2] А the boundary conditions for the co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>50</td>\n",
       "      <td>60</td>\n",
       "      <td>135.156250</td>\n",
       "      <td>[unused2] ( et [unused4] ; ( * p, [unused55] [...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>60</td>\n",
       "      <td>70</td>\n",
       "      <td>169.140625</td>\n",
       "      <td>[unused2] А rebuilding [unused8] կ the [unused...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>60</td>\n",
       "      <td>70</td>\n",
       "      <td>154.199219</td>\n",
       "      <td>[unused2] from x @ x @h @ xh [unused4] 1949 xh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>60</td>\n",
       "      <td>70</td>\n",
       "      <td>171.679688</td>\n",
       "      <td>[unused2] &lt; x [unused76] [unused40] [unused28]...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>60</td>\n",
       "      <td>70</td>\n",
       "      <td>170.312500</td>\n",
       "      <td>[unused2] &lt; ī \\ [unused31] [unused5] _ [unused...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>60</td>\n",
       "      <td>70</td>\n",
       "      <td>110.742188</td>\n",
       "      <td>[unused2] a ) : @ xmath72. these points are ze...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>60</td>\n",
       "      <td>70</td>\n",
       "      <td>60.058594</td>\n",
       "      <td>[unused2] А the boundary conditions for the co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>60</td>\n",
       "      <td>70</td>\n",
       "      <td>171.386719</td>\n",
       "      <td>[unused2] ( et [unused4] ; ( * p, [unused55] [...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>70</td>\n",
       "      <td>80</td>\n",
       "      <td>199.121094</td>\n",
       "      <td>[unused2] А rebuilding [unused8] կ the [unused...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>70</td>\n",
       "      <td>80</td>\n",
       "      <td>171.972656</td>\n",
       "      <td>[unused2] from x @ x @h @ xh [unused4] 1949 xh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>70</td>\n",
       "      <td>80</td>\n",
       "      <td>200.488281</td>\n",
       "      <td>[unused2] &lt; x [unused76] [unused40] [unused28]...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>70</td>\n",
       "      <td>80</td>\n",
       "      <td>204.101562</td>\n",
       "      <td>[unused2] &lt; ī \\ [unused31] [unused5] _ [unused...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>70</td>\n",
       "      <td>80</td>\n",
       "      <td>133.789062</td>\n",
       "      <td>[unused2] a ) : @ xmath72. these points are ze...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>70</td>\n",
       "      <td>80</td>\n",
       "      <td>75.097656</td>\n",
       "      <td>[unused2] А the boundary conditions for the co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>70</td>\n",
       "      <td>80</td>\n",
       "      <td>198.144531</td>\n",
       "      <td>[unused2] ( et [unused4] ; ( * p, [unused55] [...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>223.144531</td>\n",
       "      <td>[unused2] А rebuilding [unused8] կ the [unused...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>188.476562</td>\n",
       "      <td>[unused2] from x @ x @h @ xh [unused4] 1949 xh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>220.898438</td>\n",
       "      <td>[unused2] &lt; x [unused76] [unused40] [unused28]...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>225.878906</td>\n",
       "      <td>[unused2] &lt; ī \\ [unused31] [unused5] _ [unused...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>151.367188</td>\n",
       "      <td>[unused2] a ) : @ xmath72. these points are ze...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>75.097656</td>\n",
       "      <td>[unused2] А the boundary conditions for the co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>229.199219</td>\n",
       "      <td>[unused2] ( et [unused4] ; ( * p, [unused55] [...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Min_Kompressionsrate Max_Kompressionsrate  Endgueltige_Kompressionsrate  \\\n",
       "0                    20                   30                     56.152344   \n",
       "1                    20                   30                     48.046875   \n",
       "2                    20                   30                     58.691406   \n",
       "3                    20                   30                     58.398438   \n",
       "4                    20                   30                     21.972656   \n",
       "5                    20                   30                     31.054688   \n",
       "6                    20                   30                     50.195312   \n",
       "7                    30                   40                     86.035156   \n",
       "8                    30                   40                     80.664062   \n",
       "9                    30                   40                     86.425781   \n",
       "10                   30                   40                     87.695312   \n",
       "11                   30                   40                     28.027344   \n",
       "12                   30                   40                     37.304688   \n",
       "13                   30                   40                     83.105469   \n",
       "14                   40                   50                    112.695312   \n",
       "15                   40                   50                    109.179688   \n",
       "16                   40                   50                    109.667969   \n",
       "17                   40                   50                    112.988281   \n",
       "18                   40                   50                     50.683594   \n",
       "19                   40                   50                     44.140625   \n",
       "20                   40                   50                    104.785156   \n",
       "21                   50                   60                    145.117188   \n",
       "22                   50                   60                    134.375000   \n",
       "23                   50                   60                    143.164062   \n",
       "24                   50                   60                    141.796875   \n",
       "25                   50                   60                     81.347656   \n",
       "26                   50                   60                     52.148438   \n",
       "27                   50                   60                    135.156250   \n",
       "28                   60                   70                    169.140625   \n",
       "29                   60                   70                    154.199219   \n",
       "30                   60                   70                    171.679688   \n",
       "31                   60                   70                    170.312500   \n",
       "32                   60                   70                    110.742188   \n",
       "33                   60                   70                     60.058594   \n",
       "34                   60                   70                    171.386719   \n",
       "35                   70                   80                    199.121094   \n",
       "36                   70                   80                    171.972656   \n",
       "37                   70                   80                    200.488281   \n",
       "38                   70                   80                    204.101562   \n",
       "39                   70                   80                    133.789062   \n",
       "40                   70                   80                     75.097656   \n",
       "41                   70                   80                    198.144531   \n",
       "42                   80                   80                    223.144531   \n",
       "43                   80                   80                    188.476562   \n",
       "44                   80                   80                    220.898438   \n",
       "45                   80                   80                    225.878906   \n",
       "46                   80                   80                    151.367188   \n",
       "47                   80                   80                     75.097656   \n",
       "48                   80                   80                    229.199219   \n",
       "\n",
       "                                      Zusammenfassung  \n",
       "0   [unused2] А rebuilding [unused8] կ the [unused...  \n",
       "1   [unused2] from x @ x @h @ xh [unused4] 1949 xh...  \n",
       "2   [unused2] < x [unused76] [unused40] [unused28]...  \n",
       "3   [unused2] < ī \\ [unused31] [unused5] _ [unused...  \n",
       "4   [unused2] a ) : @ xmath72. these points are ze...  \n",
       "5   [unused2] А the boundary conditions for the co...  \n",
       "6   [unused2] ( et [unused4] ; ( * p, [unused55] [...  \n",
       "7   [unused2] А rebuilding [unused8] կ the [unused...  \n",
       "8   [unused2] from x @ x @h @ xh [unused4] 1949 xh...  \n",
       "9   [unused2] < x [unused76] [unused40] [unused28]...  \n",
       "10  [unused2] < ī \\ [unused31] [unused5] _ [unused...  \n",
       "11  [unused2] a ) : @ xmath72. these points are ze...  \n",
       "12  [unused2] А the boundary conditions for the co...  \n",
       "13  [unused2] ( et [unused4] ; ( * p, [unused55] [...  \n",
       "14  [unused2] А rebuilding [unused8] կ the [unused...  \n",
       "15  [unused2] from x @ x @h @ xh [unused4] 1949 xh...  \n",
       "16  [unused2] < x [unused76] [unused40] [unused28]...  \n",
       "17  [unused2] < ī \\ [unused31] [unused5] _ [unused...  \n",
       "18  [unused2] a ) : @ xmath72. these points are ze...  \n",
       "19  [unused2] А the boundary conditions for the co...  \n",
       "20  [unused2] ( et [unused4] ; ( * p, [unused55] [...  \n",
       "21  [unused2] А rebuilding [unused8] կ the [unused...  \n",
       "22  [unused2] from x @ x @h @ xh [unused4] 1949 xh...  \n",
       "23  [unused2] < x [unused76] [unused40] [unused28]...  \n",
       "24  [unused2] < ī \\ [unused31] [unused5] _ [unused...  \n",
       "25  [unused2] a ) : @ xmath72. these points are ze...  \n",
       "26  [unused2] А the boundary conditions for the co...  \n",
       "27  [unused2] ( et [unused4] ; ( * p, [unused55] [...  \n",
       "28  [unused2] А rebuilding [unused8] կ the [unused...  \n",
       "29  [unused2] from x @ x @h @ xh [unused4] 1949 xh...  \n",
       "30  [unused2] < x [unused76] [unused40] [unused28]...  \n",
       "31  [unused2] < ī \\ [unused31] [unused5] _ [unused...  \n",
       "32  [unused2] a ) : @ xmath72. these points are ze...  \n",
       "33  [unused2] А the boundary conditions for the co...  \n",
       "34  [unused2] ( et [unused4] ; ( * p, [unused55] [...  \n",
       "35  [unused2] А rebuilding [unused8] կ the [unused...  \n",
       "36  [unused2] from x @ x @h @ xh [unused4] 1949 xh...  \n",
       "37  [unused2] < x [unused76] [unused40] [unused28]...  \n",
       "38  [unused2] < ī \\ [unused31] [unused5] _ [unused...  \n",
       "39  [unused2] a ) : @ xmath72. these points are ze...  \n",
       "40  [unused2] А the boundary conditions for the co...  \n",
       "41  [unused2] ( et [unused4] ; ( * p, [unused55] [...  \n",
       "42  [unused2] А rebuilding [unused8] կ the [unused...  \n",
       "43  [unused2] from x @ x @h @ xh [unused4] 1949 xh...  \n",
       "44  [unused2] < x [unused76] [unused40] [unused28]...  \n",
       "45  [unused2] < ī \\ [unused31] [unused5] _ [unused...  \n",
       "46  [unused2] a ) : @ xmath72. these points are ze...  \n",
       "47  [unused2] А the boundary conditions for the co...  \n",
       "48  [unused2] ( et [unused4] ; ( * p, [unused55] [...  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_summary_testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification\n",
    "\n",
    "# Laden Sie das DistilBERT-Modell und Tokenizer\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
    "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased')\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import platform\n",
    "\n",
    "# Überprüfen, ob eine GPU verfügbar ist und das Gerät entsprechend einstellen\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() and platform.system() == \"Windows\" else \"cpu\")\n",
    "\n",
    "# Wenn das System ein Mac ist, aktivieren Sie die MPS (Metal Performance Shaders)\n",
    "if platform.system() == \"Darwin\":\n",
    "    torch.backends.mps.set_enabled(True)\n",
    "\n",
    "# Verschieben Sie das Modell auf das Gerät\n",
    "model = model.to(device)\n",
    "\n",
    "compression_rates = list(range(20, 81, 10))\n",
    "df_summary_testing = pd.DataFrame(columns=['Min_Kompressionsrate', 'Max_Kompressionsrate', 'Endgueltige_Kompressionsrate', 'Zusammenfassung'])\n",
    "\n",
    "for rate in tqdm(compression_rates):\n",
    "    compression_rate_min = rate\n",
    "    compression_rate_max = rate + 10 if rate + 10 <= 80 else 80\n",
    "\n",
    "    split_text = original_text.split('. ')\n",
    "    chunks = [\". \".join(split_text[i:i+chunks_per_summary]) for i in range(0, len(split_text), chunks_per_summary)]\n",
    "\n",
    "    summaries = []\n",
    "    for chunk in chunks:\n",
    "        inputs = tokenizer(chunk, return_tensors='pt').to(device)\n",
    "        min_length = len(inputs['input_ids'][0]) * compression_rate_min // 100\n",
    "        max_length = len(inputs['input_ids'][0]) * compression_rate_max // 100\n",
    "\n",
    "        # Beam-Suche mit weniger Strahlen für eine schnellere Ausführung\n",
    "        summary_ids = model.generate(inputs['input_ids'], num_beams=2, min_length=min_length, max_length=max_length, early_stopping=True)\n",
    "        summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True, clean_up_tokenization_spaces=False)\n",
    "        summaries.append(summary)\n",
    "\n",
    "    combined_summary = ' '.join(summaries)\n",
    "    summary_length = len(tokenizer(combined_summary)['input_ids'])\n",
    "    actual_compression_rate = summary_length / len(tokenizer(original_text)['input_ids']) * 100\n",
    "\n",
    "    df_summary_testing = df_summary_testing.append({\n",
    "        'Min_Kompressionsrate': compression_rate_min,\n",
    "        'Max_Kompressionsrate': compression_rate_max,\n",
    "        'Endgueltige_Kompressionsrate': actual_compression_rate,\n",
    "        'Zusammenfassung': combined_summary\n",
    "    }, ignore_index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "63be3639594356bc87fe58051c1d1c5221c23a964c31c0e05d208c4974bedf26"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
