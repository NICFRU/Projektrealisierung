{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Smr0ok1lbXQJ"
      },
      "source": [
        "# Training Paraphrasing with BART"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "quellen\n",
        "https://medium.com/nlplanet/a-full-guide-to-finetuning-t5-for-text2text-and-building-a-demo-with-streamlit-c72009631887\n",
        "https://github.com/hetpandya/paraphrase-datasets-pretrained-models/blob/main/examples/t5_paraphrase_model_training_example.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5LDHJ9e3bgQf"
      },
      "source": [
        "## Install libraries and download the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "import evaluate\n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from transformers import AutoModelForSeq2SeqLM, PegasusForConditionalGeneration, PegasusTokenizer, AutoTokenizer\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "from transformers import PreTrainedTokenizerFast\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "from transformers import pipeline\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from datasets import Dataset, DatasetDict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "model_name='facebook/bart-large-cnn'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "summarizer = pipeline(\"text2text-generation\", model=model_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVH49J6Dbd7l"
      },
      "source": [
        "## Load the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136,
          "referenced_widgets": [
            "02d4b6b871324b9f92cd549284594225",
            "6291ccc136df4a1b9d011ec738709da2",
            "dde56e8076ae44b28c8583da3ff14113",
            "59f8e3e626e247bba94146336cdea02f",
            "f4fd042a35994f0e9b4e8b8a5a35277c",
            "8200cf9645fd4a7181facbebcb6daef4",
            "6b980b90511d4d869a2bbff97286b53e",
            "327c2b682d2b44be8fb0e61021a4ac48",
            "2613f346dc434001979271278b2b55fe",
            "c7ed4d41f2524651af15054fc601b93b",
            "181ba258d92e49ba8eb2d8fb763f0bdf",
            "c48c5645edc94dfd9ac7c9348af06f01",
            "2ed1cceaa15b4f55b890c483b3029709",
            "246fd9e9c26b474ab8adeb20bdf26e14",
            "b7ec9d1cf5304be6b2d9d856c5250869",
            "b71a79e330c2431cbaf5e13732549b6a",
            "97c990dd1f7f4fd0b66de34898d6fb6d",
            "1f71d5ff86d549da8f5e2adf53b72095",
            "6c712f6809e448b3a310c27a3541e58e",
            "39963f9cb9ee4f9ba80ea253ff74bc4f",
            "c208d387027d4ad99384a1b9efe90ee7",
            "0b20da24f3bc46fa814e26cffea42573"
          ]
        },
        "id": "qo9DNKuHdsl-",
        "outputId": "0c0a4c5f-90dd-4889-ad56-4d37a3c4e943"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Zusammenfassung</th>\n",
              "      <th>Min_Kompressionsrate</th>\n",
              "      <th>Max_Kompressionsrate</th>\n",
              "      <th>Endgueltige_Kompressionsrate</th>\n",
              "      <th>länge Zusammenfassung</th>\n",
              "      <th>länge Ausgangstext</th>\n",
              "      <th>batch_texts</th>\n",
              "      <th>batch_output</th>\n",
              "      <th>text</th>\n",
              "      <th>text_rank_text</th>\n",
              "      <th>tokens_gesamt</th>\n",
              "      <th>token_text_rank</th>\n",
              "      <th>desired_compression_rate</th>\n",
              "      <th>text_rank_compression_rate</th>\n",
              "      <th>current_compression_rate</th>\n",
              "      <th>compression_difference</th>\n",
              "      <th>reduction_multiplier</th>\n",
              "      <th>ent_com_rate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>The Administration of Union Territory Daman an...</td>\n",
              "      <td>34</td>\n",
              "      <td>51.00</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>33</td>\n",
              "      <td>33</td>\n",
              "      <td>['The Administration of Union Territory Daman ...</td>\n",
              "      <td>['The Administration of Union Territory Daman ...</td>\n",
              "      <td>The Administration of Union Territory Daman an...</td>\n",
              "      <td>The Administration of Union Territory Daman an...</td>\n",
              "      <td>60</td>\n",
              "      <td>33</td>\n",
              "      <td>0.54</td>\n",
              "      <td>0.550000</td>\n",
              "      <td>0.550000</td>\n",
              "      <td>-0.010000</td>\n",
              "      <td>0.981818</td>\n",
              "      <td>0.550000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Malaika responded, \"You certainly got to get y...</td>\n",
              "      <td>42</td>\n",
              "      <td>63.00</td>\n",
              "      <td>75.000000</td>\n",
              "      <td>30</td>\n",
              "      <td>40</td>\n",
              "      <td>['\"Her life now is all about wearing short clo...</td>\n",
              "      <td>['Malaika responded, \"You certainly got to get...</td>\n",
              "      <td>Malaika Arora slammed an Instagram user who tr...</td>\n",
              "      <td>\"Her life now is all about wearing short cloth...</td>\n",
              "      <td>60</td>\n",
              "      <td>40</td>\n",
              "      <td>0.46</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>-0.206667</td>\n",
              "      <td>0.690000</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Bihar Health Minister defined virgin as being ...</td>\n",
              "      <td>36</td>\n",
              "      <td>54.00</td>\n",
              "      <td>97.142857</td>\n",
              "      <td>34</td>\n",
              "      <td>35</td>\n",
              "      <td>['Earlier, Bihar Health Minister defined virgi...</td>\n",
              "      <td>['Bihar Health Minister defined virgin as bein...</td>\n",
              "      <td>The Indira Gandhi Institute of Medical Science...</td>\n",
              "      <td>Earlier, Bihar Health Minister defined virgin ...</td>\n",
              "      <td>60</td>\n",
              "      <td>35</td>\n",
              "      <td>0.55</td>\n",
              "      <td>0.583333</td>\n",
              "      <td>0.583333</td>\n",
              "      <td>-0.033333</td>\n",
              "      <td>0.942857</td>\n",
              "      <td>0.566667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Lashkar e Taibas Kashmir commander Abu Dujana ...</td>\n",
              "      <td>35</td>\n",
              "      <td>52.50</td>\n",
              "      <td>55.882353</td>\n",
              "      <td>19</td>\n",
              "      <td>34</td>\n",
              "      <td>['Lashkar e Taibas Kashmir commander Abu Dujan...</td>\n",
              "      <td>['Lashkar e Taibas Kashmir commander Abu Dujan...</td>\n",
              "      <td>Lashkar e Taibas Kashmir commander Abu Dujana,...</td>\n",
              "      <td>Lashkar e Taibas Kashmir commander Abu Dujana,...</td>\n",
              "      <td>62</td>\n",
              "      <td>34</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.566667</td>\n",
              "      <td>0.548387</td>\n",
              "      <td>-0.228387</td>\n",
              "      <td>0.583529</td>\n",
              "      <td>0.306452</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Hotels in Maharashtra will train their staff t...</td>\n",
              "      <td>53</td>\n",
              "      <td>74.20</td>\n",
              "      <td>80.392157</td>\n",
              "      <td>41</td>\n",
              "      <td>51</td>\n",
              "      <td>['Hotels in Maharashtra will train their staff...</td>\n",
              "      <td>['Hotels in Maharashtra will train their staff...</td>\n",
              "      <td>Hotels in Maharashtra will train their staff t...</td>\n",
              "      <td>Hotels in Maharashtra will train their staff t...</td>\n",
              "      <td>60</td>\n",
              "      <td>51</td>\n",
              "      <td>0.69</td>\n",
              "      <td>0.850000</td>\n",
              "      <td>0.850000</td>\n",
              "      <td>-0.160000</td>\n",
              "      <td>0.811765</td>\n",
              "      <td>0.683333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>495</th>\n",
              "      <td>495</td>\n",
              "      <td>PM Narendra Modi said everyone needs to rise a...</td>\n",
              "      <td>49</td>\n",
              "      <td>73.50</td>\n",
              "      <td>80.851064</td>\n",
              "      <td>38</td>\n",
              "      <td>47</td>\n",
              "      <td>['PM Narendra Modi on Wednesday said everyone ...</td>\n",
              "      <td>['PM Narendra Modi said everyone needs to rise...</td>\n",
              "      <td>PM Narendra Modi on Wednesday said everyone ne...</td>\n",
              "      <td>PM Narendra Modi on Wednesday said everyone ne...</td>\n",
              "      <td>59</td>\n",
              "      <td>47</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.796610</td>\n",
              "      <td>0.796610</td>\n",
              "      <td>-0.096610</td>\n",
              "      <td>0.878723</td>\n",
              "      <td>0.644068</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>496</th>\n",
              "      <td>496</td>\n",
              "      <td>A US man, who claimed to be an ex employee of ...</td>\n",
              "      <td>38</td>\n",
              "      <td>57.00</td>\n",
              "      <td>70.270270</td>\n",
              "      <td>26</td>\n",
              "      <td>37</td>\n",
              "      <td>['A US man, who claimed to be an ex employee o...</td>\n",
              "      <td>['A US man, who claimed to be an ex employee o...</td>\n",
              "      <td>A US man, who claimed to be an ex employee of ...</td>\n",
              "      <td>A US man, who claimed to be an ex employee of ...</td>\n",
              "      <td>60</td>\n",
              "      <td>37</td>\n",
              "      <td>0.46</td>\n",
              "      <td>0.637931</td>\n",
              "      <td>0.616667</td>\n",
              "      <td>-0.156667</td>\n",
              "      <td>0.745946</td>\n",
              "      <td>0.433333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>497</th>\n",
              "      <td>497</td>\n",
              "      <td>Nawazuddin will play a man from the planet Mar...</td>\n",
              "      <td>22</td>\n",
              "      <td>33.00</td>\n",
              "      <td>71.428571</td>\n",
              "      <td>15</td>\n",
              "      <td>21</td>\n",
              "      <td>['Written and directed by Maitrey Bajpai, the ...</td>\n",
              "      <td>['Nawazuddin will play a man from the planet M...</td>\n",
              "      <td>Nawazuddin Siddiquis first look from the upcom...</td>\n",
              "      <td>Written and directed by Maitrey Bajpai, the fi...</td>\n",
              "      <td>54</td>\n",
              "      <td>21</td>\n",
              "      <td>0.26</td>\n",
              "      <td>0.388889</td>\n",
              "      <td>0.388889</td>\n",
              "      <td>-0.128889</td>\n",
              "      <td>0.668571</td>\n",
              "      <td>0.277778</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>498</th>\n",
              "      <td>498</td>\n",
              "      <td>Attorney General KK Venugopal on behalf of the...</td>\n",
              "      <td>66</td>\n",
              "      <td>82.50</td>\n",
              "      <td>49.206349</td>\n",
              "      <td>31</td>\n",
              "      <td>63</td>\n",
              "      <td>['Attorney General KK Venugopal on behalf of t...</td>\n",
              "      <td>['Attorney General KK Venugopal on behalf of t...</td>\n",
              "      <td>Attorney General KK Venugopal on behalf of the...</td>\n",
              "      <td>Attorney General KK Venugopal on behalf of the...</td>\n",
              "      <td>63</td>\n",
              "      <td>63</td>\n",
              "      <td>0.48</td>\n",
              "      <td>1.033333</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.520000</td>\n",
              "      <td>0.480000</td>\n",
              "      <td>0.492063</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499</th>\n",
              "      <td>499</td>\n",
              "      <td>As many as 24 kanwarias, 6 ITBP and Police per...</td>\n",
              "      <td>63</td>\n",
              "      <td>78.75</td>\n",
              "      <td>68.333333</td>\n",
              "      <td>41</td>\n",
              "      <td>60</td>\n",
              "      <td>['As many as 24 kanwarias, 6 ITBP and Police p...</td>\n",
              "      <td>['As many as 24 kanwarias, 6 ITBP and Police p...</td>\n",
              "      <td>As many as 24 kanwarias, 6 ITBP and Police per...</td>\n",
              "      <td>As many as 24 kanwarias, 6 ITBP and Police per...</td>\n",
              "      <td>60</td>\n",
              "      <td>60</td>\n",
              "      <td>0.73</td>\n",
              "      <td>1.016949</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.270000</td>\n",
              "      <td>0.730000</td>\n",
              "      <td>0.683333</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>500 rows × 19 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Unnamed: 0                                    Zusammenfassung  \\\n",
              "0             0  The Administration of Union Territory Daman an...   \n",
              "1             1  Malaika responded, \"You certainly got to get y...   \n",
              "2             2  Bihar Health Minister defined virgin as being ...   \n",
              "3             3  Lashkar e Taibas Kashmir commander Abu Dujana ...   \n",
              "4             4  Hotels in Maharashtra will train their staff t...   \n",
              "..          ...                                                ...   \n",
              "495         495  PM Narendra Modi said everyone needs to rise a...   \n",
              "496         496  A US man, who claimed to be an ex employee of ...   \n",
              "497         497  Nawazuddin will play a man from the planet Mar...   \n",
              "498         498  Attorney General KK Venugopal on behalf of the...   \n",
              "499         499  As many as 24 kanwarias, 6 ITBP and Police per...   \n",
              "\n",
              "     Min_Kompressionsrate  Max_Kompressionsrate  Endgueltige_Kompressionsrate  \\\n",
              "0                      34                 51.00                    100.000000   \n",
              "1                      42                 63.00                     75.000000   \n",
              "2                      36                 54.00                     97.142857   \n",
              "3                      35                 52.50                     55.882353   \n",
              "4                      53                 74.20                     80.392157   \n",
              "..                    ...                   ...                           ...   \n",
              "495                    49                 73.50                     80.851064   \n",
              "496                    38                 57.00                     70.270270   \n",
              "497                    22                 33.00                     71.428571   \n",
              "498                    66                 82.50                     49.206349   \n",
              "499                    63                 78.75                     68.333333   \n",
              "\n",
              "     länge Zusammenfassung  länge Ausgangstext  \\\n",
              "0                       33                  33   \n",
              "1                       30                  40   \n",
              "2                       34                  35   \n",
              "3                       19                  34   \n",
              "4                       41                  51   \n",
              "..                     ...                 ...   \n",
              "495                     38                  47   \n",
              "496                     26                  37   \n",
              "497                     15                  21   \n",
              "498                     31                  63   \n",
              "499                     41                  60   \n",
              "\n",
              "                                           batch_texts  \\\n",
              "0    ['The Administration of Union Territory Daman ...   \n",
              "1    ['\"Her life now is all about wearing short clo...   \n",
              "2    ['Earlier, Bihar Health Minister defined virgi...   \n",
              "3    ['Lashkar e Taibas Kashmir commander Abu Dujan...   \n",
              "4    ['Hotels in Maharashtra will train their staff...   \n",
              "..                                                 ...   \n",
              "495  ['PM Narendra Modi on Wednesday said everyone ...   \n",
              "496  ['A US man, who claimed to be an ex employee o...   \n",
              "497  ['Written and directed by Maitrey Bajpai, the ...   \n",
              "498  ['Attorney General KK Venugopal on behalf of t...   \n",
              "499  ['As many as 24 kanwarias, 6 ITBP and Police p...   \n",
              "\n",
              "                                          batch_output  \\\n",
              "0    ['The Administration of Union Territory Daman ...   \n",
              "1    ['Malaika responded, \"You certainly got to get...   \n",
              "2    ['Bihar Health Minister defined virgin as bein...   \n",
              "3    ['Lashkar e Taibas Kashmir commander Abu Dujan...   \n",
              "4    ['Hotels in Maharashtra will train their staff...   \n",
              "..                                                 ...   \n",
              "495  ['PM Narendra Modi said everyone needs to rise...   \n",
              "496  ['A US man, who claimed to be an ex employee o...   \n",
              "497  ['Nawazuddin will play a man from the planet M...   \n",
              "498  ['Attorney General KK Venugopal on behalf of t...   \n",
              "499  ['As many as 24 kanwarias, 6 ITBP and Police p...   \n",
              "\n",
              "                                                  text  \\\n",
              "0    The Administration of Union Territory Daman an...   \n",
              "1    Malaika Arora slammed an Instagram user who tr...   \n",
              "2    The Indira Gandhi Institute of Medical Science...   \n",
              "3    Lashkar e Taibas Kashmir commander Abu Dujana,...   \n",
              "4    Hotels in Maharashtra will train their staff t...   \n",
              "..                                                 ...   \n",
              "495  PM Narendra Modi on Wednesday said everyone ne...   \n",
              "496  A US man, who claimed to be an ex employee of ...   \n",
              "497  Nawazuddin Siddiquis first look from the upcom...   \n",
              "498  Attorney General KK Venugopal on behalf of the...   \n",
              "499  As many as 24 kanwarias, 6 ITBP and Police per...   \n",
              "\n",
              "                                        text_rank_text  tokens_gesamt  \\\n",
              "0    The Administration of Union Territory Daman an...             60   \n",
              "1    \"Her life now is all about wearing short cloth...             60   \n",
              "2    Earlier, Bihar Health Minister defined virgin ...             60   \n",
              "3    Lashkar e Taibas Kashmir commander Abu Dujana,...             62   \n",
              "4    Hotels in Maharashtra will train their staff t...             60   \n",
              "..                                                 ...            ...   \n",
              "495  PM Narendra Modi on Wednesday said everyone ne...             59   \n",
              "496  A US man, who claimed to be an ex employee of ...             60   \n",
              "497  Written and directed by Maitrey Bajpai, the fi...             54   \n",
              "498  Attorney General KK Venugopal on behalf of the...             63   \n",
              "499  As many as 24 kanwarias, 6 ITBP and Police per...             60   \n",
              "\n",
              "     token_text_rank  desired_compression_rate  text_rank_compression_rate  \\\n",
              "0                 33                      0.54                    0.550000   \n",
              "1                 40                      0.46                    0.666667   \n",
              "2                 35                      0.55                    0.583333   \n",
              "3                 34                      0.32                    0.566667   \n",
              "4                 51                      0.69                    0.850000   \n",
              "..               ...                       ...                         ...   \n",
              "495               47                      0.70                    0.796610   \n",
              "496               37                      0.46                    0.637931   \n",
              "497               21                      0.26                    0.388889   \n",
              "498               63                      0.48                    1.033333   \n",
              "499               60                      0.73                    1.016949   \n",
              "\n",
              "     current_compression_rate  compression_difference  reduction_multiplier  \\\n",
              "0                    0.550000               -0.010000              0.981818   \n",
              "1                    0.666667               -0.206667              0.690000   \n",
              "2                    0.583333               -0.033333              0.942857   \n",
              "3                    0.548387               -0.228387              0.583529   \n",
              "4                    0.850000               -0.160000              0.811765   \n",
              "..                        ...                     ...                   ...   \n",
              "495                  0.796610               -0.096610              0.878723   \n",
              "496                  0.616667               -0.156667              0.745946   \n",
              "497                  0.388889               -0.128889              0.668571   \n",
              "498                  1.000000               -0.520000              0.480000   \n",
              "499                  1.000000               -0.270000              0.730000   \n",
              "\n",
              "     ent_com_rate  \n",
              "0        0.550000  \n",
              "1        0.500000  \n",
              "2        0.566667  \n",
              "3        0.306452  \n",
              "4        0.683333  \n",
              "..            ...  \n",
              "495      0.644068  \n",
              "496      0.433333  \n",
              "497      0.277778  \n",
              "498      0.492063  \n",
              "499      0.683333  \n",
              "\n",
              "[500 rows x 19 columns]"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train=pd.read_csv('data/ergbnisse/train_news_v_2.csv')\n",
        "df_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "import ast\n",
        "df_explotde=df_train[['batch_texts','batch_output']]\n",
        "df_explotde=df_explotde.applymap(ast.literal_eval)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_explotde['C'] = df_explotde.apply(lambda row: list(zip(row['batch_texts'], row['batch_output'])), axis=1)\n",
        "df_explotde = df_explotde.explode('C')\n",
        "\n",
        "# Get 'A' and 'B' values back\n",
        "df_explotde[['batch_texts', 'batch_output']] = pd.DataFrame(df_explotde['C'].tolist(), index=df_explotde.index)\n",
        "df = df_explotde.drop(columns=['C'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>batch_texts</th>\n",
              "      <th>batch_output</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The Administration of Union Territory Daman an...</td>\n",
              "      <td>The Administration of Union Territory Daman an...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\"Her life now is all about wearing short cloth...</td>\n",
              "      <td>Malaika responded, \"You certainly got to get y...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Earlier, Bihar Health Minister defined virgin ...</td>\n",
              "      <td>Bihar Health Minister defined virgin as being ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Lashkar e Taibas Kashmir commander Abu Dujana,...</td>\n",
              "      <td>Lashkar e Taibas Kashmir commander Abu Dujana ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Hotels in Maharashtra will train their staff t...</td>\n",
              "      <td>Hotels in Maharashtra will train their staff t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>495</th>\n",
              "      <td>PM Narendra Modi on Wednesday said everyone ne...</td>\n",
              "      <td>PM Narendra Modi said everyone needs to rise a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>496</th>\n",
              "      <td>A US man, who claimed to be an ex employee of ...</td>\n",
              "      <td>A US man, who claimed to be an ex employee of ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>497</th>\n",
              "      <td>Written and directed by Maitrey Bajpai, the fi...</td>\n",
              "      <td>Nawazuddin will play a man from the planet Mar...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>498</th>\n",
              "      <td>Attorney General KK Venugopal on behalf of the...</td>\n",
              "      <td>Attorney General KK Venugopal on behalf of the...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499</th>\n",
              "      <td>As many as 24 kanwarias, 6 ITBP and Police per...</td>\n",
              "      <td>As many as 24 kanwarias, 6 ITBP and Police per...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>500 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           batch_texts  \\\n",
              "0    The Administration of Union Territory Daman an...   \n",
              "1    \"Her life now is all about wearing short cloth...   \n",
              "2    Earlier, Bihar Health Minister defined virgin ...   \n",
              "3    Lashkar e Taibas Kashmir commander Abu Dujana,...   \n",
              "4    Hotels in Maharashtra will train their staff t...   \n",
              "..                                                 ...   \n",
              "495  PM Narendra Modi on Wednesday said everyone ne...   \n",
              "496  A US man, who claimed to be an ex employee of ...   \n",
              "497  Written and directed by Maitrey Bajpai, the fi...   \n",
              "498  Attorney General KK Venugopal on behalf of the...   \n",
              "499  As many as 24 kanwarias, 6 ITBP and Police per...   \n",
              "\n",
              "                                          batch_output  \n",
              "0    The Administration of Union Territory Daman an...  \n",
              "1    Malaika responded, \"You certainly got to get y...  \n",
              "2    Bihar Health Minister defined virgin as being ...  \n",
              "3    Lashkar e Taibas Kashmir commander Abu Dujana ...  \n",
              "4    Hotels in Maharashtra will train their staff t...  \n",
              "..                                                 ...  \n",
              "495  PM Narendra Modi said everyone needs to rise a...  \n",
              "496  A US man, who claimed to be an ex employee of ...  \n",
              "497  Nawazuddin will play a man from the planet Mar...  \n",
              "498  Attorney General KK Venugopal on behalf of the...  \n",
              "499  As many as 24 kanwarias, 6 ITBP and Police per...  \n",
              "\n",
              "[500 rows x 2 columns]"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Create Test und Train Data "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def token_count(text):\n",
        "    tokens = text.split()\n",
        "    return len(tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "def token_count(text):\n",
        "    tokens = text.split()\n",
        "    return len(tokens)\n",
        "\n",
        "\n",
        "def adjust_length(text):\n",
        "    length = token_count(text)\n",
        "    if length <20:\n",
        "        min_length = length + int(length * 0.05)\n",
        "        max_length = min_length +min_length\n",
        "    elif length <50:\n",
        "        min_length = length + int(length * 0.05)\n",
        "        max_length = min_length +min_length* 0.5\n",
        "    elif length <60:\n",
        "        min_length = length + int(length * 0.05)\n",
        "        max_length = min_length +min_length* 0.4\n",
        "    elif length < 80:\n",
        "        min_length = length + int(length * 0.05)\n",
        "        max_length = min_length + min_length* 0.25\n",
        "    elif length < 100:\n",
        "        min_length = length + int(length * 0.3)\n",
        "        max_length = min_length + 100\n",
        "    else:\n",
        "        min_length = math.ceil(length / 50) * 70\n",
        "        max_length = min_length + 100\n",
        "    return min_length, max_length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "def batch_sent(sentenc,splitt=180,split='. '):\n",
        "    sentences = sentenc.split(split)\n",
        "    # Erstellen Sie Batches von Sätzen, die weniger als 1024 Tokens enthalten\n",
        "    batches = []\n",
        "    batch = []\n",
        "    batch_len = 0\n",
        "    for sentence in sentences:\n",
        "        \n",
        "        sentence_len = len(tokenizer.tokenize(sentence))\n",
        "        if sentence_len + batch_len > splitt:\n",
        "            if sentence_len < splitt:  # überspringen Sie Sätze, die länger als 256 Tokens sind\n",
        "                batches.append(batch)\n",
        "                batch = [sentence]\n",
        "                batch_len = sentence_len\n",
        "            # wenn ein Satz alleine 1024 Tokens überschreitet, wird er übersprungen\n",
        "        else:\n",
        "            batch.append(sentence)\n",
        "            batch_len += sentence_len\n",
        "    batches.append(batch)\n",
        "    return batches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def paraphrase_of_text(df_s,text_name='text',komp_name='reduction_multiplier',split='. '):\n",
        "    counter = 0\n",
        "    df_summary_testing = pd.DataFrame(columns=['text', 'Zusammenfassung','Min_Kompressionsrate', 'Max_Kompressionsrate', 'Endgueltige_Kompressionsrate','länge Zusammenfassung','länge Ausgangstext', 'batch_texts',])\n",
        "    # Teilen Sie den Text in Sätze --> für tatsächliche umsetzubng\n",
        "    soplitting=True\n",
        "    for _, row in tqdm(df_s.iterrows(), total=df_s.shape[0]):\n",
        "     \n",
        "        text = row[text_name]\n",
        "        komp = row[komp_name]\n",
        "        text_gesamt_list=[]\n",
        "\n",
        "        for batch in tqdm(batch_sent(text,split=split), desc='Verarbeite Batches'):\n",
        "            # Zusammenfügen der Sätze in einem Batch\n",
        "            batch_text = '. '.join(batch)\n",
        "            min_length_test, max_length_test = adjust_length(batch_text)\n",
        "            ext_summary=summarizer(batch_text, max_length=int(round(max_length_test*komp,0)), min_length=int(round(min_length_test*komp,0)),length_penalty=100,num_beams=2)\n",
        "            # Erstellen Sie einen DataFrame für die aktuellen Ergebnisse\n",
        "           \n",
        "            text_gesamt_list.append(ext_summary[0]['generated_text'])\n",
        "        text_gesamt = '. '.join(text_gesamt_list)\n",
        "        actual_compression_rate = len(text_gesamt.split(' '))/len(text.split(' '))*100\n",
        "      \n",
        "        df_current = pd.DataFrame({\n",
        "            'text':[text],\n",
        "            'Zusammenfassung': [text_gesamt],\n",
        "            'Min_Kompressionsrate': [min_length_test],\n",
        "            'Max_Kompressionsrate': [max_length_test],\n",
        "            'Endgueltige_Kompressionsrate': [actual_compression_rate],\n",
        "            'länge Zusammenfassung': [len(text_gesamt.split(' '))],\n",
        "            'länge Ausgangstext': [len(text.split(' '))]\n",
        "        \n",
        "        })\n",
        "       \n",
        "        # Fügen Sie die Daten zum DataFrame hinzu\n",
        "        df_summary_testing = pd.concat([df_summary_testing, df_current], ignore_index=True)\n",
        "        counter += 1\n",
        "        soplitting=False\n",
        "    return df_summary_testing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_compression(df, total_tokens_col, current_tokens_col, desired_compression_rate):\n",
        "    df['current_compression_rate'] = df[current_tokens_col] / df[total_tokens_col]\n",
        "    df['compression_difference'] = desired_compression_rate - df['current_compression_rate']\n",
        "    df['reduction_multiplier'] = desired_compression_rate / df['current_compression_rate']\n",
        "    return df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_test=calculate_compression(df_test, 'total_tokens', 'token_count', desired_compression_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_summary=paraphrase_of_text(df_test[['text','reduction_multiplier']])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "meFMYGPrbkwp"
      },
      "source": [
        "## Dataset train/validation/test split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "FPsvfzq-uAKc"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Teilen des DataFrames in Trainings- und Validierungsdatensätze\n",
        "df_train, df_val = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "# Umwandlung der DataFrames in Dictionaries\n",
        "train_dataset = Dataset.from_pandas(df_train)\n",
        "val_dataset = Dataset.from_pandas(df_val)\n",
        "\n",
        "# Erstellen des finalen DatasetDict\n",
        "datasets = DatasetDict({\n",
        "    'train': train_dataset,\n",
        "    'validation': val_dataset\n",
        "})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['batch_texts', 'batch_output', '__index_level_0__'],\n",
              "        num_rows: 400\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['batch_texts', 'batch_output', '__index_level_0__'],\n",
              "        num_rows: 100\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "4R2UP-FovZBe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "- Training set: 80.00%\n",
            "- Validation set: 20.00%\n"
          ]
        }
      ],
      "source": [
        "n_samples_train = len(datasets[\"train\"])\n",
        "n_samples_validation = len(datasets[\"validation\"])\n",
        "#n_samples_test = len(datasets[\"test\"])\n",
        "n_samples_total = n_samples_train + n_samples_validation # + n_samples_test\n",
        "\n",
        "print(f\"- Training set: {n_samples_train*100/n_samples_total:.2f}%\")\n",
        "print(f\"- Validation set: {n_samples_validation*100/n_samples_total:.2f}%\")\n",
        "#print(f\"- Test set: {n_samples_test*100/n_samples_total:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "xYW2j-_l4FwR"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['batch_texts', 'batch_output', '__index_level_0__'],\n",
              "        num_rows: 400\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['batch_texts', 'batch_output', '__index_level_0__'],\n",
              "        num_rows: 100\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# keep only a subsample of the datasets\n",
        "datasets[\"train\"] = datasets[\"train\"].shuffle().select(range(400))\n",
        "datasets[\"validation\"] = datasets[\"validation\"].shuffle().select(range(100))\n",
        "#datasets[\"test\"] = datasets[\"test\"].shuffle().select(range(1000))\n",
        "\n",
        "datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMlba5F2bqTQ"
      },
      "source": [
        "## Data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "4w4QyMc2wF4z"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     /Users/niclascramer/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "import string\n",
        "from transformers import AutoTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "fXE4liMzxJVu"
      },
      "outputs": [],
      "source": [
        "model_checkpoint = \"facebook/bart-base\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "AksRL_QyyYZj"
      },
      "outputs": [],
      "source": [
        "prefix = \"text2text-generation: \"\n",
        "\n",
        "max_input_length = 512\n",
        "max_target_length = 64\n",
        "\n",
        "def clean_text(text):\n",
        "  sentences = nltk.sent_tokenize(text.strip())\n",
        "  sentences_cleaned = [s for sent in sentences for s in sent.split(\"\\n\")]\n",
        "  sentences_cleaned_no_titles = [sent for sent in sentences_cleaned\n",
        "                                 if len(sent) > 0 and\n",
        "                                 sent[-1] in string.punctuation]\n",
        "  text_cleaned = \"\\n\".join(sentences_cleaned_no_titles)\n",
        "  return text_cleaned\n",
        "\n",
        "def preprocess_data(examples):\n",
        "  texts_cleaned = [clean_text(text) for text in examples[\"batch_texts\"]]\n",
        "  inputs = [prefix + text for text in texts_cleaned]\n",
        "  model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True)\n",
        "\n",
        "  # Setup the tokenizer for targets\n",
        "  with tokenizer.as_target_tokenizer():\n",
        "    labels = tokenizer(examples[\"batch_output\"], max_length=max_target_length,\n",
        "                       truncation=True)\n",
        "\n",
        "  model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "  return model_inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "tsEaq2Um3HcD"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8e241b267e624506abf0fca30c7e35f7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2ae78fe3f9b343dc9ed0004d22806a5e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "002489728ab947b5af0cad8b81c32998",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/niclascramer/opt/miniconda3/envs/torch/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:3546: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "782d0b3913eb4697bc38c94ed2e41f62",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['batch_texts', 'batch_output', '__index_level_0__', 'input_ids', 'attention_mask', 'labels'],\n",
              "        num_rows: 400\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['batch_texts', 'batch_output', '__index_level_0__', 'input_ids', 'attention_mask', 'labels'],\n",
              "        num_rows: 100\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "datasets_cleaned = datasets.filter(lambda example: (len(example['batch_texts']) >= 5) and (len(example['batch_output']) >= 5))\n",
        "tokenized_datasets = datasets_cleaned.map(preprocess_data, batched=True)\n",
        "tokenized_datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Xc_wx8WbtJ4"
      },
      "source": [
        "## Fine-tune bart"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "m0SW4HFx4wzG"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "73iDTHHYgVTN"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "619030.84s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "rm: {model_dir}: No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!rm -r {model_dir}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "HjLfz7b6cVHJ"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/var/folders/k3/z_svrdgd6sb9lc9bqdfzp_k00000gn/T/ipykernel_49648/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">1826872687.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">4</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: </span>                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">'/var/folders/k3/z_svrdgd6sb9lc9bqdfzp_k00000gn/T/ipykernel_49648/1826872687.py'</span>                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">&lt;string&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">108</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__init__</span>                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/Users/niclascramer/opt/miniconda3/envs/torch/lib/python3.9/site-packages/transformers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">training_</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">args.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1122</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__post_init__</span>                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1119 │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">and</span> (get_xla_device_type(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.device) != <span style=\"color: #808000; text-decoration-color: #808000\">\"GPU\"</span>)                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1120 │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">and</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.fp16 <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.fp16_full_eval)                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1121 │   │   </span>):                                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1122 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">ValueError</span>(                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1123 │   │   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"FP16 Mixed precision training with AMP or APEX (`--fp16`) and FP16 half</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1124 │   │   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\" (`--fp16_full_eval`) can only be used on CUDA devices.\"</span>                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1125 │   │   │   </span>)                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">ValueError: </span>FP16 Mixed precision training with AMP or APEX <span style=\"font-weight: bold\">(</span>`--fp16`<span style=\"font-weight: bold\">)</span> and FP16 half precision evaluation \n",
              "<span style=\"font-weight: bold\">(</span>`--fp16_full_eval`<span style=\"font-weight: bold\">)</span> can only be used on CUDA devices.\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/var/folders/k3/z_svrdgd6sb9lc9bqdfzp_k00000gn/T/ipykernel_49648/\u001b[0m\u001b[1;33m1826872687.py\u001b[0m:\u001b[94m4\u001b[0m in \u001b[92m<module>\u001b[0m     \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: \u001b[0m                                                            \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[3;31m'/var/folders/k3/z_svrdgd6sb9lc9bqdfzp_k00000gn/T/ipykernel_49648/1826872687.py'\u001b[0m                 \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[33m<string>\u001b[0m:\u001b[94m108\u001b[0m in \u001b[92m__init__\u001b[0m                                                                         \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/Users/niclascramer/opt/miniconda3/envs/torch/lib/python3.9/site-packages/transformers/\u001b[0m\u001b[1;33mtraining_\u001b[0m \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[1;33margs.py\u001b[0m:\u001b[94m1122\u001b[0m in \u001b[92m__post_init__\u001b[0m                                                                    \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1119 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[95mand\u001b[0m (get_xla_device_type(\u001b[96mself\u001b[0m.device) != \u001b[33m\"\u001b[0m\u001b[33mGPU\u001b[0m\u001b[33m\"\u001b[0m)                               \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1120 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[95mand\u001b[0m (\u001b[96mself\u001b[0m.fp16 \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m.fp16_full_eval)                                        \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1121 \u001b[0m\u001b[2m│   │   \u001b[0m):                                                                                \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1122 \u001b[2m│   │   │   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mValueError\u001b[0m(                                                             \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1123 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[33m\"\u001b[0m\u001b[33mFP16 Mixed precision training with AMP or APEX (`--fp16`) and FP16 half\u001b[0m  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1124 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[33m\"\u001b[0m\u001b[33m (`--fp16_full_eval`) can only be used on CUDA devices.\u001b[0m\u001b[33m\"\u001b[0m                 \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1125 \u001b[0m\u001b[2m│   │   │   \u001b[0m)                                                                             \u001b[31m│\u001b[0m\n",
              "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
              "\u001b[1;91mValueError: \u001b[0mFP16 Mixed precision training with AMP or APEX \u001b[1m(\u001b[0m`--fp16`\u001b[1m)\u001b[0m and FP16 half precision evaluation \n",
              "\u001b[1m(\u001b[0m`--fp16_full_eval`\u001b[1m)\u001b[0m can only be used on CUDA devices.\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "batch_size = 8\n",
        "model_name = \"bart-base-paraphrasing\"\n",
        "model_dir = f\"drive/MyDrive/Models/{model_name}\"\n",
        "args = Seq2SeqTrainingArguments(\n",
        "    model_dir,\n",
        "    evaluation_strategy=\"steps\",\n",
        "    eval_steps=100,\n",
        "    logging_strategy=\"steps\",\n",
        "    logging_steps=100,\n",
        "    save_strategy=\"steps\",\n",
        "    save_steps=200,\n",
        "    learning_rate=4e-5,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    weight_decay=0.01,\n",
        "    save_total_limit=3,\n",
        "    num_train_epochs=1,\n",
        "    predict_with_generate=True,\n",
        "    fp16=True,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"rouge1\",\n",
        "    report_to=\"tensorboard\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "joWGLoZ8dOIS"
      },
      "outputs": [],
      "source": [
        "data_collator = DataCollatorForSeq2Seq(tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qYq_4DWjdXYa"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "metric = load_metric(\"rouge\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
        "\n",
        "    # Replace -100 in the labels as we can't decode them.\n",
        "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "    # Rouge expects a newline after each sentence\n",
        "    decoded_preds = [\"\\n\".join(nltk.sent_tokenize(pred.strip()))\n",
        "                      for pred in decoded_preds]\n",
        "    decoded_labels = [\"\\n\".join(nltk.sent_tokenize(label.strip()))\n",
        "                      for label in decoded_labels]\n",
        "\n",
        "    # Compute ROUGE scores\n",
        "    result = metric.compute(predictions=decoded_preds, references=decoded_labels,\n",
        "                            use_stemmer=True)\n",
        "\n",
        "    # Extract ROUGE f1 scores\n",
        "    result = {key: value.mid.fmeasure * 100 for key, value in result.items()}\n",
        "\n",
        "    # Add mean generated length to metrics\n",
        "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id)\n",
        "                      for pred in predictions]\n",
        "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
        "\n",
        "    return {k: round(v, 4) for k, v in result.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ODp1f0ZkdadY"
      },
      "outputs": [],
      "source": [
        "# Function that returns an untrained model to be trained\n",
        "def model_init():\n",
        "    return AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)\n",
        "\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model_init=model_init,\n",
        "    args=args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"validation\"],\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tq8R43Ls8-EU"
      },
      "outputs": [],
      "source": [
        "# Start TensorBoard before training to monitor it in progress\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir '{model_dir}'/runs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XOeZoPmudwiv"
      },
      "outputs": [],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_4PIcpIeoDW7"
      },
      "outputs": [],
      "source": [
        "trainer.save_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sOuRWgO1F0Xc"
      },
      "source": [
        "## Load the model from GDrive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LNiSsHt1oRmN"
      },
      "outputs": [],
      "source": [
        "model_name = \"t5-base-medium-title-generation/checkpoint-2000\"\n",
        "model_dir = f\"drive/MyDrive/Models/{model_name}\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_dir)\n",
        "\n",
        "max_input_length = 512"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "COdutSc1Oel9"
      },
      "outputs": [],
      "source": [
        "text = \"\"\"\n",
        "We define access to a Streamlit app in a browser tab as a session.\n",
        "For each browser tab that connects to the Streamlit server, a new session is created.\n",
        "Streamlit reruns your script from top to bottom every time you interact with your app.\n",
        "Each reruns takes place in a blank slate: no variables are shared between runs.\n",
        "Session State is a way to share variables between reruns, for each user session.\n",
        "In addition to the ability to store and persist state, Streamlit also exposes the\n",
        "ability to manipulate state using Callbacks. In this guide, we will illustrate the\n",
        "usage of Session State and Callbacks as we build a stateful Counter app.\n",
        "For details on the Session State and Callbacks API, please refer to our Session\n",
        "State API Reference Guide. Also, check out this Session State basics tutorial\n",
        "video by Streamlit Developer Advocate Dr. Marisa Smith to get started:\n",
        "\"\"\"\n",
        "\n",
        "inputs = [\"summarize: \" + text]\n",
        "\n",
        "inputs = tokenizer(inputs, max_length=max_input_length, truncation=True, return_tensors=\"pt\")\n",
        "output = model.generate(**inputs, num_beams=8, do_sample=True, min_length=10, max_length=64)\n",
        "decoded_output = tokenizer.batch_decode(output, skip_special_tokens=True)[0]\n",
        "predicted_title = nltk.sent_tokenize(decoded_output.strip())[0]\n",
        "\n",
        "print(predicted_title)\n",
        "# Session State and Callbacks in Streamlit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MqH3hlZg_3HE"
      },
      "outputs": [],
      "source": [
        "text = \"\"\"\n",
        "Many financial institutions started building conversational AI, prior to the Covid19\n",
        "pandemic, as part of a digital transformation initiative. These initial solutions\n",
        "were high profile, highly personalized virtual assistants — like the Erica chatbot\n",
        "from Bank of America. As the pandemic hit, the need changed as contact centers were\n",
        "under increased pressures. As Cathal McGloin of ServisBOT explains in “how it started,\n",
        "and how it is going,” financial institutions were looking for ways to automate\n",
        "solutions to help get back to “normal” levels of customer service. This resulted\n",
        "in a change from the “future of conversational AI” to a real tactical assistant\n",
        "that can help in customer service. Haritha Dev of Wells Fargo, saw a similar trend.\n",
        "Banks were originally looking to conversational AI as part of digital transformation\n",
        "to keep up with the times. However, with the pandemic, it has been more about\n",
        "customer retention and customer satisfaction. In addition, new use cases came about\n",
        "as a result of Covid-19 that accelerated adoption of conversational AI. As Vinita\n",
        "Kumar of Deloitte points out, banks were dealing with an influx of calls about new\n",
        "concerns, like questions around the Paycheck Protection Program (PPP) loans. This\n",
        "resulted in an increase in volume, without enough agents to assist customers, and\n",
        "tipped the scale to incorporate conversational AI. When choosing initial use cases\n",
        "to support, financial institutions often start with high volume, low complexity\n",
        "tasks. For example, password resets, checking account balances, or checking the\n",
        "status of a transaction, as Vinita points out. From there, the use cases can evolve\n",
        "as the banks get more mature in developing conversational AI, and as the customers\n",
        "become more engaged with the solutions. Cathal indicates another good way for banks\n",
        "to start is looking at use cases that are a pain point, and also do not require a\n",
        "lot of IT support. Some financial institutions may have a multi-year technology\n",
        "roadmap, which can make it harder to get a new service started. A simple chatbot\n",
        "for document collection in an onboarding process can result in high engagement,\n",
        "and a high return on investment. For example, Cathal has a banking customer that\n",
        "implemented a chatbot to capture a driver’s license to be used in the verification\n",
        "process of adding an additional user to an account — it has over 85% engagement\n",
        "with high satisfaction. An interesting use case Haritha discovered involved\n",
        "educating customers on financial matters. People feel more comfortable asking a\n",
        "chatbot what might be considered a “dumb” question, as the chatbot is less judgmental.\n",
        "Users can be more ambiguous with their questions as well, not knowing the right\n",
        "words to use, as chatbot can help narrow things down.\n",
        "\"\"\"\n",
        "\n",
        "inputs = [\"summarize: \" + text]\n",
        "\n",
        "inputs = tokenizer(inputs, max_length=max_input_length, truncation=True, return_tensors=\"pt\")\n",
        "output = model.generate(**inputs, num_beams=8, do_sample=True, min_length=10, max_length=64)\n",
        "decoded_output = tokenizer.batch_decode(output, skip_special_tokens=True)[0]\n",
        "predicted_title = nltk.sent_tokenize(decoded_output.strip())[0]\n",
        "\n",
        "print(predicted_title)\n",
        "# Conversational AI: The Future of Customer Service"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fvilrwiEezhD"
      },
      "source": [
        "## Upload the model to the Hugging Space Hub"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8DdcAcVojw6z"
      },
      "source": [
        "https://huggingface.co/docs/transformers/model_sharing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7DnuA0tggwhW"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade jax jaxlib # CPU-only\n",
        "!pip install flax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LVj3RpFieol9"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lyZQIZSHfpPI"
      },
      "outputs": [],
      "source": [
        "from transformers import T5ForConditionalGeneration, TFT5ForConditionalGeneration, FlaxT5ForConditionalGeneration\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
        "pt_model = T5ForConditionalGeneration.from_pretrained(model_dir)\n",
        "tf_model = TFT5ForConditionalGeneration.from_pretrained(model_dir, from_pt=True)\n",
        "flax_model = FlaxT5ForConditionalGeneration.from_pretrained(model_dir, from_pt=True)\n",
        "\n",
        "tokenizer.push_to_hub(model_name)\n",
        "pt_model.push_to_hub(model_name)\n",
        "tf_model.push_to_hub(model_name)\n",
        "flax_model.push_to_hub(model_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tqDj8iX_kQD1"
      },
      "source": [
        "## Load the model from the Hugging Face Hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PQHVTHJTkYyR"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"fabiochiu/t5-small-medium-title-generation\")\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"fabiochiu/t5-small-medium-title-generation\")\n",
        "\n",
        "text = \"\"\"\n",
        "Many financial institutions started building conversational AI, prior to the Covid19\n",
        "pandemic, as part of a digital transformation initiative. These initial solutions\n",
        "were high profile, highly personalized virtual assistants — like the Erica chatbot\n",
        "from Bank of America. As the pandemic hit, the need changed as contact centers were\n",
        "under increased pressures. As Cathal McGloin of ServisBOT explains in “how it started,\n",
        "and how it is going,” financial institutions were looking for ways to automate\n",
        "solutions to help get back to “normal” levels of customer service. This resulted\n",
        "in a change from the “future of conversational AI” to a real tactical assistant\n",
        "that can help in customer service. Haritha Dev of Wells Fargo, saw a similar trend.\n",
        "Banks were originally looking to conversational AI as part of digital transformation\n",
        "to keep up with the times. However, with the pandemic, it has been more about\n",
        "customer retention and customer satisfaction. In addition, new use cases came about\n",
        "as a result of Covid-19 that accelerated adoption of conversational AI. As Vinita\n",
        "Kumar of Deloitte points out, banks were dealing with an influx of calls about new\n",
        "concerns, like questions around the Paycheck Protection Program (PPP) loans. This\n",
        "resulted in an increase in volume, without enough agents to assist customers, and\n",
        "tipped the scale to incorporate conversational AI. When choosing initial use cases\n",
        "to support, financial institutions often start with high volume, low complexity\n",
        "tasks. For example, password resets, checking account balances, or checking the\n",
        "status of a transaction, as Vinita points out. From there, the use cases can evolve\n",
        "as the banks get more mature in developing conversational AI, and as the customers\n",
        "become more engaged with the solutions. Cathal indicates another good way for banks\n",
        "to start is looking at use cases that are a pain point, and also do not require a\n",
        "lot of IT support. Some financial institutions may have a multi-year technology\n",
        "roadmap, which can make it harder to get a new service started. A simple chatbot\n",
        "for document collection in an onboarding process can result in high engagement,\n",
        "and a high return on investment. For example, Cathal has a banking customer that\n",
        "implemented a chatbot to capture a driver’s license to be used in the verification\n",
        "process of adding an additional user to an account — it has over 85% engagement\n",
        "with high satisfaction. An interesting use case Haritha discovered involved\n",
        "educating customers on financial matters. People feel more comfortable asking a\n",
        "chatbot what might be considered a “dumb” question, as the chatbot is less judgmental.\n",
        "Users can be more ambiguous with their questions as well, not knowing the right\n",
        "words to use, as chatbot can help narrow things down.\n",
        "\"\"\"\n",
        "\n",
        "inputs = [\"summarize: \" + text]\n",
        "\n",
        "inputs = tokenizer(inputs, max_length=max_input_length, truncation=True, return_tensors=\"pt\")\n",
        "output = model.generate(**inputs, num_beams=8, do_sample=True, min_length=10, max_length=64)\n",
        "decoded_output = tokenizer.batch_decode(output, skip_special_tokens=True)[0]\n",
        "predicted_title = nltk.sent_tokenize(decoded_output.strip())[0]\n",
        "\n",
        "print(predicted_title)\n",
        "# Conversational AI: The Future of Customer Service"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_WaVGKccca9"
      },
      "source": [
        "## Evaluate the model on the test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LsPh50j4qdFd"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "# get test split\n",
        "test_tokenized_dataset = tokenized_datasets[\"test\"]\n",
        "\n",
        "# pad texts to the same length\n",
        "def preprocess_test(examples):\n",
        "  inputs = [prefix + text for text in examples[\"text\"]]\n",
        "  model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True,\n",
        "                           padding=\"max_length\")\n",
        "  return model_inputs\n",
        "\n",
        "test_tokenized_dataset = test_tokenized_dataset.map(preprocess_test, batched=True)\n",
        "\n",
        "# prepare dataloader\n",
        "test_tokenized_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask'])\n",
        "dataloader = torch.utils.data.DataLoader(test_tokenized_dataset, batch_size=32)\n",
        "\n",
        "# generate text for each batch\n",
        "all_predictions = []\n",
        "for i,batch in enumerate(dataloader):\n",
        "  predictions = model.generate(**batch)\n",
        "  all_predictions.append(predictions)\n",
        "\n",
        "# flatten predictions\n",
        "all_predictions_flattened = [pred for preds in all_predictions for pred in preds]\n",
        "\n",
        "# tokenize and pad titles\n",
        "all_titles = tokenizer(test_tokenized_dataset[\"title\"], max_length=max_target_length,\n",
        "                       truncation=True, padding=\"max_length\")[\"input_ids\"]\n",
        "\n",
        "# compute metrics\n",
        "predictions_labels = [all_predictions_flattened, all_titles]\n",
        "compute_metrics(predictions_labels)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.15 ('torch')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    },
    "vscode": {
      "interpreter": {
        "hash": "63be3639594356bc87fe58051c1d1c5221c23a964c31c0e05d208c4974bedf26"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "02d4b6b871324b9f92cd549284594225": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6291ccc136df4a1b9d011ec738709da2",
              "IPY_MODEL_dde56e8076ae44b28c8583da3ff14113",
              "IPY_MODEL_59f8e3e626e247bba94146336cdea02f"
            ],
            "layout": "IPY_MODEL_f4fd042a35994f0e9b4e8b8a5a35277c"
          }
        },
        "0b20da24f3bc46fa814e26cffea42573": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "181ba258d92e49ba8eb2d8fb763f0bdf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1f71d5ff86d549da8f5e2adf53b72095": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "246fd9e9c26b474ab8adeb20bdf26e14": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6c712f6809e448b3a310c27a3541e58e",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_39963f9cb9ee4f9ba80ea253ff74bc4f",
            "value": 0
          }
        },
        "2613f346dc434001979271278b2b55fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2ed1cceaa15b4f55b890c483b3029709": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_97c990dd1f7f4fd0b66de34898d6fb6d",
            "placeholder": "​",
            "style": "IPY_MODEL_1f71d5ff86d549da8f5e2adf53b72095",
            "value": "Extracting data files:   0%"
          }
        },
        "327c2b682d2b44be8fb0e61021a4ac48": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39963f9cb9ee4f9ba80ea253ff74bc4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "59f8e3e626e247bba94146336cdea02f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c7ed4d41f2524651af15054fc601b93b",
            "placeholder": "​",
            "style": "IPY_MODEL_181ba258d92e49ba8eb2d8fb763f0bdf",
            "value": " 1/1 [00:00&lt;00:00, 11.74it/s]"
          }
        },
        "6291ccc136df4a1b9d011ec738709da2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8200cf9645fd4a7181facbebcb6daef4",
            "placeholder": "​",
            "style": "IPY_MODEL_6b980b90511d4d869a2bbff97286b53e",
            "value": "Downloading data files: 100%"
          }
        },
        "6b980b90511d4d869a2bbff97286b53e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6c712f6809e448b3a310c27a3541e58e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8200cf9645fd4a7181facbebcb6daef4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97c990dd1f7f4fd0b66de34898d6fb6d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b71a79e330c2431cbaf5e13732549b6a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7ec9d1cf5304be6b2d9d856c5250869": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c208d387027d4ad99384a1b9efe90ee7",
            "placeholder": "​",
            "style": "IPY_MODEL_0b20da24f3bc46fa814e26cffea42573",
            "value": " 0/1 [00:00&lt;?, ?it/s]"
          }
        },
        "c208d387027d4ad99384a1b9efe90ee7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c48c5645edc94dfd9ac7c9348af06f01": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2ed1cceaa15b4f55b890c483b3029709",
              "IPY_MODEL_246fd9e9c26b474ab8adeb20bdf26e14",
              "IPY_MODEL_b7ec9d1cf5304be6b2d9d856c5250869"
            ],
            "layout": "IPY_MODEL_b71a79e330c2431cbaf5e13732549b6a"
          }
        },
        "c7ed4d41f2524651af15054fc601b93b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dde56e8076ae44b28c8583da3ff14113": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_327c2b682d2b44be8fb0e61021a4ac48",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2613f346dc434001979271278b2b55fe",
            "value": 1
          }
        },
        "f4fd042a35994f0e9b4e8b8a5a35277c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
