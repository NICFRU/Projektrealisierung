{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy download en\n",
    "!pip install transformers\n",
    "!pip install torch\n",
    "!pip install tensorflow\n",
    "!python -m spacy download en_core_web_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import networkx as nx\n",
    "import spacy\n",
    "from summa import keywords\n",
    "from summa.summarizer import summarize\n",
    "\n",
    "# Laden des Spacy-Modells\n",
    "import evaluate\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from transformers import AutoModelForSeq2SeqLM, PegasusForConditionalGeneration, PegasusTokenizer, AutoTokenizer\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from transformers import PreTrainedTokenizerFast\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from transformers import pipeline\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classification</th>\n",
       "      <th>text</th>\n",
       "      <th>sentences</th>\n",
       "      <th>num_sentences</th>\n",
       "      <th>words</th>\n",
       "      <th>num_words</th>\n",
       "      <th>lemmas</th>\n",
       "      <th>stops</th>\n",
       "      <th>num_stops</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Scientific</td>\n",
       "      <td>the interest in anchoring phenomena and phenom...</td>\n",
       "      <td>['the interest in anchoring phenomena and phen...</td>\n",
       "      <td>222</td>\n",
       "      <td>['interest', 'anchoring', 'phenomena', 'phenom...</td>\n",
       "      <td>3533</td>\n",
       "      <td>['interest', 'anchor', 'phenomenon', 'phenomen...</td>\n",
       "      <td>[the, in, and, in, has, been, by, their, in, a...</td>\n",
       "      <td>2426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Scientific</td>\n",
       "      <td>galaxy clusters , as the largest peaks in the ...</td>\n",
       "      <td>['galaxy clusters , as the largest peaks in th...</td>\n",
       "      <td>372</td>\n",
       "      <td>['galaxy', 'clusters', 'largest', 'peaks', 'co...</td>\n",
       "      <td>8982</td>\n",
       "      <td>['galaxy', 'cluster', 'large', 'peak', 'cosmic...</td>\n",
       "      <td>[as, the, in, the, an, in, and, in, for, and, ...</td>\n",
       "      <td>5768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Scientific</td>\n",
       "      <td>quantum correlations between components of a s...</td>\n",
       "      <td>['quantum correlations between components of a...</td>\n",
       "      <td>138</td>\n",
       "      <td>['quantum', 'correlations', 'components', 'sys...</td>\n",
       "      <td>2451</td>\n",
       "      <td>['quantum', 'correlation', 'component', 'syste...</td>\n",
       "      <td>[between, of, a, or, are, on, the, of, whole, ...</td>\n",
       "      <td>1780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Scientific</td>\n",
       "      <td>methanol masers are often found in star - form...</td>\n",
       "      <td>['methanol masers are often found in star - fo...</td>\n",
       "      <td>141</td>\n",
       "      <td>['methanol', 'masers', 'found', 'star', 'formi...</td>\n",
       "      <td>3232</td>\n",
       "      <td>['methanol', 'maser', 'find', 'star', 'form', ...</td>\n",
       "      <td>[are, often, in, are, two, of, to, i, most, th...</td>\n",
       "      <td>1940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Scientific</td>\n",
       "      <td>interdisciplinary research has recently gained...</td>\n",
       "      <td>['interdisciplinary research has recently gain...</td>\n",
       "      <td>88</td>\n",
       "      <td>['interdisciplinary', 'research', 'recently', ...</td>\n",
       "      <td>2695</td>\n",
       "      <td>['interdisciplinary', 'research', 'recently', ...</td>\n",
       "      <td>[has, a, in, the, of, to, the, in, was, to, tw...</td>\n",
       "      <td>1997</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  classification                                               text  \\\n",
       "0     Scientific  the interest in anchoring phenomena and phenom...   \n",
       "1     Scientific  galaxy clusters , as the largest peaks in the ...   \n",
       "2     Scientific  quantum correlations between components of a s...   \n",
       "3     Scientific  methanol masers are often found in star - form...   \n",
       "4     Scientific  interdisciplinary research has recently gained...   \n",
       "\n",
       "                                           sentences  num_sentences  \\\n",
       "0  ['the interest in anchoring phenomena and phen...            222   \n",
       "1  ['galaxy clusters , as the largest peaks in th...            372   \n",
       "2  ['quantum correlations between components of a...            138   \n",
       "3  ['methanol masers are often found in star - fo...            141   \n",
       "4  ['interdisciplinary research has recently gain...             88   \n",
       "\n",
       "                                               words  num_words  \\\n",
       "0  ['interest', 'anchoring', 'phenomena', 'phenom...       3533   \n",
       "1  ['galaxy', 'clusters', 'largest', 'peaks', 'co...       8982   \n",
       "2  ['quantum', 'correlations', 'components', 'sys...       2451   \n",
       "3  ['methanol', 'masers', 'found', 'star', 'formi...       3232   \n",
       "4  ['interdisciplinary', 'research', 'recently', ...       2695   \n",
       "\n",
       "                                              lemmas  \\\n",
       "0  ['interest', 'anchor', 'phenomenon', 'phenomen...   \n",
       "1  ['galaxy', 'cluster', 'large', 'peak', 'cosmic...   \n",
       "2  ['quantum', 'correlation', 'component', 'syste...   \n",
       "3  ['methanol', 'maser', 'find', 'star', 'form', ...   \n",
       "4  ['interdisciplinary', 'research', 'recently', ...   \n",
       "\n",
       "                                               stops  num_stops  \n",
       "0  [the, in, and, in, has, been, by, their, in, a...       2426  \n",
       "1  [as, the, in, the, an, in, and, in, for, and, ...       5768  \n",
       "2  [between, of, a, or, are, on, the, of, whole, ...       1780  \n",
       "3  [are, often, in, are, two, of, to, i, most, th...       1940  \n",
       "4  [has, a, in, the, of, to, the, in, was, to, tw...       1997  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train=pd.read_csv('data/data_train_with_features.csv')\n",
    "df_train = df_train.drop('Unnamed: 0', axis=1)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Scientific', 'news', 'reviews', 'story'], dtype=object)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.classification.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def reduce_repetitions(text):\n",
    "    text = re.sub(r'\\.{2,}', '.', text)\n",
    "    text = re.sub(r'\\!{2,}', '!', text)\n",
    "    text = re.sub(r'\\,{2,}', ',', text)\n",
    "    text = re.sub(r'\\;{2,}', ';', text)\n",
    "    return text\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def textrank_extractive(text, compression_rate=0.5,split='\\. '):\n",
    "    # Tokenisierung\n",
    "    nlp = spacy.load(\"en_core_web_lg\")\n",
    "    #doc = nlp(text.replace(\"\\n\\n\", \" \"))\n",
    "\n",
    "    # Split the text at each \". \" that is not followed by a single letter\n",
    "    doc = re.split(fr'(?<!\\b\\w\\w){split}', reduce_repetitions(re.sub(' +', ' ', text.replace(\"\\n\", \" \").replace('-',' ').replace('_',' ').replace(\"\\'\", \"\").replace(\"!\", \".\").replace(\"?\", \".\").replace(\";\", \"\"))))\n",
    "    sentences = [sent for sent in doc if len(sent.replace(\"-\", \" \").split()) > 2]\n",
    "\n",
    "    # Speichern der Spacy-Dokumente der Sätze für spätere Verwendung\n",
    "    sentence_docs = [nlp(sentence) for sentence in sentences]\n",
    "\n",
    "    # Extrahiere Schlüsselsätze mit TextRank\n",
    "    num_sentences = max(1, int(len(sentences) * compression_rate))\n",
    "    extracted_sentences = summarize(text, words=num_sentences, split=True)\n",
    "\n",
    "    # Erzeuge eine Matrix mit den Ähnlichkeiten zwischen den Sätzen\n",
    "    similarity_matrix = np.zeros((len(sentences), len(sentences)))\n",
    "    for i, doc_i in enumerate(sentence_docs):\n",
    "        for j, doc_j in enumerate(sentence_docs):\n",
    "            similarity = similarity_function(doc_i, doc_j)\n",
    "            similarity_matrix[i, j] = similarity\n",
    "    \n",
    "    # Konstruiere einen Graphen mit den Sätzen als Knoten und den Ähnlichkeiten als Kanten\n",
    "    graph = nx.from_numpy_array(similarity_matrix)\n",
    "\n",
    "    # Berechne den TextRank-Score für jeden Satz\n",
    "    scores = nx.pagerank_numpy(graph)\n",
    "\n",
    "    # Wähle die besten Sätze basierend auf ihren TextRank-Scores aus\n",
    "    top_sentences = sorted(scores, key=scores.get, reverse=True)[:num_sentences]\n",
    "\n",
    "    # Sortiere die ausgewählten Sätze nach ihrer Position im Text\n",
    "    top_sentences = sorted(top_sentences)\n",
    "\n",
    "    # Gebe die extrahierten Schlüsselsätze zurück\n",
    "    extracted_sentences = [sentences[index] for index in top_sentences]\n",
    "    return extracted_sentences\n",
    "\n",
    "\n",
    "def similarity_function(doc1, doc2):\n",
    "    # Berechne die Cosinus-Ähnlichkeit zwischen den beiden Dokumenten\n",
    "    similarity = doc1.similarity(doc2)\n",
    "    return similarity\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def compression_ratio(text, summary):\n",
    "    # Berechne das Verhältnis der Anzahl der Wörter in der Zusammenfassung zur Anzahl der Wörter im Ausgangstext\n",
    "    num_words_text = len(text.split())\n",
    "    num_words_summary = len(summary.split())\n",
    "    ratio = num_words_summary / num_words_text\n",
    "    return ratio\n",
    "\n",
    "\n",
    "\n",
    "def compression(text, compression_rate,split='\\. '):\n",
    "    max_iterations = 20\n",
    "    iterations = 0\n",
    "    #compression_rate -= 0.05\n",
    "    \n",
    "    extracted = textrank_extractive(text, compression_rate,split)\n",
    "    summary = '. '.join(extracted)\n",
    "    compression_rate_renwed = compression_rate\n",
    "\n",
    "\n",
    "    while compression_ratio(text, summary) < compression_rate and iterations < max_iterations:\n",
    "        iterations += 1\n",
    "        compression_rate_renwed += 0.05\n",
    "        if compression_rate_renwed > 1:\n",
    "            compression_rate_renwed = 1\n",
    "        extracted = textrank_extractive(text, compression_rate=compression_rate_renwed)\n",
    "        summary = '. '.join(extracted)\n",
    "    return summary\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k3/z_svrdgd6sb9lc9bqdfzp_k00000gn/T/ipykernel_89249/1902150806.py:28: DeprecationWarning: networkx.pagerank_numpy is deprecated and will be removed in NetworkX 3.0, use networkx.pagerank instead.\n",
      "  scores = nx.pagerank_numpy(graph)\n",
      "/Users/niclascramer/opt/miniconda3/envs/torch/lib/python3.9/site-packages/networkx/algorithms/link_analysis/pagerank_alg.py:354: FutureWarning: google_matrix will return an np.ndarray instead of a np.matrix in\n",
      "NetworkX version 3.0.\n",
      "  M = google_matrix(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['The young man was noble and brave, and every body hoped that he would some day be the King of England',\n",
       " 'One summer Prince William went with his father across the sea to look after their lands in France',\n",
       " 'They were wel comed with joy by all their people there, and the young prince was so gallant and kind, that he won the love of all who saw him',\n",
       " 'The king, with his wise men and brave knights, set sail early in the day but Prince William with his younger friends waited a little while',\n",
       " 'They had had so joyous a time in France that they were in no great haste to tear them selves away',\n",
       " 'Then they went on board of the ship which was waiting to carry them home',\n",
       " 'It was a beau ti ful ship with white sails and white masts, and it had been fitted up on purpose for this voyage',\n",
       " 'The sea was smooth, the winds were fair, and no one thought of danger',\n",
       " 'On the ship, every thing had been ar ranged to make the trip a pleasant one',\n",
       " 'The sun had gone down before the white winged vessel was fairly out of the bay',\n",
       " 'The moon was at its full, and it would give light enough and before the dawn of the morrow, the narrow sea would be crossed',\n",
       " 'And so the prince, and the young people who were with him, gave themselves up to mer ri ment and feasting and joy',\n",
       " 'No one knew what to do. A small boat was quickly launched, and the prince with a few of his bravest friends leaped into it. They pushed off just as the ship was be gin ning to settle beneath the waves',\n",
       " 'They had rowed hardly ten yards from the ship, when there was a cry from among those that were left behind',\n",
       " 'One shriek of terror was heard, and then all was still save the sound of the moaning waters',\n",
       " 'Ship and boat, prince and prin cess, and all the gay com pa ny that had set sail from France, went down to the bottom together',\n",
       " 'One man clung to a floating plank, and was saved the next day',\n",
       " 'He was the only person left alive to tell the sad story',\n",
       " 'There stood proud forms before his throne, The stately and the brave But who could fill the place of one, That one beneath the wave',\n",
       " 'Before him passed the young and fair, In pleasures reckless train But seas dashed oer his sons bright hair He never smiled again',\n",
       " 'A murmur of the restless deep Was blent with every strain, A voice of winds that would not sleep He never smiled again',\n",
       " 'Hearts, in that time, closed oer the trace Of vows once fondly poured, And strangers took the kins mans place At many a joyous board Graves which true love had bathed with tears Were left to heavens bright rain Fresh hopes were born for other years He never smiled again']"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_2=str(re.sub(' +', ' ', df_training[16:17]['text'][16].replace(\"\\n\", \" \")))\n",
    "textrank_extractive(text_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name='facebook/bart-large-cnn'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "summarizer = pipeline(\"text2text-generation\", model=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_count(text):\n",
    "    tokens = text.split()\n",
    "    return len(tokens)\n",
    "\n",
    "\n",
    "def adjust_length(text):\n",
    "    length = token_count(text)\n",
    "    if length <20:\n",
    "        min_length = length + int(length * 0.05)\n",
    "        max_length = min_length +min_length\n",
    "    elif length <50:\n",
    "        min_length = length + int(length * 0.05)\n",
    "        max_length = min_length +min_length* 0.4\n",
    "    elif length <60:\n",
    "        min_length = length + int(length * 0.05)\n",
    "        max_length = min_length +min_length* 0.25\n",
    "    elif length < 80:\n",
    "        min_length = length + int(length * 0.05)\n",
    "        max_length = min_length + min_length* 0.25\n",
    "    elif length < 100:\n",
    "        min_length = length + int(length * 0.3)\n",
    "        max_length = min_length + 100\n",
    "    else:\n",
    "        min_length = math.ceil(length / 50) * 70\n",
    "        max_length = min_length + 100\n",
    "    return min_length, max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Whale naturalist and animal communicator Mary Getten goes beyond what other research has achieved in the way of whale study and communication processes: in 1991 she studied the J-Pod, a family of whales off Washington State',\n",
       " 'Her contention that they use direct telepathic communication between themselves and can do so with humans also makes for fascinating reading.Diane C',\n",
       " 'DonovanCalifornia Bookwatch']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split='\\. '\n",
    "sentenc='Whale naturalist and animal communicator Mary Getten goes beyond what other research has achieved in the way of whale study and communication processes: in 1991 she studied the J-Pod, a family of whales off Washington State. Her contention that they use direct telepathic communication between themselves and can do so with humans also makes for fascinating reading.Diane C. DonovanCalifornia Bookwatch'\n",
    "\n",
    "sentences = re.split(fr'(?<!\\b\\w\\w){split}', sentenc)\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_sent(sentenc,splitt=180,split='\\. '):\n",
    "    \n",
    "    sentences = re.split(fr'(?<!\\b\\w\\w){split}', sentenc.lower())\n",
    "\n",
    "    # Erstellen Sie Batches von Sätzen, die weniger als 1024 Tokens enthalten\n",
    "    batches = []\n",
    "    batch = []\n",
    "    batch_len = 0\n",
    "    for sentence in sentences:\n",
    "        \n",
    "        sentence_len = len(tokenizer.tokenize(sentence))\n",
    "        if sentence_len + batch_len > splitt:\n",
    "            if sentence_len < splitt:  # überspringen Sie Sätze, die länger als 256 Tokens sind\n",
    "                batches.append(batch)\n",
    "                batch = [sentence]\n",
    "                batch_len = sentence_len\n",
    "            # wenn ein Satz alleine 1024 Tokens überschreitet, wird er übersprungen\n",
    "        else:\n",
    "            batch.append(sentence)\n",
    "            batch_len += sentence_len\n",
    "    batches.append(batch)\n",
    "    return batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'This will be a waste'}]"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_news='this will be a waste of your time.'\n",
    "ext_summary=summarizer(text_news, max_length=int(round(10*1,0)), min_length=int(round(8*1,0)),length_penalty=100,num_beams=2)\n",
    "ext_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "def paraphrase_of_text(df_s,text_name='text',komp_name='reduction_multiplier',split='\\. '):\n",
    "\n",
    "    df_summary_testing = pd.DataFrame(columns=['Zusammenfassung','Min_Kompressionsrate', 'Max_Kompressionsrate', 'Endgueltige_Kompressionsrate','länge Zusammenfassung','länge Ausgangstext','batch_texts','batch_output'])\n",
    "    # Teilen Sie den Text in Sätze --> für tatsächliche umsetzubng\n",
    "    soplitting=True\n",
    "    \n",
    "    for _, row in tqdm(df_s.iterrows(), total=df_s.shape[0]):\n",
    "        batch_text_list=[]\n",
    "\n",
    "        output_text_list=[]\n",
    "        text = row[text_name]\n",
    "        komp = row[komp_name]\n",
    "        text_gesamt_list=[]\n",
    "\n",
    "        for batch in tqdm(batch_sent(text,split=split), desc='Verarbeite Batches'):\n",
    "            # Zusammenfügen der Sätze in einem Batch\n",
    "            batch_text = '. '.join(batch)\n",
    "            batch_text += \".\"\n",
    "\n",
    "            min_length_test, max_length_test = adjust_length(batch_text)\n",
    "            ext_summary=summarizer(batch_text, max_length=int(round(max_length_test*komp,0)), min_length=int(round(min_length_test*komp,0)),length_penalty=100,num_beams=2)\n",
    "            # Erstellen Sie einen read_csv für die aktuellen Ergebnisse\n",
    "\n",
    "            text_gesamt_list.append(ext_summary[0]['generated_text'])\n",
    "         \n",
    "        text_gesamt = '. '.join(text_gesamt_list)\n",
    "        actual_compression_rate = len(text_gesamt.split(' '))/len(text.split(' '))*100\n",
    "      \n",
    "        df_current = pd.DataFrame({\n",
    "            'Zusammenfassung': [text_gesamt],\n",
    "            'Min_Kompressionsrate': [min_length_test],\n",
    "            'Max_Kompressionsrate': [max_length_test],\n",
    "            'Endgueltige_Kompressionsrate': [actual_compression_rate],\n",
    "            'länge Zusammenfassung': [len(text_gesamt.split(' '))],\n",
    "            'länge Ausgangstext': [len(text.split(' '))],\n",
    "            'batch_texts': [batch_text_list],\n",
    "            'batch_output': [text_gesamt_list]\n",
    "        \n",
    "        })\n",
    "       \n",
    "        # Fügen Sie die Daten zum DataFrame hinzu\n",
    "        df_summary_testing = pd.concat([df_summary_testing, df_current], ignore_index=True)\n",
    "      \n",
    "    return df_summary_testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_compression(df, total_tokens_col, current_tokens_col, desired_compression_rate):\n",
    "    df['current_compression_rate'] = df[current_tokens_col] / df[total_tokens_col]\n",
    "    df['compression_difference'] = df[desired_compression_rate] - df['current_compression_rate']\n",
    "    df['reduction_multiplier'] = df[desired_compression_rate] / df['current_compression_rate']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_rank_algo(df,seed=10,split='\\. '):\n",
    "    df_return = pd.DataFrame(columns=['text','text_rank_text','tokens_gesamt', 'token_text_rank','desired_compression_rate','text_rank_compression_rate'])\n",
    "    # Schleife zur Generierung der zufälligen Werte\n",
    "    random.seed(seed)\n",
    "    for index, row in tqdm(df.iterrows()):\n",
    "        text = row[\"text\"].replace(\"\\n\", \" \")\n",
    "        \n",
    "        random_value = round(random.uniform(0.2, 0.8), 2)  # Zufälliger Wert zwischen 0.2 und 0.8 auf zwei Stellen nach dem Komma begrenzt\n",
    "        text_rank_text= compression(text.replace(\"\\n\\n\", \" \"),random_value,split)\n",
    "        compression_ratio_value=compression_ratio(text, compression(text,random_value,split))\n",
    "        text=re.sub(' +', ' ', text.replace(\"\\n\", \" \").replace('-',' ').replace('_',' ').replace(\"\\'\", \"\").replace(\"!\", \".\").replace(\"?\", \".\").replace(\";\", \"\"))\n",
    "        text_rank_text=re.sub(' +', ' ', text_rank_text.replace(\"\\n\", \" \").replace('-',' ').replace('_',' ').replace(\"\\'\", \"\").replace(\"!\", \".\").replace(\"?\", \".\").replace(\";\", \"\"))\n",
    "        df_current = pd.DataFrame({\n",
    "                'text':[text],\n",
    "                'text_rank_text': [text_rank_text],\n",
    "                'tokens_gesamt': [len(text.split(' '))],\n",
    "                'token_text_rank': [len(text_rank_text.split(' '))],\n",
    "                'desired_compression_rate': [random_value],\n",
    "                'text_rank_compression_rate': [compression_ratio_value]\n",
    "            })\n",
    "            # Fügen Sie die Daten zum DataFrame hinzu\n",
    "        df_return = pd.concat([df_return, df_current], ignore_index=True)\n",
    "    return df_return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_text_gen(df,split='\\. ',seed=10):\n",
    "    rank_df=text_rank_algo(df,seed=seed,split=split)\n",
    "    df_zwischen=calculate_compression(rank_df, 'tokens_gesamt', 'token_text_rank', 'desired_compression_rate')\n",
    "    df_sum=paraphrase_of_text(df_zwischen[['text_rank_text','reduction_multiplier']],text_name='text_rank_text',split=split)\n",
    "    merged_df = pd.concat([df_sum, df_zwischen], axis=1)\n",
    "    merged_df['ent_com_rate']=merged_df['länge Zusammenfassung'] / merged_df['tokens_gesamt']\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Scientific', 'news', 'reviews', 'story'], dtype=object)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.classification.unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training=df_train[df_train.classification=='news'].reset_index(drop=True)[['classification','text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'It was good horrifying never a dull moment u can watch and not be bored ir wondering when is a good part coming'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_training[186:187]['text'][186]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Whale naturalist and animal communicator Mary Getten goes beyond what other research has achieved in the way of whale study and communication processes: in 1991 she studied the J-Pod, a family of whales off Washington State']"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textrank_extractive(df_training[177:178]['text'][177],0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Whale naturalist and animal communicator Mary Getten goes beyond what other research has achieved in the way of whale study and communication processes: in 1991 she studied the J-Pod, a family of whales off Washington State',\n",
       " 'Her contention that they use direct telepathic communication between themselves and can do so with humans also makes for fascinating reading.Diane C',\n",
       " 'DonovanCalifornia Bookwatch']"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.split(fr'(?<!\\b\\w\\w)\\. ', df_training[177:178]['text'][177].replace(\"\\n\\n\", \" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df=df_train[df_train.classification=='news'].reset_index(drop=True)[['classification','text']][200:200+50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "for satz in test_df[36:37]['text'][236].split('.'):\n",
    "    if len(satz)<2:\n",
    "        print(satz)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "doc = nlp(df_training[67:68]['text'][67].replace(\"\\n\\n\", \" \").replace(\"-\", \" \"))\n",
    "[sent.text for sent in doc.sents if len(sent.text.replace(\"-\", \" \").split()) > 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classification</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>story</td>\n",
       "      <td>PART I\\n\\nIf you don't like Christmas stories,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>story</td>\n",
       "      <td>The Railroad Journey was very long and slow. T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>story</td>\n",
       "      <td>His affair that night was prosy. He was intend...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>story</td>\n",
       "      <td>This is the tale which Jehan Tugluk Khan, a wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>story</td>\n",
       "      <td>THE fact that the man whom he feared had died ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>story</td>\n",
       "      <td>IBRAHIM FADLALLAH shrugged bis shoulders: \"You...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>story</td>\n",
       "      <td>BEHIND him the Koh Haji-Lal, the \"Mountains of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>story</td>\n",
       "      <td>SPEAKING in after years about that period of h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>story</td>\n",
       "      <td>The ease and apparent willingness with which s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>story</td>\n",
       "      <td>Along in the 80's there occurred a question of...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  classification                                               text\n",
       "0          story  PART I\\n\\nIf you don't like Christmas stories,...\n",
       "1          story  The Railroad Journey was very long and slow. T...\n",
       "2          story  His affair that night was prosy. He was intend...\n",
       "3          story  This is the tale which Jehan Tugluk Khan, a wi...\n",
       "4          story  THE fact that the man whom he feared had died ...\n",
       "5          story  IBRAHIM FADLALLAH shrugged bis shoulders: \"You...\n",
       "6          story  BEHIND him the Koh Haji-Lal, the \"Mountains of...\n",
       "7          story  SPEAKING in after years about that period of h...\n",
       "8          story  The ease and apparent willingness with which s...\n",
       "9          story  Along in the 80's there occurred a question of..."
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'King Henry, the Handsome Scholar, had one son, named William, whom he dearly loved. The young man was noble and brave, and every-body hoped that he would some day be the King of England. One summer Prince William went with his father across the sea to look after their lands in France. They were wel-comed with joy by all their people there, and the young prince was so gallant and kind, that he won the love of all who saw him. But at last the time came for them to go back to England. The king, with his wise men and brave knights, set sail early in the day; but Prince William with his younger friends waited a little while. They had had so joyous a time in France that they were in no great haste to tear them-selves away. Then they went on board of the ship which was waiting to carry them home. It was a beau-ti-ful ship with white sails and white masts, and it had been fitted up on purpose for this voyage. The sea was smooth, the winds were fair, and no one thought of danger. On the ship, every-thing had been ar-ranged to make the trip a pleasant one. There was music and dancing, and everybody was merry and glad. The sun had gone down before the white-winged vessel was fairly out of the bay. But what of that? The moon was at its full, and it would give light enough; and before the dawn of the morrow, the narrow sea would be crossed. And so the prince, and the young people who were with him, gave themselves up to mer-ri-ment and feasting and joy. The ear-li-er hours of the night passed by; and then there was a cry of alarm on deck. A moment after-ward there was a great crash. The ship had struck upon a rock. The water rushed in. She was sinking. Ah, where now were those who had lately been so heart-free and glad? Every heart was full of fear. No one knew what to do. A small boat was quickly launched, and the prince with a few of his bravest friends leaped into it. They pushed off just as the ship was be-gin-ning to settle beneath the waves. Would they be saved? They had rowed hardly ten yards from the ship, when there was a cry from among those that were left behind. \"Row back!\" cried the prince. \"It is my little sister. She must be saved!\" The men did not dare to disobey. The boat was again brought along-side of the sinking vessel. The prince stood up, and held out his arms for his sister. At that moment the ship gave a great lurch forward into the waves. One shriek of terror was heard, and then all was still save the sound of the moaning waters. Ship and boat, prince and prin-cess, and all the gay com-pa-ny that had set sail from France, went down to the bottom together. One man clung to a floating plank, and was saved the next day. He was the only person left alive to tell the sad story. When King Henry heard of the death of his son his grief was more than he could bear. His heart was broken. He had no more joy in life; and men say that no one ever saw him smile again. Here is a poem about him that your teacher may read to you, and perhaps, after a while, you may learn it by heart. HE NEVER SMILED AGAIN. There stood proud forms before his throne, The stately and the brave; But who could fill the place of one,-- That one beneath the wave? Before him passed the young and fair, In pleasure\\'s reckless train; But seas dashed o\\'er his son\\'s bright hair-- He never smiled again. He sat where festal bowls went round; He heard the minstrel sing; He saw the tour-ney\\'s victor crowned Amid the knightly ring. A murmur of the restless deep Was blent with every strain, A voice of winds that would not sleep-- He never smiled again. Hearts, in that time, closed o\\'er the trace Of vows once fondly poured, And strangers took the kins-man\\'s place At many a joyous board; Graves which true love had bathed with tears Were left to heaven\\'s bright rain; Fresh hopes were born for other years-- _He_ never smiled again! '"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub(' +', ' ', df_training[16:17]['text'][16].replace(\"\\n\", \" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_2='King Henry, the Handsome Scholar, had one son, named William, whom he dearly loved. The young man was noble and brave, and every-body hoped that he would some day be the King of England. One summer Prince William went with his father across the sea to look after their lands in France. They were wel-comed with joy by all their people there, and the young prince was so gallant and kind, that he won the love of all who saw him. But at last the time came for them to go back to England. The king, with his wise men and brave knights, set sail early in the day; but Prince William with his younger friends waited a little while. They had had so joyous a time in France that they were in no great haste to tear them-selves away. Then they went on board of the ship which was waiting to carry them home. It was a beau-ti-ful ship with white sails and white masts, and it had been fitted up on purpose for this voyage. The sea was smooth, the winds were fair, and no one thought of danger. On the ship, every-thing had been ar-ranged to make the trip a pleasant one. There was music and dancing, and everybody was merry and glad. The sun had gone down before the white-winged vessel was fairly out of the bay. But what of that? The moon was at its full, and it would give light enough; and before the dawn of the morrow, the narrow sea would be crossed. And so the prince, and the young people who were with him, gave themselves up to mer-ri-ment and feasting and joy. The ear-li-er hours of the night passed by; and then there was a cry of alarm on deck. A moment after-ward there was a great crash. The ship had struck upon a rock. The water rushed in. She was sinking. Ah, where now were those who had lately been so heart-free and glad? Every heart was full of fear. No one knew what to do. A small boat was quickly launched, and the prince with a few of his bravest friends leaped into it. They pushed off just as the ship was be-gin-ning to settle beneath the waves. Would they be saved? They had rowed hardly ten yards from the ship, when there was a cry from among those that were left behind. \"Row back!\" cried the prince.\"It is my little sister. She must be saved!\" The men did not dare to disobey. The boat was again brought along-side of the sinking vessel. The prince stood up, and held out his arms for his sister. At that moment the ship gave a great lurch forward into the waves. One shriek of terror was heard, and then all was still save the sound of the moaning waters. Ship and boat, prince and prin-cess, and all the gay com-pa-ny that had set sail from France, went down to the bottom together. One man clung to a floating plank, and was saved the next day. He was the only person left alive to tell the sad story. When King Henry heard of the death of his son his grief was more than he could bear. His heart was broken. He had no more joy in life; and men say that no one ever saw him smile again. Here is a poem about him that your teacher may read to you, and perhaps, after a while, you may learn it by heart. HE NEVER SMILED AGAIN.There stood proud forms before his throne, The stately and the brave; But who could fill the place of one,-- That one beneath the wave? Before him passed the young and fair, In pleasure\\'s reckless train; But seas dashed o\\'er his son\\'s bright hair-- He never smiled again. He sat where festal bowls went round; He heard the minstrel sing; He saw the tour-ney\\'s victor crowned Amid the knightly ring. A murmur of the restless deep Was blent with every strain, A voice of winds that would not sleep-- He never smiled again. Hearts, in that time, closed o\\'er the trace Of vows once fondly poured, And strangers took the kins-man\\'s place At many a joyous board; Graves which true love had bathed with tears Were left to heaven\\'s bright rain; Fresh hopes were born for other years-- _He_ never smiled again! '\n",
    "type(text_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_2=str(re.sub(' +', ' ', df_training[16:17]['text'][16].replace(\"\\n\", \" \")))\n",
    "type(text_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_2='King Henry, the Handsome Scholar, had one son, named William, whom he dearly loved. The young man was noble and brave, and every-body hoped that he would some day be the King of England. One summer Prince William went with his father across the sea to look after their lands in France. They were wel-comed with joy by all their people there, and the young prince was so gallant and kind, that he won the love of all who saw him. But at last the time came for them to go back to England. The king, with his wise men and brave knights, set sail early in the day; but Prince William with his younger friends waited a little while. They had had so joyous a time in France that they were in no great haste to tear them-selves away. Then they went on board of the ship which was waiting to carry them home. It was a beau-ti-ful ship with white sails and white masts, and it had been fitted up on purpose for this voyage. The sea was smooth, the winds were fair, and no one thought of danger. On the ship, every-thing had been ar-ranged to make the trip a pleasant one. There was music and dancing, and everybody was merry and glad. The sun had gone down before the white-winged vessel was fairly out of the bay. But what of that? The moon was at its full, and it would give light enough; and before the dawn of the morrow, the narrow sea would be crossed. And so the prince, and the young people who were with him, gave themselves up to mer-ri-ment and feasting and joy. The ear-li-er hours of the night passed by; and then there was a cry of alarm on deck. A moment after-ward there was a great crash. The ship had struck upon a rock. The water rushed in. She was sinking. Ah, where now were those who had lately been so heart-free and glad? Every heart was full of fear. No one knew what to do. A small boat was quickly launched, and the prince with a few of his bravest friends leaped into it. They pushed off just as the ship was be-gin-ning to settle beneath the waves. Would they be saved? They had rowed hardly ten yards from the ship, when there was a cry from among those that were left behind. \"Row back!\" cried the prince.\"It is my little sister. She must be saved!\" The men did not dare to disobey. The boat was again brought along-side of the sinking vessel. The prince stood up, and held out his arms for his sister. At that moment the ship gave a great lurch forward into the waves. One shriek of terror was heard, and then all was still save the sound of the moaning waters. Ship and boat, prince and prin-cess, and all the gay com-pa-ny that had set sail from France, went down to the bottom together. One man clung to a floating plank, and was saved the next day. He was the only person left alive to tell the sad story. When King Henry heard of the death of his son his grief was more than he could bear. His heart was broken. He had no more joy in life; and men say that no one ever saw him smile again. Here is a poem about him that your teacher may read to you, and perhaps, after a while, you may learn it by heart. HE NEVER SMILED AGAIN.There stood proud forms before his throne, The stately and the brave; But who could fill the place of one,-- That one beneath the wave? Before him passed the young and fair, In pleasure\\'s reckless train; But seas dashed o\\'er his son\\'s bright hair-- He never smiled again. He sat where festal bowls went round; He heard the minstrel sing; He saw the tour-ney\\'s victor crowned Amid the knightly ring. A murmur of the restless deep Was blent with every strain, A voice of winds that would not sleep-- He never smiled again. Hearts, in that time, closed o\\'er the trace Of vows once fondly poured, And strangers took the kins-man\\'s place At many a joyous board; Graves which true love had bathed with tears Were left to heaven\\'s bright rain; Fresh hopes were born for other years-- _He_ never smiled again! '\n",
    "text_2=str(re.sub(' +', ' ', df_training[16:17]['text'][16].replace(\"\\n\", \" \")))\n",
    "textrank_extractive(text_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "textrank_extractive(re.sub(' +', ' ', df_training[16:17]['text'][16].replace(\"\\n\", \" \").replace('-',' ').replace('_',' ').replace(\"\\'\", \"\").replace(\"!\", \".\").replace(\"?\", \".\").replace(\";\", \"\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "758"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(re.sub(' +', ' ', df_training[16:17]['text'][16].replace(\"\\n\", \" \").replace('-',' ').replace('_',' ').replace(\"\\'\", \"\").replace(\"!\", \".\").replace(\"?\", \".\").replace('\"','').replace(\";\", \"\")).split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "textrank_extractive(df_training[16:17]['text'][16].replace(\"\\n\", \" \").replace('     ',' ').replace('    ',' ').replace('   ',' ').replace('--',' ').replace('_','').replace(\"\\'\", \"\").replace(\"!\", \".\").replace(\"?\", \".\").replace('\"','').replace(\";\", \"\"))\n",
    "#re.sub(' +', ' ', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=re.sub(' +', ' ', df_training[16:17]['text'][16].replace(\"\\n\", \" \").replace('--',' ').replace('_',' ').replace(\"\\'\", \"\"))\n",
    "textrank_extractive(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training=df_train[df_train.classification=='reviews'].reset_index(drop=True)[['classification','text']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classification</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>reviews</td>\n",
       "      <td>This sound track was beautiful! It paints the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>reviews</td>\n",
       "      <td>I'm reading a lot of reviews saying that this ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>reviews</td>\n",
       "      <td>This soundtrack is my favorite music of all ti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>reviews</td>\n",
       "      <td>I truly like this soundtrack and I enjoy video...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>reviews</td>\n",
       "      <td>If you've played the game, you know how divine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>reviews</td>\n",
       "      <td>This book is a wonderful illustration of the s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>reviews</td>\n",
       "      <td>I think beyond the fact that Hazlitt produces ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>reviews</td>\n",
       "      <td>Economics in One Lesson elucidates the basic p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>reviews</td>\n",
       "      <td>Economics in One Lesson is another great \"must...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>reviews</td>\n",
       "      <td>Sure, a few of the specific examples cited 60+...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    classification                                               text\n",
       "0          reviews  This sound track was beautiful! It paints the ...\n",
       "1          reviews  I'm reading a lot of reviews saying that this ...\n",
       "2          reviews  This soundtrack is my favorite music of all ti...\n",
       "3          reviews  I truly like this soundtrack and I enjoy video...\n",
       "4          reviews  If you've played the game, you know how divine...\n",
       "..             ...                                                ...\n",
       "495        reviews  This book is a wonderful illustration of the s...\n",
       "496        reviews  I think beyond the fact that Hazlitt produces ...\n",
       "497        reviews  Economics in One Lesson elucidates the basic p...\n",
       "498        reviews  Economics in One Lesson is another great \"must...\n",
       "499        reviews  Sure, a few of the specific examples cited 60+...\n",
       "\n",
       "[500 rows x 2 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/var/folders/k3/z_svrdgd6sb9lc9bqdfzp_k00000gn/T/ipykernel_89249/1576956366.py:38: DeprecationWarning: networkx.pagerank_numpy is deprecated and will be removed in NetworkX 3.0, use networkx.pagerank instead.\n",
      "  scores = nx.pagerank_numpy(graph)\n",
      "/Users/niclascramer/opt/miniconda3/envs/torch/lib/python3.9/site-packages/networkx/algorithms/link_analysis/pagerank_alg.py:354: FutureWarning: google_matrix will return an np.ndarray instead of a np.matrix in\n",
      "NetworkX version 3.0.\n",
      "  M = google_matrix(\n",
      "390it [36:03,  9.85s/it]"
     ]
    }
   ],
   "source": [
    "df_training=df_train[df_train.classification=='news'].reset_index(drop=True)[['classification','text']].copy()\n",
    "alsdf_sum=execute_text_gen(df_training,split='\\. ')\n",
    "alsdf_sum.to_csv('data/ergbnisse/train_news.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['The Administration of Union Territory Daman and Diu has revoked its order that made it compulsory for women to tie rakhis to their male colleagues on the occasion of Rakshabandhan on August 7.']\""
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_test=pd.read_csv('data/ergbnisse/train_news_test.csv')\n",
    "#news_test[['batch_texts','batch_output']]\n",
    "news_test['batch_output'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Administration of Union Territory Daman and Diu has revoked its order that made it compulsory for women to tie rakhis to their male colleagues on the occasion of Rakshabandhan on August 7. The administration was forced to withdraw the decision within 24 hours of issuing the circular after it received flak from employees and was slammed on social media.'"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_test['text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['The Administration of Union Territory Daman and Diu has revoked its order that made it compulsory for women to tie rakhis to their male colleagues on the occasion of Rakshabandhan on August 7']\""
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_test['batch_texts'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training=df_train[df_train.classification=='news'].reset_index(drop=True)[['classification','text']].copy()\n",
    "rank_df=text_rank_algo(df_training)\n",
    "df_zwischen=calculate_compression(rank_df, 'tokens_gesamt', 'token_text_rank', 'desired_compression_rate')\n",
    "alsdf_sum.to_csv(f'data/ergbnisse/train_news.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/var/folders/k3/z_svrdgd6sb9lc9bqdfzp_k00000gn/T/ipykernel_89249/1902150806.py:28: DeprecationWarning: networkx.pagerank_numpy is deprecated and will be removed in NetworkX 3.0, use networkx.pagerank instead.\n",
      "  scores = nx.pagerank_numpy(graph)\n",
      "/Users/niclascramer/opt/miniconda3/envs/torch/lib/python3.9/site-packages/networkx/algorithms/link_analysis/pagerank_alg.py:354: FutureWarning: google_matrix will return an np.ndarray instead of a np.matrix in\n",
      "NetworkX version 3.0.\n",
      "  M = google_matrix(\n",
      "100it [05:52,  3.52s/it]\n"
     ]
    }
   ],
   "source": [
    "seed=14\n",
    "for x in range(0,401,100):\n",
    "  df_training=df_train[df_train.classification=='reviews'].reset_index(drop=True)[['classification','text']][x:x+100].reset_index(drop=True).copy()\n",
    "  rank_df=text_rank_algo(df_training,seed=seed)\n",
    "  df_zwischen=calculate_compression(rank_df, 'tokens_gesamt', 'token_text_rank', 'desired_compression_rate')\n",
    "  df_zwischen.to_csv(f'data/ergbnisse/train_story_text_rank_{x+100}.csv')\n",
    "  seed+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'my husband and I watched this and ended up watching something else. this will be a waste of your time'"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[df_train.classification=='reviews'].reset_index(drop=True)[416:417]['text'][416]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/var/folders/k3/z_svrdgd6sb9lc9bqdfzp_k00000gn/T/ipykernel_89249/1576956366.py:38: DeprecationWarning: networkx.pagerank_numpy is deprecated and will be removed in NetworkX 3.0, use networkx.pagerank instead.\n",
      "  scores = nx.pagerank_numpy(graph)\n",
      "/Users/niclascramer/opt/miniconda3/envs/torch/lib/python3.9/site-packages/networkx/algorithms/link_analysis/pagerank_alg.py:354: FutureWarning: google_matrix will return an np.ndarray instead of a np.matrix in\n",
      "NetworkX version 3.0.\n",
      "  M = google_matrix(\n",
      "100it [06:14,  3.74s/it]\n",
      "Verarbeite Batches: 100%|██████████| 1/1 [00:05<00:00,  5.31s/it]\n",
      "Verarbeite Batches: 100%|██████████| 1/1 [00:04<00:00,  4.76s/it]\n",
      "Verarbeite Batches: 100%|██████████| 1/1 [00:06<00:00,  6.52s/it]\n",
      "Verarbeite Batches: 100%|██████████| 1/1 [00:03<00:00,  3.44s/it]\n",
      "Verarbeite Batches: 100%|██████████| 1/1 [00:05<00:00,  5.27s/it]\n",
      "Verarbeite Batches: 100%|██████████| 1/1 [00:12<00:00, 12.03s/it]\n",
      "Verarbeite Batches: 100%|██████████| 1/1 [00:08<00:00,  8.96s/it]\n",
      "Verarbeite Batches: 100%|██████████| 1/1 [00:02<00:00,  2.33s/it]\n",
      "Verarbeite Batches: 100%|██████████| 1/1 [00:03<00:00,  3.74s/it]\n",
      "Verarbeite Batches: 100%|██████████| 1/1 [00:03<00:00,  3.02s/it]\n",
      "Verarbeite Batches: 100%|██████████| 1/1 [00:01<00:00,  1.56s/it]\n",
      "Verarbeite Batches: 100%|██████████| 1/1 [00:06<00:00,  6.59s/it]\n",
      "Verarbeite Batches: 100%|██████████| 1/1 [00:04<00:00,  4.16s/it]\n",
      "Verarbeite Batches: 100%|██████████| 1/1 [00:02<00:00,  2.04s/it]\n",
      "Verarbeite Batches: 100%|██████████| 1/1 [00:09<00:00,  9.57s/it]\n",
      "Verarbeite Batches: 100%|██████████| 1/1 [00:02<00:00,  2.54s/it]\n",
      "Verarbeite Batches: 100%|██████████| 1/1 [00:06<00:00,  6.26s/it]\n",
      "Verarbeite Batches: 100%|██████████| 1/1 [00:04<00:00,  4.16s/it]\n",
      "Verarbeite Batches: 100%|██████████| 1/1 [00:04<00:00,  4.05s/it]\n",
      "Verarbeite Batches: 100%|██████████| 1/1 [00:02<00:00,  2.67s/it]\n",
      "Verarbeite Batches: 100%|██████████| 1/1 [00:03<00:00,  3.83s/it]\n",
      "Verarbeite Batches: 100%|██████████| 1/1 [00:16<00:00, 16.64s/it]\n",
      "Verarbeite Batches: 100%|██████████| 1/1 [00:03<00:00,  3.53s/it]\n",
      "Verarbeite Batches: 100%|██████████| 1/1 [00:12<00:00, 12.26s/it]\n",
      "Verarbeite Batches: 100%|██████████| 1/1 [00:04<00:00,  4.31s/it]\n",
      "Verarbeite Batches: 100%|██████████| 1/1 [00:09<00:00,  9.95s/it]\n",
      "Verarbeite Batches: 100%|██████████| 1/1 [00:05<00:00,  5.39s/it]\n",
      "Verarbeite Batches: 100%|██████████| 1/1 [00:02<00:00,  2.65s/it]\n",
      "Verarbeite Batches: 100%|██████████| 1/1 [00:02<00:00,  2.82s/it]\n",
      "Verarbeite Batches: 100%|██████████| 1/1 [00:04<00:00,  4.03s/it]\n",
      "Verarbeite Batches: 100%|██████████| 1/1 [00:06<00:00,  6.15s/it]\n",
      "Verarbeite Batches: 100%|██████████| 1/1 [00:05<00:00,  5.21s/it]\n",
      "Verarbeite Batches: 100%|██████████| 1/1 [00:02<00:00,  2.82s/it]\n",
      "Verarbeite Batches: 100%|██████████| 1/1 [00:17<00:00, 17.22s/it]\n",
      "Verarbeite Batches: 100%|██████████| 1/1 [00:02<00:00,  2.13s/it]\n",
      "Verarbeite Batches: 100%|██████████| 1/1 [00:05<00:00,  5.73s/it]\n",
      "Verarbeite Batches: 100%|██████████| 1/1 [00:05<00:00,  5.19s/it]\n",
      "Verarbeite Batches: 100%|██████████| 1/1 [00:02<00:00,  2.64s/it]\n",
      "Verarbeite Batches: 100%|██████████| 1/1 [00:02<00:00,  2.04s/it]\n",
      "Verarbeite Batches: 100%|██████████| 1/1 [00:05<00:00,  5.83s/it]\n",
      "Verarbeite Batches: 100%|██████████| 1/1 [00:02<00:00,  2.51s/it]\n",
      "Verarbeite Batches: 100%|██████████| 1/1 [00:09<00:00,  9.17s/it]\n",
      "Verarbeite Batches: 100%|██████████| 1/1 [00:01<00:00,  1.80s/it]\n",
      "Verarbeite Batches: 100%|██████████| 1/1 [00:01<00:00,  1.55s/it]\n",
      "Verarbeite Batches: 100%|██████████| 1/1 [00:01<00:00,  1.46s/it]\n",
      "Verarbeite Batches: 100%|██████████| 1/1 [00:04<00:00,  4.83s/it]\n",
      "Verarbeite Batches: 100%|██████████| 1/1 [00:05<00:00,  5.79s/it]\n",
      "Verarbeite Batches: 100%|██████████| 1/1 [00:04<00:00,  4.55s/it]\n",
      "Verarbeite Batches: 100%|██████████| 1/1 [00:03<00:00,  3.74s/it]\n",
      "Verarbeite Batches: 100%|██████████| 1/1 [00:02<00:00,  2.40s/it]\n",
      "Verarbeite Batches: 100%|██████████| 1/1 [00:03<00:00,  3.99s/it]\n",
      "Verarbeite Batches: 100%|██████████| 1/1 [00:07<00:00,  7.99s/it]\n",
      "Verarbeite Batches: 100%|██████████| 1/1 [00:04<00:00,  4.80s/it]\n",
      "Verarbeite Batches: 100%|██████████| 1/1 [00:03<00:00,  3.53s/it]\n",
      "Verarbeite Batches: 100%|██████████| 1/1 [00:04<00:00,  4.19s/it]\n",
      "Verarbeite Batches: 100%|██████████| 1/1 [00:02<00:00,  2.82s/it]\n",
      "Verarbeite Batches: 100%|██████████| 1/1 [00:02<00:00,  2.97s/it]\n",
      "Verarbeite Batches: 100%|██████████| 1/1 [00:04<00:00,  4.26s/it]\n",
      "Verarbeite Batches: 100%|██████████| 1/1 [00:02<00:00,  2.11s/it]\n",
      "Verarbeite Batches: 100%|██████████| 1/1 [00:02<00:00,  2.86s/it]\n",
      "Verarbeite Batches: 100%|██████████| 1/1 [00:02<00:00,  2.74s/it]\n",
      "Verarbeite Batches: 100%|██████████| 1/1 [00:01<00:00,  1.89s/it]\n",
      "Verarbeite Batches: 100%|██████████| 1/1 [00:03<00:00,  3.62s/it]\n",
      "Verarbeite Batches: 100%|██████████| 1/1 [00:04<00:00,  4.35s/it]\n",
      "Verarbeite Batches: 100%|██████████| 1/1 [00:01<00:00,  1.67s/it]\n",
      "Verarbeite Batches: 100%|██████████| 1/1 [00:03<00:00,  3.58s/it]\n",
      "Verarbeite Batches: 100%|██████████| 1/1 [00:03<00:00,  3.67s/it]\n",
      "Verarbeite Batches: 100%|██████████| 1/1 [00:02<00:00,  2.84s/it]\n",
      "Verarbeite Batches: 100%|██████████| 1/1 [00:05<00:00,  5.09s/it]\n",
      "Verarbeite Batches: 100%|██████████| 1/1 [00:03<00:00,  3.85s/it]\n",
      "Verarbeite Batches: 100%|██████████| 1/1 [00:04<00:00,  4.38s/it]\n",
      "Verarbeite Batches: 100%|██████████| 1/1 [00:09<00:00,  9.68s/it]\n",
      "Verarbeite Batches: 100%|██████████| 1/1 [00:03<00:00,  3.09s/it]\n",
      "Verarbeite Batches: 100%|██████████| 1/1 [00:07<00:00,  7.23s/it]\n",
      "Verarbeite Batches: 100%|██████████| 1/1 [00:03<00:00,  3.45s/it]\n",
      "Verarbeite Batches: 100%|██████████| 1/1 [00:13<00:00, 13.16s/it]\n",
      "Verarbeite Batches: 100%|██████████| 1/1 [00:04<00:00,  4.90s/it]\n",
      "Verarbeite Batches: 100%|██████████| 1/1 [00:02<00:00,  2.26s/it]\n",
      "Verarbeite Batches: 100%|██████████| 1/1 [00:00<00:00,  1.16it/s]\n",
      "Verarbeite Batches: 100%|██████████| 1/1 [00:02<00:00,  2.60s/it]\n",
      "Verarbeite Batches: 100%|██████████| 1/1 [00:05<00:00,  5.79s/it]\n",
      "Verarbeite Batches: 100%|██████████| 1/1 [00:07<00:00,  7.79s/it]\n",
      "Verarbeite Batches: 100%|██████████| 1/1 [00:04<00:00,  4.92s/it]\n",
      "Verarbeite Batches: 100%|██████████| 1/1 [00:03<00:00,  3.59s/it]\n",
      "Verarbeite Batches: 100%|██████████| 1/1 [00:02<00:00,  2.40s/it]\n",
      "Verarbeite Batches: 100%|██████████| 1/1 [00:04<00:00,  4.03s/it]\n",
      "Verarbeite Batches: 100%|██████████| 1/1 [00:02<00:00,  2.19s/it]\n",
      "Verarbeite Batches: 100%|██████████| 1/1 [00:03<00:00,  3.42s/it]\n",
      "Verarbeite Batches:   0%|          | 0/1 [00:02<?, ?it/s]\n",
      " 88%|████████▊ | 88/100 [06:58<00:57,  4.75s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/var/folders/k3/z_svrdgd6sb9lc9bqdfzp_k00000gn/T/ipykernel_89249/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">238664303.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">4</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: </span>                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">'/var/folders/k3/z_svrdgd6sb9lc9bqdfzp_k00000gn/T/ipykernel_89249/238664303.py'</span>                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/var/folders/k3/z_svrdgd6sb9lc9bqdfzp_k00000gn/T/ipykernel_89249/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">233606247.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">4</span> in               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">execute_text_gen</span>                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: </span>                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">'/var/folders/k3/z_svrdgd6sb9lc9bqdfzp_k00000gn/T/ipykernel_89249/233606247.py'</span>                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/var/folders/k3/z_svrdgd6sb9lc9bqdfzp_k00000gn/T/ipykernel_89249/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">78837128.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">21</span> in               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">paraphrase_of_text</span>                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: </span>                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">'/var/folders/k3/z_svrdgd6sb9lc9bqdfzp_k00000gn/T/ipykernel_89249/78837128.py'</span>                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/Users/niclascramer/opt/miniconda3/envs/torch/lib/python3.9/site-packages/transformers/pipelines</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">text2text_generation.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">150</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__call__</span>                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">147 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   │   │     </span><span style=\"color: #808000; text-decoration-color: #808000\">ids of the generated text.</span>                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">148 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"</span>                                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">149 │   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>150 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>result = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">super</span>().<span style=\"color: #00ff00; text-decoration-color: #00ff00\">__call__</span>(*args, **kwargs)                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">151 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> (                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">152 │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">isinstance</span>(args[<span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>], <span style=\"color: #00ffff; text-decoration-color: #00ffff\">list</span>)                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">153 │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">and</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">all</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">isinstance</span>(el, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">str</span>) <span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> el <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> args[<span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>])                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/Users/niclascramer/opt/miniconda3/envs/torch/lib/python3.9/site-packages/transformers/pipelines</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">base.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1074</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__call__</span>                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1071 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">elif</span> is_iterable:                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1072 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.iterate(inputs, preprocess_params, forward_params, postprocess_p  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1073 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1074 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.run_single(inputs, preprocess_params, forward_params, postproces  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1075 │   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1076 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">run_multi</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, inputs, preprocess_params, forward_params, postprocess_params):   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1077 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> [<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.run_single(item, preprocess_params, forward_params, postprocess_par  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/Users/niclascramer/opt/miniconda3/envs/torch/lib/python3.9/site-packages/transformers/pipelines</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">base.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1081</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">run_single</span>                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1078 │   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1079 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">run_single</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, inputs, preprocess_params, forward_params, postprocess_params):  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1080 │   │   </span>model_inputs = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.preprocess(inputs, **preprocess_params)                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1081 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>model_outputs = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.forward(model_inputs, **forward_params)                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1082 │   │   </span>outputs = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.postprocess(model_outputs, **postprocess_params)                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1083 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> outputs                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1084 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/Users/niclascramer/opt/miniconda3/envs/torch/lib/python3.9/site-packages/transformers/pipelines</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">base.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">990</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 987 │   │   │   │   </span>inference_context = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.get_inference_context()                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 988 │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">with</span> inference_context():                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 989 │   │   │   │   │   </span>model_inputs = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._ensure_tensor_on_device(model_inputs, device=<span style=\"color: #00ffff; text-decoration-color: #00ffff\">se</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 990 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span>model_outputs = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward(model_inputs, **forward_params)         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 991 │   │   │   │   │   </span>model_outputs = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._ensure_tensor_on_device(model_outputs, device=  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 992 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 993 │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">ValueError</span>(<span style=\"color: #808000; text-decoration-color: #808000\">f\"Framework {</span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.framework<span style=\"color: #808000; text-decoration-color: #808000\">} is not supported\"</span>)          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/Users/niclascramer/opt/miniconda3/envs/torch/lib/python3.9/site-packages/transformers/pipelines</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">text2text_generation.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">172</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_forward</span>                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">169 │   │   </span>generate_kwargs[<span style=\"color: #808000; text-decoration-color: #808000\">\"min_length\"</span>] = generate_kwargs.get(<span style=\"color: #808000; text-decoration-color: #808000\">\"min_length\"</span>, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.model.con   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">170 │   │   </span>generate_kwargs[<span style=\"color: #808000; text-decoration-color: #808000\">\"max_length\"</span>] = generate_kwargs.get(<span style=\"color: #808000; text-decoration-color: #808000\">\"max_length\"</span>, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.model.con   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">171 │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.check_inputs(input_length, generate_kwargs[<span style=\"color: #808000; text-decoration-color: #808000\">\"min_length\"</span>], generate_kwargs[<span style=\"color: #808000; text-decoration-color: #808000\">\"</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>172 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>output_ids = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.model.generate(**model_inputs, **generate_kwargs)                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">173 │   │   </span>out_b = output_ids.shape[<span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>]                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">174 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.framework == <span style=\"color: #808000; text-decoration-color: #808000\">\"pt\"</span>:                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">175 │   │   │   </span>output_ids = output_ids.reshape(in_b, out_b // in_b, *output_ids.shape[<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>:])    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/Users/niclascramer/opt/miniconda3/envs/torch/lib/python3.9/site-packages/torch/autograd/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">grad_mo</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">de.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">34</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">decorate_context</span>                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 31 │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">@functools</span>.wraps(func)                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 32 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">decorate_context</span>(*args, **kwargs):                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 33 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">with</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.clone():                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 34 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> func(*args, **kwargs)                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 35 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> cast(F, decorate_context)                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 36 │   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 37 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_wrap_generator</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, func):                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/Users/niclascramer/opt/miniconda3/envs/torch/lib/python3.9/site-packages/transformers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">generatio</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">n_utils.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1577</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">generate</span>                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1574 │   │   │   │   </span>input_ids, expand_size=num_beams, is_encoder_decoder=<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.config.is_enco  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1575 │   │   │   </span>)                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1576 │   │   │   # 12. run beam search</span>                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1577 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.beam_search(                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1578 │   │   │   │   </span>input_ids,                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1579 │   │   │   │   </span>beam_scorer,                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1580 │   │   │   │   </span>logits_processor=logits_processor,                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/Users/niclascramer/opt/miniconda3/envs/torch/lib/python3.9/site-packages/transformers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">generatio</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">n_utils.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2747</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">beam_search</span>                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2744 │   │   │   </span>                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2745 │   │   │   </span>model_inputs = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.prepare_inputs_for_generation(input_ids, **model_kwargs)  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2746 │   │   │   </span>                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>2747 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>outputs = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>(                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2748 │   │   │   │   </span>**model_inputs,                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2749 │   │   │   │   </span>return_dict=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>,                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2750 │   │   │   │   </span>output_attentions=output_attentions,                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/Users/niclascramer/opt/miniconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">modul</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">e.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1482</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1479 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1480 │   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1481 │   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1482 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*args, **kwargs)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1483 │   │   # Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1484 │   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1485 │   │   </span>backward_pre_hooks = []                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/Users/niclascramer/opt/miniconda3/envs/torch/lib/python3.9/site-packages/transformers/models/ba</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">rt/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">modeling_bart.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1362</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1359 │   │   │   │   │   </span>labels, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.config.pad_token_id, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.config.decoder_start_token_id  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1360 │   │   │   │   </span>)                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1361 │   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1362 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>outputs = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.model(                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1363 │   │   │   </span>input_ids,                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1364 │   │   │   </span>attention_mask=attention_mask,                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1365 │   │   │   </span>decoder_input_ids=decoder_input_ids,                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/Users/niclascramer/opt/miniconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">modul</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">e.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1482</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1479 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1480 │   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1481 │   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1482 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*args, **kwargs)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1483 │   │   # Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1484 │   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1485 │   │   </span>backward_pre_hooks = []                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/Users/niclascramer/opt/miniconda3/envs/torch/lib/python3.9/site-packages/transformers/models/ba</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">rt/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">modeling_bart.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1249</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1246 │   │   │   </span>)                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1247 │   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1248 │   │   # decoder outputs consists of (dec_features, past_key_value, dec_hidden, dec_att</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1249 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>decoder_outputs = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.decoder(                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1250 │   │   │   </span>input_ids=decoder_input_ids,                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1251 │   │   │   </span>attention_mask=decoder_attention_mask,                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1252 │   │   │   </span>encoder_hidden_states=encoder_outputs[<span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>],                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/Users/niclascramer/opt/miniconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">modul</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">e.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1482</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1479 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1480 │   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1481 │   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1482 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*args, **kwargs)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1483 │   │   # Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1484 │   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1485 │   │   </span>backward_pre_hooks = []                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/Users/niclascramer/opt/miniconda3/envs/torch/lib/python3.9/site-packages/transformers/models/ba</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">rt/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">modeling_bart.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1107</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1104 │   │   │   │   </span>)                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1105 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1106 │   │   │   │   </span>                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1107 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>layer_outputs = decoder_layer(                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1108 │   │   │   │   │   </span>hidden_states,                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1109 │   │   │   │   │   </span>attention_mask=attention_mask,                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1110 │   │   │   │   │   </span>encoder_hidden_states=encoder_hidden_states,                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/Users/niclascramer/opt/miniconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">modul</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">e.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1482</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1479 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1480 │   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1481 │   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1482 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*args, **kwargs)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1483 │   │   # Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1484 │   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1485 │   │   </span>backward_pre_hooks = []                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/Users/niclascramer/opt/miniconda3/envs/torch/lib/python3.9/site-packages/transformers/models/ba</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">rt/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">modeling_bart.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">420</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 417 │   │   # decoder uni-directional self-attention cached key/values tuple is at positions</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 418 │   │   </span>self_attn_past_key_value = past_key_value[:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2</span>] <span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> past_key_value <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 419 │   │   # add present self-attn cache to positions 1,2 of present_key_value tuple</span>         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 420 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>hidden_states, self_attn_weights, present_key_value = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.self_attn(             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 421 │   │   │   </span>hidden_states=hidden_states,                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 422 │   │   │   </span>past_key_value=self_attn_past_key_value,                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 423 │   │   │   </span>attention_mask=attention_mask,                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/Users/niclascramer/opt/miniconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">modul</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">e.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1482</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1479 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1480 │   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1481 │   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1482 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*args, **kwargs)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1483 │   │   # Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1484 │   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1485 │   │   </span>backward_pre_hooks = []                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/Users/niclascramer/opt/miniconda3/envs/torch/lib/python3.9/site-packages/transformers/models/ba</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">rt/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">modeling_bart.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">206</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 203 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">elif</span> past_key_value <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 204 │   │   │   # reuse k, v, self_attention</span>                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 205 │   │   │   </span>key_states = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._shape(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.k_proj(hidden_states), -<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>, bsz)                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 206 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>value_states = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._shape(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.v_proj(hidden_states), -<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>, bsz)               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 207 │   │   │   </span>key_states = torch.cat([past_key_value[<span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>], key_states], dim=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2</span>)                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 208 │   │   │   </span>value_states = torch.cat([past_key_value[<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>], value_states], dim=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2</span>)            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 209 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/Users/niclascramer/opt/miniconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">modul</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">e.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1482</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1479 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1480 │   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1481 │   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1482 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*args, **kwargs)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1483 │   │   # Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1484 │   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1485 │   │   </span>backward_pre_hooks = []                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/Users/niclascramer/opt/miniconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">linea</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">r.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">114</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">111 │   │   │   </span>init.uniform_(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.bias, -bound, bound)                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">112 │   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">113 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>: Tensor) -&gt; Tensor:                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>114 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> F.linear(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.weight, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.bias)                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">115 │   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">116 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">extra_repr</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>) -&gt; <span style=\"color: #00ffff; text-decoration-color: #00ffff\">str</span>:                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">117 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #808000; text-decoration-color: #808000\">'in_features={}, out_features={}, bias={}'</span>.format(                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">KeyboardInterrupt</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/var/folders/k3/z_svrdgd6sb9lc9bqdfzp_k00000gn/T/ipykernel_89249/\u001b[0m\u001b[1;33m238664303.py\u001b[0m:\u001b[94m4\u001b[0m in \u001b[92m<module>\u001b[0m      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: \u001b[0m                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m'/var/folders/k3/z_svrdgd6sb9lc9bqdfzp_k00000gn/T/ipykernel_89249/238664303.py'\u001b[0m                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/var/folders/k3/z_svrdgd6sb9lc9bqdfzp_k00000gn/T/ipykernel_89249/\u001b[0m\u001b[1;33m233606247.py\u001b[0m:\u001b[94m4\u001b[0m in               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92mexecute_text_gen\u001b[0m                                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: \u001b[0m                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m'/var/folders/k3/z_svrdgd6sb9lc9bqdfzp_k00000gn/T/ipykernel_89249/233606247.py'\u001b[0m                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/var/folders/k3/z_svrdgd6sb9lc9bqdfzp_k00000gn/T/ipykernel_89249/\u001b[0m\u001b[1;33m78837128.py\u001b[0m:\u001b[94m21\u001b[0m in               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92mparaphrase_of_text\u001b[0m                                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: \u001b[0m                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m'/var/folders/k3/z_svrdgd6sb9lc9bqdfzp_k00000gn/T/ipykernel_89249/78837128.py'\u001b[0m                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/Users/niclascramer/opt/miniconda3/envs/torch/lib/python3.9/site-packages/transformers/pipelines\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/\u001b[0m\u001b[1;33mtext2text_generation.py\u001b[0m:\u001b[94m150\u001b[0m in \u001b[92m__call__\u001b[0m                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m147 \u001b[0m\u001b[2;33m│   │   │     \u001b[0m\u001b[33mids of the generated text.\u001b[0m                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m148 \u001b[0m\u001b[2;33m│   │   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m149 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m150 \u001b[2m│   │   \u001b[0mresult = \u001b[96msuper\u001b[0m().\u001b[92m__call__\u001b[0m(*args, **kwargs)                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m151 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m (                                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m152 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96misinstance\u001b[0m(args[\u001b[94m0\u001b[0m], \u001b[96mlist\u001b[0m)                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m153 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[95mand\u001b[0m \u001b[96mall\u001b[0m(\u001b[96misinstance\u001b[0m(el, \u001b[96mstr\u001b[0m) \u001b[94mfor\u001b[0m el \u001b[95min\u001b[0m args[\u001b[94m0\u001b[0m])                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/Users/niclascramer/opt/miniconda3/envs/torch/lib/python3.9/site-packages/transformers/pipelines\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/\u001b[0m\u001b[1;33mbase.py\u001b[0m:\u001b[94m1074\u001b[0m in \u001b[92m__call__\u001b[0m                                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1071 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melif\u001b[0m is_iterable:                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1072 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m.iterate(inputs, preprocess_params, forward_params, postprocess_p  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1073 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1074 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m.run_single(inputs, preprocess_params, forward_params, postproces  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1075 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1076 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mrun_multi\u001b[0m(\u001b[96mself\u001b[0m, inputs, preprocess_params, forward_params, postprocess_params):   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1077 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m [\u001b[96mself\u001b[0m.run_single(item, preprocess_params, forward_params, postprocess_par  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/Users/niclascramer/opt/miniconda3/envs/torch/lib/python3.9/site-packages/transformers/pipelines\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/\u001b[0m\u001b[1;33mbase.py\u001b[0m:\u001b[94m1081\u001b[0m in \u001b[92mrun_single\u001b[0m                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1078 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1079 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mrun_single\u001b[0m(\u001b[96mself\u001b[0m, inputs, preprocess_params, forward_params, postprocess_params):  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1080 \u001b[0m\u001b[2m│   │   \u001b[0mmodel_inputs = \u001b[96mself\u001b[0m.preprocess(inputs, **preprocess_params)                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1081 \u001b[2m│   │   \u001b[0mmodel_outputs = \u001b[96mself\u001b[0m.forward(model_inputs, **forward_params)                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1082 \u001b[0m\u001b[2m│   │   \u001b[0moutputs = \u001b[96mself\u001b[0m.postprocess(model_outputs, **postprocess_params)                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1083 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m outputs                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1084 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/Users/niclascramer/opt/miniconda3/envs/torch/lib/python3.9/site-packages/transformers/pipelines\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/\u001b[0m\u001b[1;33mbase.py\u001b[0m:\u001b[94m990\u001b[0m in \u001b[92mforward\u001b[0m                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 987 \u001b[0m\u001b[2m│   │   │   │   \u001b[0minference_context = \u001b[96mself\u001b[0m.get_inference_context()                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 988 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mwith\u001b[0m inference_context():                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 989 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mmodel_inputs = \u001b[96mself\u001b[0m._ensure_tensor_on_device(model_inputs, device=\u001b[96mse\u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 990 \u001b[2m│   │   │   │   │   \u001b[0mmodel_outputs = \u001b[96mself\u001b[0m._forward(model_inputs, **forward_params)         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 991 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mmodel_outputs = \u001b[96mself\u001b[0m._ensure_tensor_on_device(model_outputs, device=  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 992 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 993 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mValueError\u001b[0m(\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33mFramework \u001b[0m\u001b[33m{\u001b[0m\u001b[96mself\u001b[0m.framework\u001b[33m}\u001b[0m\u001b[33m is not supported\u001b[0m\u001b[33m\"\u001b[0m)          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/Users/niclascramer/opt/miniconda3/envs/torch/lib/python3.9/site-packages/transformers/pipelines\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/\u001b[0m\u001b[1;33mtext2text_generation.py\u001b[0m:\u001b[94m172\u001b[0m in \u001b[92m_forward\u001b[0m                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m169 \u001b[0m\u001b[2m│   │   \u001b[0mgenerate_kwargs[\u001b[33m\"\u001b[0m\u001b[33mmin_length\u001b[0m\u001b[33m\"\u001b[0m] = generate_kwargs.get(\u001b[33m\"\u001b[0m\u001b[33mmin_length\u001b[0m\u001b[33m\"\u001b[0m, \u001b[96mself\u001b[0m.model.con   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m170 \u001b[0m\u001b[2m│   │   \u001b[0mgenerate_kwargs[\u001b[33m\"\u001b[0m\u001b[33mmax_length\u001b[0m\u001b[33m\"\u001b[0m] = generate_kwargs.get(\u001b[33m\"\u001b[0m\u001b[33mmax_length\u001b[0m\u001b[33m\"\u001b[0m, \u001b[96mself\u001b[0m.model.con   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m171 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.check_inputs(input_length, generate_kwargs[\u001b[33m\"\u001b[0m\u001b[33mmin_length\u001b[0m\u001b[33m\"\u001b[0m], generate_kwargs[\u001b[33m\"\u001b[0m   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m172 \u001b[2m│   │   \u001b[0moutput_ids = \u001b[96mself\u001b[0m.model.generate(**model_inputs, **generate_kwargs)                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m173 \u001b[0m\u001b[2m│   │   \u001b[0mout_b = output_ids.shape[\u001b[94m0\u001b[0m]                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m174 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m.framework == \u001b[33m\"\u001b[0m\u001b[33mpt\u001b[0m\u001b[33m\"\u001b[0m:                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m175 \u001b[0m\u001b[2m│   │   │   \u001b[0moutput_ids = output_ids.reshape(in_b, out_b // in_b, *output_ids.shape[\u001b[94m1\u001b[0m:])    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/Users/niclascramer/opt/miniconda3/envs/torch/lib/python3.9/site-packages/torch/autograd/\u001b[0m\u001b[1;33mgrad_mo\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[1;33mde.py\u001b[0m:\u001b[94m34\u001b[0m in \u001b[92mdecorate_context\u001b[0m                                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 31 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[1;95m@functools\u001b[0m.wraps(func)                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 32 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mdecorate_context\u001b[0m(*args, **kwargs):                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 33 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mwith\u001b[0m \u001b[96mself\u001b[0m.clone():                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 34 \u001b[2m│   │   │   │   \u001b[0m\u001b[94mreturn\u001b[0m func(*args, **kwargs)                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 35 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m cast(F, decorate_context)                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 36 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 37 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m_wrap_generator\u001b[0m(\u001b[96mself\u001b[0m, func):                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/Users/niclascramer/opt/miniconda3/envs/torch/lib/python3.9/site-packages/transformers/\u001b[0m\u001b[1;33mgeneratio\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[1;33mn_utils.py\u001b[0m:\u001b[94m1577\u001b[0m in \u001b[92mgenerate\u001b[0m                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1574 \u001b[0m\u001b[2m│   │   │   │   \u001b[0minput_ids, expand_size=num_beams, is_encoder_decoder=\u001b[96mself\u001b[0m.config.is_enco  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1575 \u001b[0m\u001b[2m│   │   │   \u001b[0m)                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1576 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# 12. run beam search\u001b[0m                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1577 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m.beam_search(                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1578 \u001b[0m\u001b[2m│   │   │   │   \u001b[0minput_ids,                                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1579 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mbeam_scorer,                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1580 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mlogits_processor=logits_processor,                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/Users/niclascramer/opt/miniconda3/envs/torch/lib/python3.9/site-packages/transformers/\u001b[0m\u001b[1;33mgeneratio\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[1;33mn_utils.py\u001b[0m:\u001b[94m2747\u001b[0m in \u001b[92mbeam_search\u001b[0m                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2744 \u001b[0m\u001b[2m│   │   │   \u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2745 \u001b[0m\u001b[2m│   │   │   \u001b[0mmodel_inputs = \u001b[96mself\u001b[0m.prepare_inputs_for_generation(input_ids, **model_kwargs)  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2746 \u001b[0m\u001b[2m│   │   │   \u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m2747 \u001b[2m│   │   │   \u001b[0moutputs = \u001b[96mself\u001b[0m(                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2748 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m**model_inputs,                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2749 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mreturn_dict=\u001b[94mTrue\u001b[0m,                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2750 \u001b[0m\u001b[2m│   │   │   │   \u001b[0moutput_attentions=output_attentions,                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/Users/niclascramer/opt/miniconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodul\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[1;33me.py\u001b[0m:\u001b[94m1482\u001b[0m in \u001b[92m_call_impl\u001b[0m                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1479 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1480 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hooks                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1481 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1482 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1483 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1484 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1485 \u001b[0m\u001b[2m│   │   \u001b[0mbackward_pre_hooks = []                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/Users/niclascramer/opt/miniconda3/envs/torch/lib/python3.9/site-packages/transformers/models/ba\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33mrt/\u001b[0m\u001b[1;33mmodeling_bart.py\u001b[0m:\u001b[94m1362\u001b[0m in \u001b[92mforward\u001b[0m                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1359 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mlabels, \u001b[96mself\u001b[0m.config.pad_token_id, \u001b[96mself\u001b[0m.config.decoder_start_token_id  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1360 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m)                                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1361 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1362 \u001b[2m│   │   \u001b[0moutputs = \u001b[96mself\u001b[0m.model(                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1363 \u001b[0m\u001b[2m│   │   │   \u001b[0minput_ids,                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1364 \u001b[0m\u001b[2m│   │   │   \u001b[0mattention_mask=attention_mask,                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1365 \u001b[0m\u001b[2m│   │   │   \u001b[0mdecoder_input_ids=decoder_input_ids,                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/Users/niclascramer/opt/miniconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodul\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[1;33me.py\u001b[0m:\u001b[94m1482\u001b[0m in \u001b[92m_call_impl\u001b[0m                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1479 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1480 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hooks                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1481 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1482 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1483 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1484 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1485 \u001b[0m\u001b[2m│   │   \u001b[0mbackward_pre_hooks = []                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/Users/niclascramer/opt/miniconda3/envs/torch/lib/python3.9/site-packages/transformers/models/ba\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33mrt/\u001b[0m\u001b[1;33mmodeling_bart.py\u001b[0m:\u001b[94m1249\u001b[0m in \u001b[92mforward\u001b[0m                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1246 \u001b[0m\u001b[2m│   │   │   \u001b[0m)                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1247 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1248 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# decoder outputs consists of (dec_features, past_key_value, dec_hidden, dec_att\u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1249 \u001b[2m│   │   \u001b[0mdecoder_outputs = \u001b[96mself\u001b[0m.decoder(                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1250 \u001b[0m\u001b[2m│   │   │   \u001b[0minput_ids=decoder_input_ids,                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1251 \u001b[0m\u001b[2m│   │   │   \u001b[0mattention_mask=decoder_attention_mask,                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1252 \u001b[0m\u001b[2m│   │   │   \u001b[0mencoder_hidden_states=encoder_outputs[\u001b[94m0\u001b[0m],                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/Users/niclascramer/opt/miniconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodul\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[1;33me.py\u001b[0m:\u001b[94m1482\u001b[0m in \u001b[92m_call_impl\u001b[0m                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1479 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1480 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hooks                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1481 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1482 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1483 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1484 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1485 \u001b[0m\u001b[2m│   │   \u001b[0mbackward_pre_hooks = []                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/Users/niclascramer/opt/miniconda3/envs/torch/lib/python3.9/site-packages/transformers/models/ba\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33mrt/\u001b[0m\u001b[1;33mmodeling_bart.py\u001b[0m:\u001b[94m1107\u001b[0m in \u001b[92mforward\u001b[0m                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1104 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m)                                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1105 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1106 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1107 \u001b[2m│   │   │   │   \u001b[0mlayer_outputs = decoder_layer(                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1108 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mhidden_states,                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1109 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mattention_mask=attention_mask,                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1110 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mencoder_hidden_states=encoder_hidden_states,                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/Users/niclascramer/opt/miniconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodul\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[1;33me.py\u001b[0m:\u001b[94m1482\u001b[0m in \u001b[92m_call_impl\u001b[0m                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1479 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1480 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hooks                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1481 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1482 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1483 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1484 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1485 \u001b[0m\u001b[2m│   │   \u001b[0mbackward_pre_hooks = []                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/Users/niclascramer/opt/miniconda3/envs/torch/lib/python3.9/site-packages/transformers/models/ba\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33mrt/\u001b[0m\u001b[1;33mmodeling_bart.py\u001b[0m:\u001b[94m420\u001b[0m in \u001b[92mforward\u001b[0m                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 417 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# decoder uni-directional self-attention cached key/values tuple is at positions\u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 418 \u001b[0m\u001b[2m│   │   \u001b[0mself_attn_past_key_value = past_key_value[:\u001b[94m2\u001b[0m] \u001b[94mif\u001b[0m past_key_value \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m \u001b[94melse\u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 419 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# add present self-attn cache to positions 1,2 of present_key_value tuple\u001b[0m         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 420 \u001b[2m│   │   \u001b[0mhidden_states, self_attn_weights, present_key_value = \u001b[96mself\u001b[0m.self_attn(             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 421 \u001b[0m\u001b[2m│   │   │   \u001b[0mhidden_states=hidden_states,                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 422 \u001b[0m\u001b[2m│   │   │   \u001b[0mpast_key_value=self_attn_past_key_value,                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 423 \u001b[0m\u001b[2m│   │   │   \u001b[0mattention_mask=attention_mask,                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/Users/niclascramer/opt/miniconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodul\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[1;33me.py\u001b[0m:\u001b[94m1482\u001b[0m in \u001b[92m_call_impl\u001b[0m                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1479 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1480 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hooks                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1481 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1482 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1483 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1484 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1485 \u001b[0m\u001b[2m│   │   \u001b[0mbackward_pre_hooks = []                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/Users/niclascramer/opt/miniconda3/envs/torch/lib/python3.9/site-packages/transformers/models/ba\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33mrt/\u001b[0m\u001b[1;33mmodeling_bart.py\u001b[0m:\u001b[94m206\u001b[0m in \u001b[92mforward\u001b[0m                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 203 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melif\u001b[0m past_key_value \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m:                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 204 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# reuse k, v, self_attention\u001b[0m                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 205 \u001b[0m\u001b[2m│   │   │   \u001b[0mkey_states = \u001b[96mself\u001b[0m._shape(\u001b[96mself\u001b[0m.k_proj(hidden_states), -\u001b[94m1\u001b[0m, bsz)                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 206 \u001b[2m│   │   │   \u001b[0mvalue_states = \u001b[96mself\u001b[0m._shape(\u001b[96mself\u001b[0m.v_proj(hidden_states), -\u001b[94m1\u001b[0m, bsz)               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 207 \u001b[0m\u001b[2m│   │   │   \u001b[0mkey_states = torch.cat([past_key_value[\u001b[94m0\u001b[0m], key_states], dim=\u001b[94m2\u001b[0m)                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 208 \u001b[0m\u001b[2m│   │   │   \u001b[0mvalue_states = torch.cat([past_key_value[\u001b[94m1\u001b[0m], value_states], dim=\u001b[94m2\u001b[0m)            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 209 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/Users/niclascramer/opt/miniconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodul\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[1;33me.py\u001b[0m:\u001b[94m1482\u001b[0m in \u001b[92m_call_impl\u001b[0m                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1479 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1480 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hooks                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1481 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1482 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1483 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1484 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1485 \u001b[0m\u001b[2m│   │   \u001b[0mbackward_pre_hooks = []                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/Users/niclascramer/opt/miniconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mlinea\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[1;33mr.py\u001b[0m:\u001b[94m114\u001b[0m in \u001b[92mforward\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m111 \u001b[0m\u001b[2m│   │   │   \u001b[0minit.uniform_(\u001b[96mself\u001b[0m.bias, -bound, bound)                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m112 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m113 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mforward\u001b[0m(\u001b[96mself\u001b[0m, \u001b[96minput\u001b[0m: Tensor) -> Tensor:                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m114 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m F.linear(\u001b[96minput\u001b[0m, \u001b[96mself\u001b[0m.weight, \u001b[96mself\u001b[0m.bias)                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m115 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m116 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mextra_repr\u001b[0m(\u001b[96mself\u001b[0m) -> \u001b[96mstr\u001b[0m:                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m117 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[33m'\u001b[0m\u001b[33min_features=\u001b[0m\u001b[33m{}\u001b[0m\u001b[33m, out_features=\u001b[0m\u001b[33m{}\u001b[0m\u001b[33m, bias=\u001b[0m\u001b[33m{}\u001b[0m\u001b[33m'\u001b[0m.format(                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mKeyboardInterrupt\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "seed=10\n",
    "for x in range(0,401,100):\n",
    "  df_training=df_train[df_train.classification=='reviews'].reset_index(drop=True)[['classification','text']][x:x+100].reset_index(drop=True).copy()\n",
    "  alsdf_sum=execute_text_gen(df_training,split='\\. ',seed=seed)\n",
    "  alsdf_sum.to_csv(f'data/ergbnisse/train_review_2_{x+100}.csv')\n",
    "  seed+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Zusammenfassung</th>\n",
       "      <th>Min_Kompressionsrate</th>\n",
       "      <th>Max_Kompressionsrate</th>\n",
       "      <th>länge Zusammenfassung</th>\n",
       "      <th>text</th>\n",
       "      <th>tokens_gesamt</th>\n",
       "      <th>token_text_rank</th>\n",
       "      <th>desired_compression_rate</th>\n",
       "      <th>text_rank_compression_rate</th>\n",
       "      <th>current_compression_rate</th>\n",
       "      <th>reduction_multiplier</th>\n",
       "      <th>ent_com_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Administration of Union Territory Daman an...</td>\n",
       "      <td>34</td>\n",
       "      <td>84</td>\n",
       "      <td>33</td>\n",
       "      <td>The Administration of Union Territory Daman an...</td>\n",
       "      <td>60</td>\n",
       "      <td>33</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.981818</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Malaika Arora slammed an Instagram user who tr...</td>\n",
       "      <td>40</td>\n",
       "      <td>90</td>\n",
       "      <td>39</td>\n",
       "      <td>Malaika Arora slammed an Instagram user who tr...</td>\n",
       "      <td>60</td>\n",
       "      <td>39</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.707692</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bihar Health Minister defined virgin as being ...</td>\n",
       "      <td>36</td>\n",
       "      <td>86</td>\n",
       "      <td>34</td>\n",
       "      <td>The Indira Gandhi Institute of Medical Science...</td>\n",
       "      <td>60</td>\n",
       "      <td>35</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>0.566667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lashkar-e-Taiba's Kashmir commander Abu Dujana...</td>\n",
       "      <td>42</td>\n",
       "      <td>92</td>\n",
       "      <td>22</td>\n",
       "      <td>Lashkar-e-Taiba's Kashmir commander Abu Dujana...</td>\n",
       "      <td>60</td>\n",
       "      <td>40</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.366667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hotels in Maharashtra will train their staff t...</td>\n",
       "      <td>53</td>\n",
       "      <td>103</td>\n",
       "      <td>38</td>\n",
       "      <td>Hotels in Maharashtra will train their staff t...</td>\n",
       "      <td>60</td>\n",
       "      <td>51</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.811765</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Man, 32, was found hanging inside the washroom...</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>42</td>\n",
       "      <td>A 32-year-old man on Wednesday was found hangi...</td>\n",
       "      <td>60</td>\n",
       "      <td>48</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8625</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Delhi High Court reduced the compensation awar...</td>\n",
       "      <td>37</td>\n",
       "      <td>87</td>\n",
       "      <td>35</td>\n",
       "      <td>The Delhi High Court reduced the compensation ...</td>\n",
       "      <td>61</td>\n",
       "      <td>36</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.590164</td>\n",
       "      <td>0.999722</td>\n",
       "      <td>0.57377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>60-year-old Dalit woman was allegedly lynched ...</td>\n",
       "      <td>27</td>\n",
       "      <td>77</td>\n",
       "      <td>21</td>\n",
       "      <td>A 60-year old Dalit woman was allegedly lynche...</td>\n",
       "      <td>60</td>\n",
       "      <td>26</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The Pawan Hans helicopter was flying at a crit...</td>\n",
       "      <td>63</td>\n",
       "      <td>113</td>\n",
       "      <td>40</td>\n",
       "      <td>An inquiry by the Aircraft Accident Investigat...</td>\n",
       "      <td>61</td>\n",
       "      <td>60</td>\n",
       "      <td>0.51</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.983607</td>\n",
       "      <td>0.5185</td>\n",
       "      <td>0.655738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Congress party has opened a bank called 'State...</td>\n",
       "      <td>43</td>\n",
       "      <td>93</td>\n",
       "      <td>30</td>\n",
       "      <td>The Congress party has opened a bank called 'S...</td>\n",
       "      <td>57</td>\n",
       "      <td>41</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.556098</td>\n",
       "      <td>0.526316</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Zusammenfassung Min_Kompressionsrate  \\\n",
       "0  The Administration of Union Territory Daman an...                   34   \n",
       "1  Malaika Arora slammed an Instagram user who tr...                   40   \n",
       "2  Bihar Health Minister defined virgin as being ...                   36   \n",
       "3  Lashkar-e-Taiba's Kashmir commander Abu Dujana...                   42   \n",
       "4  Hotels in Maharashtra will train their staff t...                   53   \n",
       "5  Man, 32, was found hanging inside the washroom...                   50   \n",
       "6  Delhi High Court reduced the compensation awar...                   37   \n",
       "7  60-year-old Dalit woman was allegedly lynched ...                   27   \n",
       "8  The Pawan Hans helicopter was flying at a crit...                   63   \n",
       "9  Congress party has opened a bank called 'State...                   43   \n",
       "\n",
       "  Max_Kompressionsrate länge Zusammenfassung  \\\n",
       "0                   84                    33   \n",
       "1                   90                    39   \n",
       "2                   86                    34   \n",
       "3                   92                    22   \n",
       "4                  103                    38   \n",
       "5                  100                    42   \n",
       "6                   87                    35   \n",
       "7                   77                    21   \n",
       "8                  113                    40   \n",
       "9                   93                    30   \n",
       "\n",
       "                                                text tokens_gesamt  \\\n",
       "0  The Administration of Union Territory Daman an...            60   \n",
       "1  Malaika Arora slammed an Instagram user who tr...            60   \n",
       "2  The Indira Gandhi Institute of Medical Science...            60   \n",
       "3  Lashkar-e-Taiba's Kashmir commander Abu Dujana...            60   \n",
       "4  Hotels in Maharashtra will train their staff t...            60   \n",
       "5  A 32-year-old man on Wednesday was found hangi...            60   \n",
       "6  The Delhi High Court reduced the compensation ...            61   \n",
       "7  A 60-year old Dalit woman was allegedly lynche...            60   \n",
       "8  An inquiry by the Aircraft Accident Investigat...            61   \n",
       "9  The Congress party has opened a bank called 'S...            57   \n",
       "\n",
       "  token_text_rank  desired_compression_rate  text_rank_compression_rate  \\\n",
       "0              33                      0.54                    0.550000   \n",
       "1              39                      0.46                    0.650000   \n",
       "2              35                      0.55                    0.583333   \n",
       "3              40                      0.32                    0.666667   \n",
       "4              51                      0.69                    0.850000   \n",
       "5              48                      0.69                    0.800000   \n",
       "6              36                      0.59                    0.600000   \n",
       "7              26                      0.30                    0.433333   \n",
       "8              60                      0.51                    1.000000   \n",
       "9              41                      0.40                    0.719298   \n",
       "\n",
       "  current_compression_rate reduction_multiplier ent_com_rate  \n",
       "0                     0.55             0.981818         0.55  \n",
       "1                     0.65             0.707692         0.65  \n",
       "2                 0.583333             0.942857     0.566667  \n",
       "3                 0.666667                 0.48     0.366667  \n",
       "4                     0.85             0.811765     0.633333  \n",
       "5                      0.8               0.8625          0.7  \n",
       "6                 0.590164             0.999722      0.57377  \n",
       "7                 0.433333             0.692308         0.35  \n",
       "8                 0.983607               0.5185     0.655738  \n",
       "9                 0.719298             0.556098     0.526316  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sum[['Zusammenfassung', 'Min_Kompressionsrate', 'Max_Kompressionsrate',\n",
    "       'länge Zusammenfassung',\n",
    "       'text','tokens_gesamt',\n",
    "       'token_text_rank', 'desired_compression_rate',\n",
    "       'text_rank_compression_rate', 'current_compression_rate',\n",
    "      'reduction_multiplier', 'ent_com_rate']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/var/folders/k3/z_svrdgd6sb9lc9bqdfzp_k00000gn/T/ipykernel_89249/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">3261862292.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: </span>                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">'/var/folders/k3/z_svrdgd6sb9lc9bqdfzp_k00000gn/T/ipykernel_89249/3261862292.py'</span>                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/Users/niclascramer/opt/miniconda3/envs/torch/lib/python3.9/site-packages/pandas/core/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">frame.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">7</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">80</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__init__</span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  777 │   │   # For data is scalar</span>                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  778 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  779 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> index <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> columns <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>  780 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">ValueError</span>(<span style=\"color: #808000; text-decoration-color: #808000\">\"DataFrame constructor not properly called!\"</span>)           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  781 │   │   │   </span>                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  782 │   │   │   </span>index = ensure_index(index)                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  783 │   │   │   </span>columns = ensure_index(columns)                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">ValueError: </span>DataFrame constructor not properly called!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/var/folders/k3/z_svrdgd6sb9lc9bqdfzp_k00000gn/T/ipykernel_89249/\u001b[0m\u001b[1;33m3261862292.py\u001b[0m:\u001b[94m1\u001b[0m in \u001b[92m<module>\u001b[0m     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: \u001b[0m                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m'/var/folders/k3/z_svrdgd6sb9lc9bqdfzp_k00000gn/T/ipykernel_89249/3261862292.py'\u001b[0m                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/Users/niclascramer/opt/miniconda3/envs/torch/lib/python3.9/site-packages/pandas/core/\u001b[0m\u001b[1;33mframe.py\u001b[0m:\u001b[94m7\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[94m80\u001b[0m in \u001b[92m__init__\u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m  777 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# For data is scalar\u001b[0m                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m  778 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m  779 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m index \u001b[95mis\u001b[0m \u001b[94mNone\u001b[0m \u001b[95mor\u001b[0m columns \u001b[95mis\u001b[0m \u001b[94mNone\u001b[0m:                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m  780 \u001b[2m│   │   │   │   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mValueError\u001b[0m(\u001b[33m\"\u001b[0m\u001b[33mDataFrame constructor not properly called!\u001b[0m\u001b[33m\"\u001b[0m)           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m  781 \u001b[0m\u001b[2m│   │   │   \u001b[0m                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m  782 \u001b[0m\u001b[2m│   │   │   \u001b[0mindex = ensure_index(index)                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m  783 \u001b[0m\u001b[2m│   │   │   \u001b[0mcolumns = ensure_index(columns)                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mValueError: \u001b[0mDataFrame constructor not properly called!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df1=pd.DataFrame('data/ergbnisse/train_review_100.csv')\n",
    "df2=pd.DataFrame('data/ergbnisse/train_review_200.csv')\n",
    "df3=pd.DataFrame('data/ergbnisse/train_review_300.csv')\n",
    "df4=pd.DataFrame('data/ergbnisse/train_review_400.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "frames = [pd.read_csv('data/ergbnisse/train_review_100.csv'), pd.read_csv('data/ergbnisse/train_story_text_rank_200.csv'), pd.read_csv('data/ergbnisse/train_story_text_rank_300.csv'),pd.read_csv('data/ergbnisse/train_review_400.csv'),pd.read_csv('data/ergbnisse/train_review_500.csv')]\n",
    "\n",
    "# Verkettung der DataFrames und Neuzuweisung der Indizes\n",
    "df_review = pd.concat(frames, ignore_index=True).drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Zusammenfassung</th>\n",
       "      <th>Min_Kompressionsrate</th>\n",
       "      <th>Max_Kompressionsrate</th>\n",
       "      <th>Endgueltige_Kompressionsrate</th>\n",
       "      <th>länge Zusammenfassung</th>\n",
       "      <th>länge Ausgangstext</th>\n",
       "      <th>text</th>\n",
       "      <th>text_rank_text</th>\n",
       "      <th>tokens_gesamt</th>\n",
       "      <th>token_text_rank</th>\n",
       "      <th>desired_compression_rate</th>\n",
       "      <th>text_rank_compression_rate</th>\n",
       "      <th>current_compression_rate</th>\n",
       "      <th>compression_difference</th>\n",
       "      <th>reduction_multiplier</th>\n",
       "      <th>ent_com_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This sound track was beautiful! It paints the ...</td>\n",
       "      <td>78</td>\n",
       "      <td>128</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>57</td>\n",
       "      <td>75</td>\n",
       "      <td>This sound track was beautiful! It paints the ...</td>\n",
       "      <td>This sound track was beautiful! It paints the ...</td>\n",
       "      <td>75</td>\n",
       "      <td>75</td>\n",
       "      <td>0.54</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.460000</td>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.760000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The music is timeless and I'm been listening t...</td>\n",
       "      <td>58</td>\n",
       "      <td>108</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>56</td>\n",
       "      <td>56</td>\n",
       "      <td>I'm reading a lot of reviews saying that this ...</td>\n",
       "      <td>The music is timeless and I'm been listening t...</td>\n",
       "      <td>91</td>\n",
       "      <td>56</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>-0.155385</td>\n",
       "      <td>0.747500</td>\n",
       "      <td>0.615385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The soundtrack is amazing music, probably the ...</td>\n",
       "      <td>78</td>\n",
       "      <td>128</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>60</td>\n",
       "      <td>75</td>\n",
       "      <td>This soundtrack is my favorite music of all ti...</td>\n",
       "      <td>The higher energy tracks like \"Chrono Cross ~ ...</td>\n",
       "      <td>128</td>\n",
       "      <td>75</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.585938</td>\n",
       "      <td>0.585938</td>\n",
       "      <td>-0.035937</td>\n",
       "      <td>0.938667</td>\n",
       "      <td>0.468750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>On disk one Garden Of God, Chronopolis, Fates,...</td>\n",
       "      <td>64</td>\n",
       "      <td>114</td>\n",
       "      <td>40.983607</td>\n",
       "      <td>25</td>\n",
       "      <td>61</td>\n",
       "      <td>I truly like this soundtrack and I enjoy video...</td>\n",
       "      <td>I have played this game and most of the music ...</td>\n",
       "      <td>116</td>\n",
       "      <td>61</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.525862</td>\n",
       "      <td>0.525862</td>\n",
       "      <td>-0.205862</td>\n",
       "      <td>0.608525</td>\n",
       "      <td>0.215517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The music is perfect if you ask me, the best i...</td>\n",
       "      <td>80</td>\n",
       "      <td>130</td>\n",
       "      <td>67.532468</td>\n",
       "      <td>52</td>\n",
       "      <td>77</td>\n",
       "      <td>If you've played the game, you know how divine...</td>\n",
       "      <td>If you've played the game, you know how divine...</td>\n",
       "      <td>77</td>\n",
       "      <td>77</td>\n",
       "      <td>0.69</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.310000</td>\n",
       "      <td>0.690000</td>\n",
       "      <td>0.675325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>Only thing i found funny about this movie was ...</td>\n",
       "      <td>35</td>\n",
       "      <td>85</td>\n",
       "      <td>97.058824</td>\n",
       "      <td>33</td>\n",
       "      <td>34</td>\n",
       "      <td>His movies seem to be going down hill. The onl...</td>\n",
       "      <td>The only thing i found funny about this movie ...</td>\n",
       "      <td>42</td>\n",
       "      <td>34</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>-0.219524</td>\n",
       "      <td>0.728824</td>\n",
       "      <td>0.785714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>Comic has terminal illness that almost kills h...</td>\n",
       "      <td>42</td>\n",
       "      <td>92</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>28</td>\n",
       "      <td>40</td>\n",
       "      <td>FUNNY PEOPLE is somewhat compelling and engagi...</td>\n",
       "      <td>FUNNY PEOPLE is somewhat compelling and engagi...</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.470000</td>\n",
       "      <td>0.530000</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>\"This movie seems like it's all over the place...</td>\n",
       "      <td>49</td>\n",
       "      <td>99</td>\n",
       "      <td>76.595745</td>\n",
       "      <td>36</td>\n",
       "      <td>47</td>\n",
       "      <td>This is not a typical Adam Sandler movie, whic...</td>\n",
       "      <td>It's about \"comedy\" but I wouldn't consider th...</td>\n",
       "      <td>85</td>\n",
       "      <td>47</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.552941</td>\n",
       "      <td>0.552941</td>\n",
       "      <td>-0.022941</td>\n",
       "      <td>0.958511</td>\n",
       "      <td>0.423529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>I found the jokes and humor to be at best, lam...</td>\n",
       "      <td>48</td>\n",
       "      <td>98</td>\n",
       "      <td>102.173913</td>\n",
       "      <td>47</td>\n",
       "      <td>46</td>\n",
       "      <td>Adam Sadler plays an unlikable comedian, Georg...</td>\n",
       "      <td>Everyone has sex but Ira, which seems to be a ...</td>\n",
       "      <td>174</td>\n",
       "      <td>46</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.264368</td>\n",
       "      <td>0.264368</td>\n",
       "      <td>-0.044368</td>\n",
       "      <td>0.832174</td>\n",
       "      <td>0.270115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>Adam Sandler gives a terrific dramatic perform...</td>\n",
       "      <td>79</td>\n",
       "      <td>129</td>\n",
       "      <td>27.631579</td>\n",
       "      <td>21</td>\n",
       "      <td>76</td>\n",
       "      <td>Intelligent, funny, sad, real, with a terrific...</td>\n",
       "      <td>Intelligent, funny, sad, real, with a terrific...</td>\n",
       "      <td>76</td>\n",
       "      <td>76</td>\n",
       "      <td>0.46</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.540000</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>0.276316</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Zusammenfassung  Min_Kompressionsrate  \\\n",
       "0    This sound track was beautiful! It paints the ...                    78   \n",
       "1    The music is timeless and I'm been listening t...                    58   \n",
       "2    The soundtrack is amazing music, probably the ...                    78   \n",
       "3    On disk one Garden Of God, Chronopolis, Fates,...                    64   \n",
       "4    The music is perfect if you ask me, the best i...                    80   \n",
       "..                                                 ...                   ...   \n",
       "395  Only thing i found funny about this movie was ...                    35   \n",
       "396  Comic has terminal illness that almost kills h...                    42   \n",
       "397  \"This movie seems like it's all over the place...                    49   \n",
       "398  I found the jokes and humor to be at best, lam...                    48   \n",
       "399  Adam Sandler gives a terrific dramatic perform...                    79   \n",
       "\n",
       "     Max_Kompressionsrate  Endgueltige_Kompressionsrate  \\\n",
       "0                     128                     76.000000   \n",
       "1                     108                    100.000000   \n",
       "2                     128                     80.000000   \n",
       "3                     114                     40.983607   \n",
       "4                     130                     67.532468   \n",
       "..                    ...                           ...   \n",
       "395                    85                     97.058824   \n",
       "396                    92                     70.000000   \n",
       "397                    99                     76.595745   \n",
       "398                    98                    102.173913   \n",
       "399                   129                     27.631579   \n",
       "\n",
       "     länge Zusammenfassung  länge Ausgangstext  \\\n",
       "0                       57                  75   \n",
       "1                       56                  56   \n",
       "2                       60                  75   \n",
       "3                       25                  61   \n",
       "4                       52                  77   \n",
       "..                     ...                 ...   \n",
       "395                     33                  34   \n",
       "396                     28                  40   \n",
       "397                     36                  47   \n",
       "398                     47                  46   \n",
       "399                     21                  76   \n",
       "\n",
       "                                                  text  \\\n",
       "0    This sound track was beautiful! It paints the ...   \n",
       "1    I'm reading a lot of reviews saying that this ...   \n",
       "2    This soundtrack is my favorite music of all ti...   \n",
       "3    I truly like this soundtrack and I enjoy video...   \n",
       "4    If you've played the game, you know how divine...   \n",
       "..                                                 ...   \n",
       "395  His movies seem to be going down hill. The onl...   \n",
       "396  FUNNY PEOPLE is somewhat compelling and engagi...   \n",
       "397  This is not a typical Adam Sandler movie, whic...   \n",
       "398  Adam Sadler plays an unlikable comedian, Georg...   \n",
       "399  Intelligent, funny, sad, real, with a terrific...   \n",
       "\n",
       "                                        text_rank_text  tokens_gesamt  \\\n",
       "0    This sound track was beautiful! It paints the ...             75   \n",
       "1    The music is timeless and I'm been listening t...             91   \n",
       "2    The higher energy tracks like \"Chrono Cross ~ ...            128   \n",
       "3    I have played this game and most of the music ...            116   \n",
       "4    If you've played the game, you know how divine...             77   \n",
       "..                                                 ...            ...   \n",
       "395  The only thing i found funny about this movie ...             42   \n",
       "396  FUNNY PEOPLE is somewhat compelling and engagi...             40   \n",
       "397  It's about \"comedy\" but I wouldn't consider th...             85   \n",
       "398  Everyone has sex but Ira, which seems to be a ...            174   \n",
       "399  Intelligent, funny, sad, real, with a terrific...             76   \n",
       "\n",
       "     token_text_rank  desired_compression_rate  text_rank_compression_rate  \\\n",
       "0                 75                      0.54                    1.000000   \n",
       "1                 56                      0.46                    0.615385   \n",
       "2                 75                      0.55                    0.585938   \n",
       "3                 61                      0.32                    0.525862   \n",
       "4                 77                      0.69                    1.000000   \n",
       "..               ...                       ...                         ...   \n",
       "395               34                      0.59                    0.809524   \n",
       "396               40                      0.53                    1.000000   \n",
       "397               47                      0.53                    0.552941   \n",
       "398               46                      0.22                    0.264368   \n",
       "399               76                      0.46                    1.000000   \n",
       "\n",
       "     current_compression_rate  compression_difference  reduction_multiplier  \\\n",
       "0                    1.000000               -0.460000              0.540000   \n",
       "1                    0.615385               -0.155385              0.747500   \n",
       "2                    0.585938               -0.035937              0.938667   \n",
       "3                    0.525862               -0.205862              0.608525   \n",
       "4                    1.000000               -0.310000              0.690000   \n",
       "..                        ...                     ...                   ...   \n",
       "395                  0.809524               -0.219524              0.728824   \n",
       "396                  1.000000               -0.470000              0.530000   \n",
       "397                  0.552941               -0.022941              0.958511   \n",
       "398                  0.264368               -0.044368              0.832174   \n",
       "399                  1.000000               -0.540000              0.460000   \n",
       "\n",
       "     ent_com_rate  \n",
       "0        0.760000  \n",
       "1        0.615385  \n",
       "2        0.468750  \n",
       "3        0.215517  \n",
       "4        0.675325  \n",
       "..            ...  \n",
       "395      0.785714  \n",
       "396      0.700000  \n",
       "397      0.423529  \n",
       "398      0.270115  \n",
       "399      0.276316  \n",
       "\n",
       "[400 rows x 16 columns]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "frames = [pd.read_csv('data/ergbnisse/train_story_text_rank_100.csv'), pd.read_csv('data/ergbnisse/train_story_text_rank_200.csv'), pd.read_csv('data/ergbnisse/train_story_text_rank_300.csv'),pd.read_csv('data/ergbnisse/train_story_text_rank_400.csv'),pd.read_csv('data/ergbnisse/train_story_text_rank_500.csv')]\n",
    "\n",
    "# Verkettung der DataFrames und Neuzuweisung der Indizes\n",
    "df_story_text_rank = pd.concat(frames, ignore_index=True).drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_rank_text</th>\n",
       "      <th>tokens_gesamt</th>\n",
       "      <th>token_text_rank</th>\n",
       "      <th>desired_compression_rate</th>\n",
       "      <th>text_rank_compression_rate</th>\n",
       "      <th>current_compression_rate</th>\n",
       "      <th>compression_difference</th>\n",
       "      <th>reduction_multiplier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PART I If you don't like Christmas stories, do...</td>\n",
       "      <td>For I warn you perfectly frankly that I am dis...</td>\n",
       "      <td>5499</td>\n",
       "      <td>3773</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.686125</td>\n",
       "      <td>0.686125</td>\n",
       "      <td>-0.146125</td>\n",
       "      <td>0.787029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Railroad Journey was very long and slow. T...</td>\n",
       "      <td>And the Young Electrician who lolled across th...</td>\n",
       "      <td>5610</td>\n",
       "      <td>3999</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.712961</td>\n",
       "      <td>0.712834</td>\n",
       "      <td>-0.252834</td>\n",
       "      <td>0.645311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>His affair that night was prosy. He was intend...</td>\n",
       "      <td>He was intending the murder of an old Spanish ...</td>\n",
       "      <td>5644</td>\n",
       "      <td>4526</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.801914</td>\n",
       "      <td>0.801914</td>\n",
       "      <td>-0.251914</td>\n",
       "      <td>0.685859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This is the tale which Jehan Tugluk Khan, a wi...</td>\n",
       "      <td>This is the tale which Jehan Tugluk Khan, a wi...</td>\n",
       "      <td>4370</td>\n",
       "      <td>2414</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.552403</td>\n",
       "      <td>0.552403</td>\n",
       "      <td>-0.232403</td>\n",
       "      <td>0.579287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>THE fact that the man whom he feared had died ...</td>\n",
       "      <td>THE fact that the man whom he feared had died ...</td>\n",
       "      <td>3412</td>\n",
       "      <td>3065</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.898300</td>\n",
       "      <td>0.898300</td>\n",
       "      <td>-0.208300</td>\n",
       "      <td>0.768117</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  PART I If you don't like Christmas stories, do...   \n",
       "1  The Railroad Journey was very long and slow. T...   \n",
       "2  His affair that night was prosy. He was intend...   \n",
       "3  This is the tale which Jehan Tugluk Khan, a wi...   \n",
       "4  THE fact that the man whom he feared had died ...   \n",
       "\n",
       "                                      text_rank_text  tokens_gesamt  \\\n",
       "0  For I warn you perfectly frankly that I am dis...           5499   \n",
       "1  And the Young Electrician who lolled across th...           5610   \n",
       "2  He was intending the murder of an old Spanish ...           5644   \n",
       "3  This is the tale which Jehan Tugluk Khan, a wi...           4370   \n",
       "4  THE fact that the man whom he feared had died ...           3412   \n",
       "\n",
       "   token_text_rank  desired_compression_rate  text_rank_compression_rate  \\\n",
       "0             3773                      0.54                    0.686125   \n",
       "1             3999                      0.46                    0.712961   \n",
       "2             4526                      0.55                    0.801914   \n",
       "3             2414                      0.32                    0.552403   \n",
       "4             3065                      0.69                    0.898300   \n",
       "\n",
       "   current_compression_rate  compression_difference  reduction_multiplier  \n",
       "0                  0.686125               -0.146125              0.787029  \n",
       "1                  0.712834               -0.252834              0.645311  \n",
       "2                  0.801914               -0.251914              0.685859  \n",
       "3                  0.552403               -0.232403              0.579287  \n",
       "4                  0.898300               -0.208300              0.768117  "
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_story_text_rank.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Verarbeite Batches: 100%|██████████| 33/33 [06:33<00:00, 11.92s/it]\n",
      "Verarbeite Batches: 100%|██████████| 31/31 [04:42<00:00,  9.10s/it]\n",
      "Verarbeite Batches: 100%|██████████| 44/44 [06:49<00:00,  9.31s/it]\n",
      "Verarbeite Batches: 100%|██████████| 15/15 [02:10<00:00,  8.72s/it]\n",
      "Verarbeite Batches: 100%|██████████| 27/27 [05:14<00:00, 11.66s/it]\n",
      "100%|██████████| 5/5 [25:30<00:00, 306.17s/it]\n"
     ]
    }
   ],
   "source": [
    "df_sum=paraphrase_of_text(df_story_text_rank.head()[['text_rank_text','reduction_multiplier']],text_name='text_rank_text',split=split)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.concat([df_sum, df_story_text_rank.head()], axis=1)\n",
    "merged_df['ent_com_rate']=merged_df['länge Zusammenfassung'] / merged_df['tokens_gesamt']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k3/z_svrdgd6sb9lc9bqdfzp_k00000gn/T/ipykernel_89249/1497145124.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['current_compression_rate'] = df[current_tokens_col] / df[total_tokens_col]\n",
      "/var/folders/k3/z_svrdgd6sb9lc9bqdfzp_k00000gn/T/ipykernel_89249/1497145124.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['compression_difference'] = df[desired_compression_rate] - df['current_compression_rate']\n",
      "/var/folders/k3/z_svrdgd6sb9lc9bqdfzp_k00000gn/T/ipykernel_89249/1497145124.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['reduction_multiplier'] = df[desired_compression_rate] / df['current_compression_rate']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Zusammenfassung</th>\n",
       "      <th>länge Zusammenfassung</th>\n",
       "      <th>text</th>\n",
       "      <th>tokens_gesamt</th>\n",
       "      <th>desired_compression_rate</th>\n",
       "      <th>ent_com_rate</th>\n",
       "      <th>current_compression_rate</th>\n",
       "      <th>compression_difference</th>\n",
       "      <th>reduction_multiplier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Flame's mother gasped when she found out who w...</td>\n",
       "      <td>3485</td>\n",
       "      <td>PART I If you don't like Christmas stories, do...</td>\n",
       "      <td>5499</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.633752</td>\n",
       "      <td>0.633752</td>\n",
       "      <td>-0.093752</td>\n",
       "      <td>0.852069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Young Electrician was neither one length n...</td>\n",
       "      <td>2680</td>\n",
       "      <td>The Railroad Journey was very long and slow. T...</td>\n",
       "      <td>5610</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.477718</td>\n",
       "      <td>0.477718</td>\n",
       "      <td>-0.017718</td>\n",
       "      <td>0.96291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>He was intending the murder of an old Spanish ...</td>\n",
       "      <td>3803</td>\n",
       "      <td>His affair that night was prosy. He was intend...</td>\n",
       "      <td>5644</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.673813</td>\n",
       "      <td>0.673813</td>\n",
       "      <td>-0.123813</td>\n",
       "      <td>0.81625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The tale of Vasantasena, the slave who was fre...</td>\n",
       "      <td>1295</td>\n",
       "      <td>This is the tale which Jehan Tugluk Khan, a wi...</td>\n",
       "      <td>4370</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.296339</td>\n",
       "      <td>0.296339</td>\n",
       "      <td>0.023661</td>\n",
       "      <td>1.079846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stuart McGregor reconstructed the final scene ...</td>\n",
       "      <td>2948</td>\n",
       "      <td>THE fact that the man whom he feared had died ...</td>\n",
       "      <td>3412</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.864009</td>\n",
       "      <td>0.864009</td>\n",
       "      <td>-0.174009</td>\n",
       "      <td>0.798602</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Zusammenfassung länge Zusammenfassung  \\\n",
       "0  Flame's mother gasped when she found out who w...                  3485   \n",
       "1  The Young Electrician was neither one length n...                  2680   \n",
       "2  He was intending the murder of an old Spanish ...                  3803   \n",
       "3  The tale of Vasantasena, the slave who was fre...                  1295   \n",
       "4  Stuart McGregor reconstructed the final scene ...                  2948   \n",
       "\n",
       "                                                text  tokens_gesamt  \\\n",
       "0  PART I If you don't like Christmas stories, do...           5499   \n",
       "1  The Railroad Journey was very long and slow. T...           5610   \n",
       "2  His affair that night was prosy. He was intend...           5644   \n",
       "3  This is the tale which Jehan Tugluk Khan, a wi...           4370   \n",
       "4  THE fact that the man whom he feared had died ...           3412   \n",
       "\n",
       "   desired_compression_rate ent_com_rate current_compression_rate  \\\n",
       "0                      0.54     0.633752                 0.633752   \n",
       "1                      0.46     0.477718                 0.477718   \n",
       "2                      0.55     0.673813                 0.673813   \n",
       "3                      0.32     0.296339                 0.296339   \n",
       "4                      0.69     0.864009                 0.864009   \n",
       "\n",
       "  compression_difference reduction_multiplier  \n",
       "0              -0.093752             0.852069  \n",
       "1              -0.017718              0.96291  \n",
       "2              -0.123813              0.81625  \n",
       "3               0.023661             1.079846  \n",
       "4              -0.174009             0.798602  "
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Zusammenfassung</th>\n",
       "      <th>Min_Kompressionsrate</th>\n",
       "      <th>Max_Kompressionsrate</th>\n",
       "      <th>Endgueltige_Kompressionsrate</th>\n",
       "      <th>länge Zusammenfassung</th>\n",
       "      <th>länge Ausgangstext</th>\n",
       "      <th>text</th>\n",
       "      <th>text_rank_text</th>\n",
       "      <th>tokens_gesamt</th>\n",
       "      <th>token_text_rank</th>\n",
       "      <th>desired_compression_rate</th>\n",
       "      <th>text_rank_compression_rate</th>\n",
       "      <th>current_compression_rate</th>\n",
       "      <th>compression_difference</th>\n",
       "      <th>reduction_multiplier</th>\n",
       "      <th>ent_com_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Flame's mother gasped when she found out who w...</td>\n",
       "      <td>67</td>\n",
       "      <td>117</td>\n",
       "      <td>92.366817</td>\n",
       "      <td>3485</td>\n",
       "      <td>3773</td>\n",
       "      <td>PART I If you don't like Christmas stories, do...</td>\n",
       "      <td>For I warn you perfectly frankly that I am dis...</td>\n",
       "      <td>5499</td>\n",
       "      <td>3773</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.686125</td>\n",
       "      <td>0.686125</td>\n",
       "      <td>-0.146125</td>\n",
       "      <td>0.787029</td>\n",
       "      <td>0.633752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Young Electrician was neither one length n...</td>\n",
       "      <td>210</td>\n",
       "      <td>310</td>\n",
       "      <td>67.016754</td>\n",
       "      <td>2680</td>\n",
       "      <td>3999</td>\n",
       "      <td>The Railroad Journey was very long and slow. T...</td>\n",
       "      <td>And the Young Electrician who lolled across th...</td>\n",
       "      <td>5610</td>\n",
       "      <td>3999</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.712961</td>\n",
       "      <td>0.712834</td>\n",
       "      <td>-0.252834</td>\n",
       "      <td>0.645311</td>\n",
       "      <td>0.477718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>He was intending the murder of an old Spanish ...</td>\n",
       "      <td>53</td>\n",
       "      <td>103</td>\n",
       "      <td>84.025630</td>\n",
       "      <td>3803</td>\n",
       "      <td>4526</td>\n",
       "      <td>His affair that night was prosy. He was intend...</td>\n",
       "      <td>He was intending the murder of an old Spanish ...</td>\n",
       "      <td>5644</td>\n",
       "      <td>4526</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.801914</td>\n",
       "      <td>0.801914</td>\n",
       "      <td>-0.251914</td>\n",
       "      <td>0.685859</td>\n",
       "      <td>0.673813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The tale of Vasantasena, the slave who was fre...</td>\n",
       "      <td>60</td>\n",
       "      <td>110</td>\n",
       "      <td>53.645402</td>\n",
       "      <td>1295</td>\n",
       "      <td>2414</td>\n",
       "      <td>This is the tale which Jehan Tugluk Khan, a wi...</td>\n",
       "      <td>This is the tale which Jehan Tugluk Khan, a wi...</td>\n",
       "      <td>4370</td>\n",
       "      <td>2414</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.552403</td>\n",
       "      <td>0.552403</td>\n",
       "      <td>-0.232403</td>\n",
       "      <td>0.579287</td>\n",
       "      <td>0.296339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stuart McGregor reconstructed the final scene ...</td>\n",
       "      <td>67</td>\n",
       "      <td>117</td>\n",
       "      <td>96.182708</td>\n",
       "      <td>2948</td>\n",
       "      <td>3065</td>\n",
       "      <td>THE fact that the man whom he feared had died ...</td>\n",
       "      <td>THE fact that the man whom he feared had died ...</td>\n",
       "      <td>3412</td>\n",
       "      <td>3065</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.898300</td>\n",
       "      <td>0.898300</td>\n",
       "      <td>-0.208300</td>\n",
       "      <td>0.768117</td>\n",
       "      <td>0.864009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Zusammenfassung Min_Kompressionsrate  \\\n",
       "0  Flame's mother gasped when she found out who w...                   67   \n",
       "1  The Young Electrician was neither one length n...                  210   \n",
       "2  He was intending the murder of an old Spanish ...                   53   \n",
       "3  The tale of Vasantasena, the slave who was fre...                   60   \n",
       "4  Stuart McGregor reconstructed the final scene ...                   67   \n",
       "\n",
       "  Max_Kompressionsrate  Endgueltige_Kompressionsrate länge Zusammenfassung  \\\n",
       "0                  117                     92.366817                  3485   \n",
       "1                  310                     67.016754                  2680   \n",
       "2                  103                     84.025630                  3803   \n",
       "3                  110                     53.645402                  1295   \n",
       "4                  117                     96.182708                  2948   \n",
       "\n",
       "  länge Ausgangstext                                               text  \\\n",
       "0               3773  PART I If you don't like Christmas stories, do...   \n",
       "1               3999  The Railroad Journey was very long and slow. T...   \n",
       "2               4526  His affair that night was prosy. He was intend...   \n",
       "3               2414  This is the tale which Jehan Tugluk Khan, a wi...   \n",
       "4               3065  THE fact that the man whom he feared had died ...   \n",
       "\n",
       "                                      text_rank_text  tokens_gesamt  \\\n",
       "0  For I warn you perfectly frankly that I am dis...           5499   \n",
       "1  And the Young Electrician who lolled across th...           5610   \n",
       "2  He was intending the murder of an old Spanish ...           5644   \n",
       "3  This is the tale which Jehan Tugluk Khan, a wi...           4370   \n",
       "4  THE fact that the man whom he feared had died ...           3412   \n",
       "\n",
       "   token_text_rank  desired_compression_rate  text_rank_compression_rate  \\\n",
       "0             3773                      0.54                    0.686125   \n",
       "1             3999                      0.46                    0.712961   \n",
       "2             4526                      0.55                    0.801914   \n",
       "3             2414                      0.32                    0.552403   \n",
       "4             3065                      0.69                    0.898300   \n",
       "\n",
       "   current_compression_rate  compression_difference  reduction_multiplier  \\\n",
       "0                  0.686125               -0.146125              0.787029   \n",
       "1                  0.712834               -0.252834              0.645311   \n",
       "2                  0.801914               -0.251914              0.685859   \n",
       "3                  0.552403               -0.232403              0.579287   \n",
       "4                  0.898300               -0.208300              0.768117   \n",
       "\n",
       "  ent_com_rate  \n",
       "0     0.633752  \n",
       "1     0.477718  \n",
       "2     0.673813  \n",
       "3     0.296339  \n",
       "4     0.864009  "
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k3/z_svrdgd6sb9lc9bqdfzp_k00000gn/T/ipykernel_89249/1497145124.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['current_compression_rate'] = df[current_tokens_col] / df[total_tokens_col]\n",
      "/var/folders/k3/z_svrdgd6sb9lc9bqdfzp_k00000gn/T/ipykernel_89249/1497145124.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['compression_difference'] = df[desired_compression_rate] - df['current_compression_rate']\n",
      "/var/folders/k3/z_svrdgd6sb9lc9bqdfzp_k00000gn/T/ipykernel_89249/1497145124.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['reduction_multiplier'] = df[desired_compression_rate] / df['current_compression_rate']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Zusammenfassung</th>\n",
       "      <th>länge Zusammenfassung</th>\n",
       "      <th>text</th>\n",
       "      <th>tokens_gesamt</th>\n",
       "      <th>desired_compression_rate</th>\n",
       "      <th>ent_com_rate</th>\n",
       "      <th>current_compression_rate</th>\n",
       "      <th>compression_difference</th>\n",
       "      <th>reduction_multiplier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Flame's mother gasped when she found out who w...</td>\n",
       "      <td>3485</td>\n",
       "      <td>PART I If you don't like Christmas stories, do...</td>\n",
       "      <td>5499</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.633752</td>\n",
       "      <td>0.633752</td>\n",
       "      <td>-0.093752</td>\n",
       "      <td>0.852069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Young Electrician was neither one length n...</td>\n",
       "      <td>2680</td>\n",
       "      <td>The Railroad Journey was very long and slow. T...</td>\n",
       "      <td>5610</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.477718</td>\n",
       "      <td>0.477718</td>\n",
       "      <td>-0.017718</td>\n",
       "      <td>0.96291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>He was intending the murder of an old Spanish ...</td>\n",
       "      <td>3803</td>\n",
       "      <td>His affair that night was prosy. He was intend...</td>\n",
       "      <td>5644</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.673813</td>\n",
       "      <td>0.673813</td>\n",
       "      <td>-0.123813</td>\n",
       "      <td>0.81625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The tale of Vasantasena, the slave who was fre...</td>\n",
       "      <td>1295</td>\n",
       "      <td>This is the tale which Jehan Tugluk Khan, a wi...</td>\n",
       "      <td>4370</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.296339</td>\n",
       "      <td>0.296339</td>\n",
       "      <td>0.023661</td>\n",
       "      <td>1.079846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stuart McGregor reconstructed the final scene ...</td>\n",
       "      <td>2948</td>\n",
       "      <td>THE fact that the man whom he feared had died ...</td>\n",
       "      <td>3412</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.864009</td>\n",
       "      <td>0.864009</td>\n",
       "      <td>-0.174009</td>\n",
       "      <td>0.798602</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Zusammenfassung länge Zusammenfassung  \\\n",
       "0  Flame's mother gasped when she found out who w...                  3485   \n",
       "1  The Young Electrician was neither one length n...                  2680   \n",
       "2  He was intending the murder of an old Spanish ...                  3803   \n",
       "3  The tale of Vasantasena, the slave who was fre...                  1295   \n",
       "4  Stuart McGregor reconstructed the final scene ...                  2948   \n",
       "\n",
       "                                                text  tokens_gesamt  \\\n",
       "0  PART I If you don't like Christmas stories, do...           5499   \n",
       "1  The Railroad Journey was very long and slow. T...           5610   \n",
       "2  His affair that night was prosy. He was intend...           5644   \n",
       "3  This is the tale which Jehan Tugluk Khan, a wi...           4370   \n",
       "4  THE fact that the man whom he feared had died ...           3412   \n",
       "\n",
       "   desired_compression_rate ent_com_rate current_compression_rate  \\\n",
       "0                      0.54     0.633752                 0.633752   \n",
       "1                      0.46     0.477718                 0.477718   \n",
       "2                      0.55     0.673813                 0.673813   \n",
       "3                      0.32     0.296339                 0.296339   \n",
       "4                      0.69     0.864009                 0.864009   \n",
       "\n",
       "  compression_difference reduction_multiplier  \n",
       "0              -0.093752             0.852069  \n",
       "1              -0.017718              0.96291  \n",
       "2              -0.123813              0.81625  \n",
       "3               0.023661             1.079846  \n",
       "4              -0.174009             0.798602  "
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_zwischen_test=calculate_compression(merged_df[['Zusammenfassung','länge Zusammenfassung','text','tokens_gesamt','desired_compression_rate','ent_com_rate']], 'tokens_gesamt', 'länge Zusammenfassung', 'desired_compression_rate')\n",
    "df_zwischen_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k3/z_svrdgd6sb9lc9bqdfzp_k00000gn/T/ipykernel_89249/1902150806.py:28: DeprecationWarning: networkx.pagerank_numpy is deprecated and will be removed in NetworkX 3.0, use networkx.pagerank instead.\n",
      "  scores = nx.pagerank_numpy(graph)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7069167643610785"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compression_ratio(df_zwischen_test['text'][4:5][4], compression(df_zwischen_test['Zusammenfassung'][4:5][4],df_zwischen_test['desired_compression_rate'][4:5][4],'\\. '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compression(df_zwischen_test['Zusammenfassung'][0:1][0],df_zwischen_test['reduction_multiplier'][0:1][0],'\\. ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6872801875732708"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len('. '.join(merged_df['Zusammenfassung'][4:5][4].split('. ')[:-40]).split())/merged_df['tokens_gesamt'][4:5][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_df=text_rank_algo(df,seed=seed,split=split)\n",
    "df_zwischen=calculate_compression(rank_df, 'tokens_gesamt', 'token_text_rank', 'desired_compression_rate')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "63be3639594356bc87fe58051c1d1c5221c23a964c31c0e05d208c4974bedf26"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
